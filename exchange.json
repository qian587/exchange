[
  [
    {
      "author": "GLU <glerma@stanford.edu>",
      "description": "Normalize anatomical NIfTI with the MNI template or with AC-PC coordinates provided by the user.",
      "label": "VISTA Lab: ACPC-ANAT Normalize",
      "license": "MIT",
      "maintainer": "GLU <glerma@stanford.edu>",
      "name": "acpc-anat",
      "source": "https://github.com/vistalab/acpc-anat",
      "url": "https://github.com/vistalab/acpc-anat",
      "version": "1.0.3"
    },
    {
      "author": "GLU <glerma@stanford.edu>",
      "description": "Normalize anatomical NIfTI with the MNI template or with AC-PC coordinates provided by the user.",
      "label": "VISTA Lab: ACPC-ANAT Normalize",
      "license": "MIT",
      "maintainer": "GLU <glerma@stanford.edu>",
      "name": "acpc-anat",
      "source": "https://github.com/vistalab/acpc-anat",
      "url": "https://github.com/vistalab/acpc-anat",
      "version": "1.0.2"
    },
    {
      "author": "GLU <glerma@stanford.edu>",
      "description": "Normalize anatomical NIfTI with the MNI template or with AC-PC coordinates provided by the user.",
      "label": "VISTA Lab: ACPC-ANAT Normalize",
      "license": "MIT",
      "maintainer": "GLU <glerma@stanford.edu>",
      "name": "acpc-anat",
      "source": "https://github.com/vistalab/acpc-anat",
      "url": "https://github.com/vistalab/acpc-anat",
      "version": "1.0.0"
    }
  ],
  [
    {
      "author": "Daniel Glen <glend@mail.nih.gov>",
      "description": "AFNI-based brain warping based on D99 Macaque Atlas warp scripts, which use AFNI functions (AFNI_2011_12_21_1014) to align a template and segmentation to the native space of an individual macaque in its native space. The output includes the native aligned to the template dataset and vice versa. It also creates surfaces for structures in the individual native space and an approximate surface for the whole brain. All surfaces are saved in GIFTI format, and volumes are in AFNI format. This Gear will convert output volume files to NIfTI format.",
      "label": "AFNI: Brain Warp",
      "license": "GPL-2.0",
      "maintainer": "Carlos Correa <cgc@stanford.edu>",
      "name": "afni-brain-warp",
      "source": "https://github.com/scitran-apps/afni-brain-warp",
      "url": "https://afni.nimh.nih.gov/pub/dist/atlases/macaque/macaqueatlas_1.2a/AFNI_scripts/",
      "version": "0.0.1"
    }
  ],
  [
    {
      "author": "Jason D. Yeatman <jyeatman@uw.edu>",
      "description": "AFQ was designed [by Jason D. Yeatman, et al.] to generate Tract Profiles of tissue properties for major fiber tracts in healthy and diseased brains. Online documentation can be found at: https://github.com/yeatmanlab/AFQ/wiki.",
      "label": "AFQ: Automated Fiber Quantification",
      "license": "GPL-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "afq",
      "source": "https://github.com/scitran-apps/afq",
      "url": "https://github.com/yeatmanlab/afq",
      "version": "0.0.2"
    }
  ],
  [
    {
      "author": "Yeatman et al., Stanford VISTA Lab, FMRIB Software Lab, MRTrix, Pestilli et al., Takemura et al.",
      "cite": "Yeatman J.D., Dougherty R.F., Myall N.J., Wandell B.A., Feldman H.M. (2012). Tract Profiles of White Matter Properties: Automating Fiber-Tract Quantification. PLoS One.; M. Jenkinson, C.F. Beckmann, T.E. Behrens, M.W. Woolrich, S.M. Smith. FSL. NeuroImage, 62:782-90, 2012.  Evaluation and statistical inference for human connectomes. F. Pestilli, J.D. Yeatman, A. Rokem, K.N. Kay & B.A. Wandell (2014) Nature Methods doi:10.1038/nmeth.3098 Published online 07 September 2014. https://mrtrix.readthedocs.io/en/latest/reference/references.html.  Takemura H, Caiafa CF, Wandell BA, Pestilli F (2016) Ensemble Tractography. PLoS Comput Biol 12(2): e1004692. https://doi.org/10.1371/journal.pcbi.1004692",
      "description": "This gear contains a multi-step pipeline designed to run DTIInit, MRtrix3, LiFE, ET, and AFQ. DTIInit runs preprocessing steps, MRTrix3 + Ensemble Tractography + LiFE generate a connectome which is then run through Automated Fiber Quantification (AFQ). AFQ generates tract profiles of tissue properties for major fiber tracts in the brain. This gear also generates AFQ Browser outputs for visualization. Required inputs are (1) DWI NIfTI image, (2) BVEC file, (3) BVAL file, and (4) and Anatomical NIfTI file - which is optional and will be used to align the DWI data, if provided.",
      "label": "AFQ Pipeline: Automated Fiber Quantification Pipeline (DTIInit + MRtrix3 + ET + LiFE + AFQ)",
      "license": "Other",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "afq-pipeline",
      "source": "https://github.com/scitran-apps/afq-pipline",
      "url": "https://github.com/yeatmanlab/afq",
      "version": "3.0.0"
    },
    {
      "author": "Jason D. Yeatman, et. al, VISTA Lab, FMRIB Software Laboratory",
      "cite": "Yeatman J.D., Dougherty R.F., Myall N.J., Wandell B.A., Feldman H.M. (2012). Tract Profiles of White Matter Properties: Automating Fiber-Tract Quantification. PLoS One.; M. Jenkinson, C.F. Beckmann, T.E. Behrens, M.W. Woolrich, S.M. Smith. FSL. NeuroImage, 62:782-90, 2012",
      "description": "This gear contains a 3-step pipeline designed to run AFQ. The first step is optional, and will merge two diffusion datasets using FSLMERGE. The second step is data preprocessing using DTIINIT, from the VISTA Lab, Stanford University. The final step is the Automated Fiber Quantification (AFQ), which generates tract profiles of tissue properties for major fiber tracts in the brain.",
      "label": "AFQ Pipeline: Automated Fiber Quantification Pipeline",
      "license": "GPL-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "afq-pipeline",
      "source": "https://github.com/scitran-apps/afq-pipline",
      "url": "https://github.com/yeatmanlab/afq",
      "version": "1.0.3"
    },
    {
      "author": "Jason D. Yeatman, et. al, VISTA Lab, FMRIB Software Laboratory",
      "cite": "Yeatman J.D., Dougherty R.F., Myall N.J., Wandell B.A., Feldman H.M. (2012). Tract Profiles of White Matter Properties: Automating Fiber-Tract Quantification. PLoS One.; M. Jenkinson, C.F. Beckmann, T.E. Behrens, M.W. Woolrich, S.M. Smith. FSL. NeuroImage, 62:782-90, 2012",
      "description": "This gear contains a 3-step pipeline designed to run AFQ. The first step is optional, and will merge two diffusion datasets using FSLMERGE. The second step is data preprocessing using DTIINIT, from the VISTA Lab, Stanford University. The final step is the Automated Fiber Quantification (AFQ), which generates tract profiles of tissue properties for major fiber tracts in the brain.",
      "label": "AFQ Pipeline: Automated Fiber Quantification Pipeline",
      "license": "GPL-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "afq-pipeline",
      "source": "https://github.com/scitran-apps/afq-pipline",
      "url": "https://github.com/yeatmanlab/afq",
      "version": "1.0.2"
    },
    {
      "author": "Jason D. Yeatman, et. al, VISTA Lab, FMRIB Software Laboratory",
      "cite": "Yeatman J.D., Dougherty R.F., Myall N.J., Wandell B.A., Feldman H.M. (2012). Tract Profiles of White Matter Properties: Automating Fiber-Tract Quantification. PLoS One.; M. Jenkinson, C.F. Beckmann, T.E. Behrens, M.W. Woolrich, S.M. Smith. FSL. NeuroImage, 62:782-90, 2012",
      "description": "This gear contains a 3-step pipeline designed to run AFQ. The first step is optional, and will merge two diffusion datasets using FSLMERGE. The second step is data preprocessing using DTIINIT, from the VISTA Lab, Stanford University. The final step is the Automated Fiber Quantification (AFQ), which generates tract profiles of tissue properties for major fiber tracts in the brain.",
      "label": "AFQ Pipeline: Automated Fiber Quantification Pipeline",
      "license": "GPL-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "afq-pipeline",
      "source": "https://github.com/scitran-apps/afq-pipline",
      "url": "https://github.com/yeatmanlab/afq",
      "version": "1.0.1"
    },
    {
      "author": "Jason D. Yeatman, et. al, VISTA Lab, FMRIB Software Laboratory",
      "cite": "Yeatman J.D., Dougherty R.F., Myall N.J., Wandell B.A., Feldman H.M. (2012). Tract Profiles of White Matter Properties: Automating Fiber-Tract Quantification. PLoS One.; M. Jenkinson, C.F. Beckmann, T.E. Behrens, M.W. Woolrich, S.M. Smith. FSL. NeuroImage, 62:782-90, 2012",
      "description": "This gear contains a 3-step pipeline designed to run AFQ. The first step is optional, and will merge two diffusion datasets using FSLMERGE. The second step is data preprocessing using DTIINIT, from the VISTA Lab, Stanford University. The final step is the Automated Fiber Quantification (AFQ), which generates tract profiles of tissue properties for major fiber tracts in the brain.",
      "label": "AFQ Pipeline: Automated Fiber Quantification Pipeline",
      "license": "GPL-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "afq-pipeline",
      "source": "https://github.com/scitran-apps/afq-pipline",
      "url": "https://github.com/yeatmanlab/afq",
      "version": "1.0.0"
    }
  ],
  [
    {
      "author": "Jason D. Yeatman, et. al, VISTA Lab, FMRIB Software Laboratory",
      "cite": "Yeatman J.D., Dougherty R.F., Myall N.J., Wandell B.A., Feldman H.M. (2012). Tract Profiles of White Matter Properties: Automating Fiber-Tract Quantification. PLoS One.; M. Jenkinson, C.F. Beckmann, T.E. Behrens, M.W. Woolrich, S.M. Smith. FSL. NeuroImage, 62:782-90, 2012",
      "description": "This SDK-enabled Gear is able to take a user-provided acquisition label and automatically find appropriate inputs for the Gear. The Gear runs a 3-step pipeline culminating in a run of AFQ. The first step is optional, and will merge two diffusion datasets using FSLMERGE. The second step is diffusion data preprocessing using DTIINIT. The final step is Automated Fiber Quantification (AFQ), which generates tract profiles of tissue properties for major white matter tracts in the brain.",
      "label": "AFQ Pipeline SDK: Automated Fiber Quantification Processing Pipeline",
      "license": "Other",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "afq-pipeline-sdk",
      "source": "https://github.com/scitran-apps/afq-pipeline-sdk",
      "url": "https://github.com/yeatmanlab/afq",
      "version": "1.1.0"
    },
    {
      "author": "Jason D. Yeatman, et. al, VISTA Lab, FMRIB Software Laboratory",
      "cite": "Yeatman J.D., Dougherty R.F., Myall N.J., Wandell B.A., Feldman H.M. (2012). Tract Profiles of White Matter Properties: Automating Fiber-Tract Quantification. PLoS One.; M. Jenkinson, C.F. Beckmann, T.E. Behrens, M.W. Woolrich, S.M. Smith. FSL. NeuroImage, 62:782-90, 2012",
      "description": "This SDK-enabled Gear is able to take a user-provided acquisition label and automatically find appropriate inputs for the Gear. The Gear runs a 3-step pipeline culminating in a run of AFQ. The first step is optional, and will merge two diffusion datasets using FSLMERGE. The second step is diffusion data preprocessing using DTIINIT. The final step is Automated Fiber Quantification (AFQ), which generates tract profiles of tissue properties for major white matter tracts in the brain.",
      "label": "AFQ Pipeline SDK: Automated Fiber Quantification Processing Pipeline",
      "license": "Other",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "afq-pipeline-sdk",
      "source": "https://github.com/scitran-apps/afq-pipeline-sdk",
      "url": "https://github.com/yeatmanlab/afq",
      "version": "1.0.2"
    },
    {
      "author": "Jason D. Yeatman, et. al, VISTA Lab, FMRIB Software Laboratory",
      "cite": "Yeatman J.D., Dougherty R.F., Myall N.J., Wandell B.A., Feldman H.M. (2012). Tract Profiles of White Matter Properties: Automating Fiber-Tract Quantification. PLoS One.; M. Jenkinson, C.F. Beckmann, T.E. Behrens, M.W. Woolrich, S.M. Smith. FSL. NeuroImage, 62:782-90, 2012",
      "description": "This SDK Gear will take a user-provided acquisition label and automatically find appropriate inputs for the Gear. The Gear runs a 3-step pipeline designed to run AFQ. The first step is optional, and will merge two diffusion datasets using FSLMERGE. The second step is data preprocessing using DTIINIT. The final step the Automated Fiber Quantification (AFQ), which generates tract profiles of tissue properties for major fiber tracts in the brain.",
      "label": "AFQ Pipeline SDK: Automated Fiber Quantification Processing Pipeline",
      "license": "Other",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "afq-pipeline-sdk",
      "source": "https://github.com/scitran-apps/afq-pipline-sdk",
      "url": "https://github.com/yeatmanlab/afq",
      "version": "1.0.1"
    },
    {
      "author": "Jason D. Yeatman, et. al, VISTA Lab, FMRIB Software Laboratory",
      "cite": "Yeatman J.D., Dougherty R.F., Myall N.J., Wandell B.A., Feldman H.M. (2012). Tract Profiles of White Matter Properties: Automating Fiber-Tract Quantification. PLoS One.; M. Jenkinson, C.F. Beckmann, T.E. Behrens, M.W. Woolrich, S.M. Smith. FSL. NeuroImage, 62:782-90, 2012",
      "description": "This SDK Gear will take a user-provided acquisition label and automatically find appropriate inputs for the Gear. The Gear runs a 3-step pipeline designed to run AFQ. The first step is optional, and will merge two diffusion datasets using FSLMERGE. The second step is data preprocessing using DTIINIT. The final step the Automated Fiber Quantification (AFQ), which generates tract profiles of tissue properties for major fiber tracts in the brain.",
      "label": "AFQ Pipeline SDK: Automated Fiber Quantification Processing Pipeline",
      "license": "Other",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "afq-pipeline-sdk",
      "source": "https://github.com/scitran-apps/afq-pipline-sdk",
      "url": "https://github.com/yeatmanlab/afq",
      "version": "1.0.0"
    }
  ],
  [
    {
      "author": "Bob Dougherty <bobd@stanford.edu>",
      "description": "Reorient NIfTI data and metadata fields into RAS space by estimating and applying a canonical transform.",
      "label": "Apply Canonical Transform",
      "license": "MIT",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "apply-canonical-xform",
      "source": "https://github.com/scitran-apps/apply-canonical-xform",
      "url": "https://github.com/vistalab/vistasoft/blob/master/fileFilters/nifti/niftiApplyCannonicalXform.m",
      "version": "0.1.0"
    }
  ],
  [
    {
      "author": "Poldrack lab, Stanford University",
      "cite": "see https://fmriprep.readthedocs.io/en/stable/citing.html",
      "command": "python run.py",
      "description": "fMRIPrep 20.2.0 (September 28, 2020) is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that can be easily submitted to a variety of group level analyses, including task-based or resting-state fMRI, graph theory measures, surface or volume-based statistics, etc.",
      "environment": {
        "PATH": "/usr/local/miniconda/bin:/opt/ICA-AROMA:/usr/lib/ants:/usr/lib/fsl/5.0:/usr/lib/afni/bin:/opt/freesurfer/bin:/bin:/opt/freesurfer/tktools:/opt/freesurfer/mni/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
        "PYTHONUNBUFFERED": "1"
      },
      "label": "BIDS fMRIPrep: A Robust Preprocessing Pipeline for fMRI Data",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "bids-fmriprep",
      "source": "https://github.com/flywheel-apps/bids-fmriprep",
      "url": "https://github.com/flywheel-apps/bids-fmriprep/blob/master/README.md",
      "version": "1.1.9_20.2.0"
    },
    {
      "author": "Poldrack lab, Stanford University",
      "cite": "see https://fmriprep.readthedocs.io/en/stable/citing.html",
      "command": "python run.py",
      "description": "fMRIPrep 20.2.1 (Long-Term Support version, November 6, 2020) is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that can be easily submitted to a variety of group level analyses, including task-based or resting-state fMRI, graph theory measures, surface or volume-based statistics, etc.",
      "environment": {
        "PATH": "/usr/local/miniconda/bin:/opt/ICA-AROMA:/usr/lib/ants:/usr/lib/fsl/5.0:/usr/lib/afni/bin:/opt/freesurfer/bin:/bin:/opt/freesurfer/tktools:/opt/freesurfer/mni/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
        "PYTHONUNBUFFERED": "1"
      },
      "label": "BIDS fMRIPrep: A Robust Preprocessing Pipeline for fMRI Data",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "bids-fmriprep",
      "source": "https://github.com/nipreps/fmriprep",
      "url": "https://github.com/flywheel-apps/bids-fmriprep/blob/master/README.md",
      "version": "1.1.16_20.2.1"
    },
    {
      "author": "Poldrack lab, Stanford University",
      "cite": "see https://fmriprep.readthedocs.io/en/stable/citing.html",
      "command": "python run.py",
      "description": "fMRIPrep (1.5.2 December 2, 2019) is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that can be easily submitted to a variety of group level analyses, including task-based or resting-state fMRI, graph theory measures, surface or volume-based statistics, etc.",
      "environment": {
        "PATH": "/usr/local/miniconda/bin:/opt/ICA-AROMA:/usr/lib/ants:/usr/lib/fsl/5.0:/usr/lib/afni/bin:/opt/freesurfer/bin:/bin:/opt/freesurfer/tktools:/opt/freesurfer/mni/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
        "PYTHONUNBUFFERED": "1"
      },
      "label": "BIDS fMRIPrep: A Robust Preprocessing Pipeline for fMRI Data",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "bids-fmriprep",
      "source": "https://github.com/flywheel-apps/bids-fmriprep",
      "url": "https://github.com/flywheel-apps/bids-fmriprep/blob/master/README.md",
      "version": "1.0.3_1.5.2"
    },
    {
      "author": "Poldrack lab, Stanford University",
      "cite": "see https://fmriprep.readthedocs.io/en/stable/citing.html",
      "command": "python run.py",
      "description": "fMRIPrep (1.5.10 April 16, 2020) is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that can be easily submitted to a variety of group level analyses, including task-based or resting-state fMRI, graph theory measures, surface or volume-based statistics, etc.",
      "environment": {
        "PATH": "/usr/local/miniconda/bin:/opt/ICA-AROMA:/usr/lib/ants:/usr/lib/fsl/5.0:/usr/lib/afni/bin:/opt/freesurfer/bin:/bin:/opt/freesurfer/tktools:/opt/freesurfer/mni/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
        "PYTHONUNBUFFERED": "1"
      },
      "label": "BIDS fMRIPrep: A Robust Preprocessing Pipeline for fMRI Data",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "bids-fmriprep",
      "source": "https://github.com/flywheel-apps/bids-fmriprep",
      "url": "https://github.com/flywheel-apps/bids-fmriprep/blob/master/README.md",
      "version": "1.0.12_1.5.10"
    },
    {
      "author": "Poldrack lab, Stanford University",
      "cite": "see https://fmriprep.readthedocs.io/en/stable/citing.html",
      "command": "python run.py",
      "description": "fMRIPrep (1.5.9 Feb. 15, 2020) is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that can be easily submitted to a variety of group level analyses, including task-based or resting-state fMRI, graph theory measures, surface or volume-based statistics, etc.",
      "environment": {
        "PATH": "/usr/local/miniconda/bin:/opt/ICA-AROMA:/usr/lib/ants:/usr/lib/fsl/5.0:/usr/lib/afni/bin:/opt/freesurfer/bin:/bin:/opt/freesurfer/tktools:/opt/freesurfer/mni/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
        "PYTHONUNBUFFERED": "1"
      },
      "label": "BIDS fMRIPrep: A Robust Preprocessing Pipeline for fMRI Data",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "bids-fmriprep",
      "source": "https://github.com/flywheel-apps/bids-fmriprep",
      "url": "https://github.com/flywheel-apps/bids-fmriprep/blob/master/README.md",
      "version": "1.0.11_1.5.9"
    }
  ],
  [
    {
      "author": "http://surfer.nmr.mgh.harvard.edu/",
      "cite": "https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferMethodsCitation",
      "command": "/usr/local/miniconda/bin/python3 run.py",
      "description": "BIDS-Apps/Freesurfer (6.0.1-5) This app implements surface reconstruction using Freesurfer. It reconstructs the surface for each subject individually and then creates a study specific template. In case there are multiple sessions the Freesurfer longitudinal pipeline is used (creating subject specific templates) unless instructed to combine data across sessions.  The current Freesurfer version is based on: freesurfer-Linux-centos6_x86_64-stable-pub-v6.0.0.tar.gz.",
      "environment": {
        "PATH": "PATH=/usr/local/miniconda/bin:/opt/freesurfer/bin:/opt/freesurfer/fsfast/bin:/opt/freesurfer/tktools:/opt/freesurfer/mni/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
        "PYTHONUNBUFFERED": "1"
      },
      "label": "BIDS Freesurfer: Freesurfer recon-all BIDS App",
      "license": "Apache-2.0",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "bids-freesurfer",
      "source": "https://github.com/flywheel-apps/bids-freesurfer",
      "url": "https://github.com/BIDS-Apps/freesurfer",
      "version": "1.0.4_6.0.1-5"
    },
    {
      "author": "http://surfer.nmr.mgh.harvard.edu/",
      "cite": "https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferMethodsCitation",
      "command": "/usr/local/miniconda/bin/python3 run.py",
      "description": "BIDS-Apps/Freesurfer (6.0.1-5) This app implements surface reconstruction using Freesurfer. It reconstructs the surface for each subject individually and then creates a study specific template. In case there are multiple sessions the Freesurfer longitudinal pipeline is used (creating subject specific templates) unless instructed to combine data across sessions.  The current Freesurfer version is based on: freesurfer-Linux-centos6_x86_64-stable-pub-v6.0.0.tar.gz.",
      "environment": {
        "PATH": "PATH=/usr/local/miniconda/bin:/opt/freesurfer/bin:/opt/freesurfer/fsfast/bin:/opt/freesurfer/tktools:/opt/freesurfer/mni/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
        "PYTHONUNBUFFERED": "1"
      },
      "label": "BIDS Freesurfer: Freesurfer recon-all BIDS App",
      "license": "Apache-2.0",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "bids-freesurfer",
      "source": "https://github.com/flywheel-apps/bids-freesurfer",
      "url": "https://github.com/BIDS-Apps/freesurfer",
      "version": "1.0.1_6.0.1-5"
    }
  ],
  [
    {
      "author": "Poldrack Lab, Stanford University",
      "cite": "Esteban O, Birman D, Schaer M, Koyejo OO, Poldrack RA, Gorgolewski KJ; MRIQC: Advancing the Automatic Prediction of Image Quality in MRI from Unseen Sites; PLOS ONE 12(9):e0184661; doi:10.1371/journal.pone.0184661.",
      "command": "python run.py",
      "description": "MRIQC (0.15.2 - April 6, 2020)) extracts no-reference IQMs (image quality metrics) from structural (T1w and T2w) and functional MRI (magnetic resonance imaging) data.  Arguments such as --n_procs --mem_gb and --ants-nthreads are set to use the maximum available as detected by MRIQC.",
      "environment": {
        "AFNI_IMSAVE_WARNINGS": "NO",
        "AFNI_MODELPATH": "/opt/afni/models",
        "AFNI_PLUGINPATH": "/opt/afni/plugins",
        "AFNI_TTATLAS_DATASET": "/opt/afni/atlases",
        "ANTSPATH": "/usr/lib/ants",
        "CPATH": "/usr/local/miniconda/include/:",
        "FSLDIR": "/usr/share/fsl/5.0",
        "FSLMULTIFILEQUIT": "TRUE",
        "FSLOUTPUTTYPE": "NIFTI_GZ",
        "FSLTCLSH": "/usr/bin/tclsh",
        "FSLWISH": "/usr/bin/wish",
        "HOME": "/home/bidsapp",
        "LANG": "C.UTF-8",
        "LC_ALL": "C.UTF-8",
        "LD_LIBRARY_PATH": "/usr/lib/fsl/5.0:",
        "MKL_NUM_THREADS": "1",
        "OMP_NUM_THREADS": "1",
        "PATH": "/usr/local/miniconda/bin:/opt/afni:/usr/lib/ants:/usr/lib/fsl/5.0:/usr/lib/afni/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
        "POSSUMDIR": "/usr/share/fsl/5.0",
        "PYTHONNOUSERSITE": "1",
        "TEMPLATEFLOW_HOME": "/opt/templateflow"
      },
      "label": "BIDS MRIQC: Automatic prediction of quality and visual reporting of MRI scans in BIDS format",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "bids-mriqc",
      "source": "https://github.com/flywheel-apps/bids-mriqc",
      "url": "https://mriqc.readthedocs.io/en/stable/about.html",
      "version": "1.1.0_0.15.2"
    },
    {
      "author": "Poldrack Lab, Stanford University",
      "cite": "Esteban O, Birman D, Schaer M, Koyejo OO, Poldrack RA, Gorgolewski KJ; MRIQC: Advancing the Automatic Prediction of Image Quality in MRI from Unseen Sites; PLOS ONE 12(9):e0184661; doi:10.1371/journal.pone.0184661.",
      "command": "python run.py",
      "description": "MRIQC (v0.15.1) extracts no-reference IQMs (image quality metrics) from structural (T1w and T2w) and functional MRI (magnetic resonance imaging) data.",
      "environment": {
        "AFNI_IMSAVE_WARNINGS": "NO",
        "AFNI_MODELPATH": "/opt/afni/models",
        "AFNI_PLUGINPATH": "/opt/afni/plugins",
        "AFNI_TTATLAS_DATASET": "/opt/afni/atlases",
        "ANTSPATH": "/usr/lib/ants",
        "CPATH": "/usr/local/miniconda/include/:",
        "FSLDIR": "/usr/share/fsl/5.0",
        "FSLMULTIFILEQUIT": "TRUE",
        "FSLOUTPUTTYPE": "NIFTI_GZ",
        "FSLTCLSH": "/usr/bin/tclsh",
        "FSLWISH": "/usr/bin/wish",
        "HOME": "/home/bidsapp",
        "LANG": "C.UTF-8",
        "LC_ALL": "C.UTF-8",
        "LD_LIBRARY_PATH": "/usr/lib/fsl/5.0:",
        "MKL_NUM_THREADS": "1",
        "OMP_NUM_THREADS": "1",
        "PATH": "/usr/local/miniconda/bin:/opt/afni:/usr/lib/ants:/usr/lib/fsl/5.0:/usr/lib/afni/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
        "POSSUMDIR": "/usr/share/fsl/5.0",
        "PYTHONNOUSERSITE": "1",
        "TEMPLATEFLOW_HOME": "/opt/templateflow"
      },
      "label": "MRIQC: Automatic prediction of quality and visual reporting of MRI scans in BIDS format",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "bids-mriqc",
      "source": "https://github.com/flywheel-apps/bids-mriqc",
      "url": "https://mriqc.readthedocs.io/en/stable/about.html",
      "version": "1.0.8_0.15.1"
    },
    {
      "author": "Poldrack Lab, Stanford University",
      "cite": "Esteban O, Birman D, Schaer M, Koyejo OO, Poldrack RA, Gorgolewski KJ; MRIQC: Advancing the Automatic Prediction of Image Quality in MRI from Unseen Sites; PLOS ONE 12(9):e0184661; doi:10.1371/journal.pone.0184661.",
      "description": "MRIQC (v0.15.1) extracts no-reference IQMs (image quality metrics) from structural (T1w and T2w) and functional MRI (magnetic resonance imaging) data.",
      "environment": {
        "AFNI_IMSAVE_WARNINGS": "NO",
        "AFNI_MODELPATH": "/opt/afni/models",
        "AFNI_PLUGINPATH": "/opt/afni/plugins",
        "AFNI_TTATLAS_DATASET": "/opt/afni/atlases",
        "ANTSPATH": "/usr/lib/ants",
        "CPATH": "/usr/local/miniconda/include/:",
        "FSLDIR": "/usr/share/fsl/5.0",
        "FSLMULTIFILEQUIT": "TRUE",
        "FSLOUTPUTTYPE": "NIFTI_GZ",
        "FSLTCLSH": "/usr/bin/tclsh",
        "FSLWISH": "/usr/bin/wish",
        "HOME": "/home/bidsapp",
        "LANG": "C.UTF-8",
        "LC_ALL": "C.UTF-8",
        "LD_LIBRARY_PATH": "/usr/lib/fsl/5.0:",
        "MKL_NUM_THREADS": "1",
        "OMP_NUM_THREADS": "1",
        "PATH": "/usr/local/miniconda/bin:/opt/afni:/usr/lib/ants:/usr/lib/fsl/5.0:/usr/lib/afni/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
        "POSSUMDIR": "/usr/share/fsl/5.0",
        "PYTHONNOUSERSITE": "1",
        "TEMPLATEFLOW_HOME": "/opt/templateflow"
      },
      "label": "MRIQC: Automatic prediction of quality and visual reporting of MRI scans in BIDS format",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "bids-mriqc",
      "source": "https://github.com/flywheel-apps/bids-mriqc",
      "url": "https://mriqc.readthedocs.io/en/stable/about.html",
      "version": "1.0.0_0.15.1"
    }
  ],
  [
    {
      "author": "Flywheel Exchange, LLC",
      "command": "pipenv run python3 /flywheel/v0/run.py",
      "description": "Prepare project for BIDS Curation. BIDS Pre-Curate offers a simple way to modify labels and classifications of project data to be compatible with the BIDS-spec. Running pre-curate on a given project (as a project-level analysis) will generate CSV files that will be populated with a unique list of container labels, as well as slots for the information needed for BIDS curation (classification, task, etc.). These CSV files can be downloaded and modified (outside of Flywheel) to provide missing or corrected information. The completed CSV file is then uploaded to the project (as an attachment) and provided as input to a run of this same gear to do on-the-fly mappings and metadata updates. For more information, please see the readme in the source repository.",
      "environment": {
        "PYTHONUNBUFFERED": "1"
      },
      "label": "BIDS Pre-Curation",
      "license": "MIT",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "bids-pre-curate",
      "source": "https://github.com/flywheel-apps/bids-pre-curate",
      "url": "https://github.com/flywheel-apps/bids-pre-curate",
      "version": "0.1.4"
    }
  ],
  [
    {
      "author": "Flywheel",
      "command": "python run.py",
      "description": "Bruker2nifti is an open source medical image format converter from raw Bruker ParaVision to NifTi, without any intermediate step through the DICOM standard formats.",
      "label": "Bruker to NIfTI converter",
      "license": "Other",
      "maintainer": "support@flywheel.io",
      "name": "bruker2nifti",
      "source": "",
      "url": "",
      "version": "0.1.0"
    }
  ],
  [
    {
      "author": "Syam Gadde <gadde@biac.duke.edu>",
      "description": "Use BXH/XCEDE Tools to perform QA (quality assurance) calculations and produce images, graphs, and/or XML data as output. fmriqa_phantomqa.pl and fmriqa_generate.pl produce an HTML report with various QA measures. fmriqa_phantomqa.pl was designed for fMRI images of the BIRN stability phantom, and fmriqa_generate.pl has been used for human fMRI data.",
      "label": "BXH-XCEDE-TOOLS: fMRI QA (v1.11.14)",
      "license": "Other",
      "maintainer": "Michael Perry <support@flywheel.io>",
      "name": "bxh-xcede-tools-qa",
      "source": "https://github.com/flywheel-apps/bxh-xcede-tools-qa/",
      "url": "https://www.nitrc.org/projects/bxh_xcede_tools/",
      "version": "1.0.2_1.11.14"
    },
    {
      "author": "Syam Gadde <gadde@biac.duke.edu>",
      "description": "These tools perform QA (quality assurance) calculations and produce images, graphs, and/or XML data as output. fmriqa_phantomqa.pl and fmriqa_generate.pl produce an HTML report with various QA measures. fmriqa_phantomqa.pl was designed for fMRI images of the BIRN stability phantom, and fmriqa_generate.pl has been used for human fMRI data.",
      "label": "BXH-XCEDE-TOOLS: fMRI QA (v1.11.14)",
      "license": "Other",
      "maintainer": "Michael Perry <support@flywheel.io>",
      "name": "bxh-xcede-tools-qa",
      "source": "https://github.com/flywheel-apps/bxh-xcede-tools-qa/",
      "url": "https://www.nitrc.org/projects/bxh_xcede_tools/",
      "version": "1.0.1_1.11.14"
    },
    {
      "author": "Syam Gadde <gadde@biac.duke.edu>",
      "description": "These tools perform QA (quality assurance) calculations and produce images, graphs, and/or XML data as output. fmriqa_phantomqa.pl and fmriqa_generate.pl produce an HTML report with various QA measures. fmriqa_phantomqa.pl was designed for fMRI images of the BIRN stability phantom, and fmriqa_generate.pl has been used for human fMRI data.",
      "label": "BXH-XCEDE-TOOLS: fMRI QA (v1.11.14-lsb30.x86_64)",
      "license": "Other",
      "name": "bxh-xcede-tools-qa",
      "source": "https://github.com/flywheel-apps/bxh-xcede-tools-qa/",
      "url": "https://www.nitrc.org/projects/bxh_xcede_tools/",
      "version": "0.1"
    }
  ],
  [
    {
      "author": "Craddock C, Sikka S, Cheung B, et al.",
      "command": "/flywheel/v0/run.py",
      "description": "The Configurable Pipeline for the Analysis of Connectomes C-PAC is a software for performing high-throughput preprocessing and analysis of functional connectomes data using high-performance computers. C-PAC is implemented in Python using the Nipype pipelining library to efficiently combine tools from AFNI, ANTS, and FSL to achieve high quality and robust automated processing. This docker container, when built, is an application for performing participant level analyses. Future releases will include group-level analyses, when there is a BIDS standard for handling derivatives and group models.",
      "environment": {
        "C3DPATH": "/opt/c3d/",
        "FSLDIR": "/usr/share/fsl/5.0",
        "FSLMULTIFILEQUIT": "TRUE",
        "FSLOUTPUTTYPE": "NIFTI_GZ",
        "FSLTCLSH": "/usr/bin/tclsh",
        "FSLWISH": "/usr/bin/wish",
        "LD_LIBRARY_PATH": "/usr/lib/fsl/5.0:",
        "PATH": "/usr/local/miniconda/bin:/opt/ICA-AROMA:/usr/lib/fsl/5.0:/opt/afni:/opt/c3d//bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
        "POSSUMDIR": "/usr/share/fsl/5.0"
      },
      "label": "BIDS-APP: C-PAC (Configurable Pipeline for the Analysis of Connectomes)",
      "license": "Apache-2.0",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "c-pac",
      "source": "https://github.com/flywheel-apps/c-pac",
      "url": "https://github.com/BIDS-Apps/CPAC",
      "version": "0.1.2_v1.4.1"
    },
    {
      "author": "Craddock C, Sikka S, Cheung B, et al.",
      "command": "/flywheel/v0/run.py",
      "description": "The Configurable Pipeline for the Analysis of Connectomes C-PAC is a software for performing high-throughput preprocessing and analysis of functional connectomes data using high-performance computers. C-PAC is implemented in Python using the Nipype pipelining library to efficiently combine tools from AFNI, ANTS, and FSL to achieve high quality and robust automated processing. This docker container, when built, is an application for performing participant level analyses. Future releases will include group-level analyses, when there is a BIDS standard for handling derivatives and group models.",
      "environment": {
        "C3DPATH": "/opt/c3d/",
        "FSLDIR": "/usr/share/fsl/5.0",
        "FSLMULTIFILEQUIT": "TRUE",
        "FSLOUTPUTTYPE": "NIFTI_GZ",
        "FSLTCLSH": "/usr/bin/tclsh",
        "FSLWISH": "/usr/bin/wish",
        "LD_LIBRARY_PATH": "/usr/lib/fsl/5.0:",
        "PATH": "/usr/local/miniconda/bin:/opt/ICA-AROMA:/usr/lib/fsl/5.0:/opt/afni:/opt/c3d//bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
        "POSSUMDIR": "/usr/share/fsl/5.0"
      },
      "label": "BIDS-APP: C-PAC (Configurable Pipeline for the Analysis of Connectomes)",
      "license": "Apache-2.0",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "c-pac",
      "source": "https://github.com/flywheel-apps/c-pac",
      "url": "https://github.com/BIDS-Apps/CPAC",
      "version": "0.1.1_v1.4.1"
    },
    {
      "author": "Craddock C, Sikka S, Cheung B, et al.",
      "description": "The Configurable Pipeline for the Analysis of Connectomes C-PAC is a software for performing high-throughput preprocessing and analysis of functional connectomes data using high-performance computers. C-PAC is implemented in Python using the Nipype pipelining library to efficiently combine tools from AFNI, ANTS, and FSL to achieve high quality and robust automated processing. This docker container, when built, is an application for performing participant level analyses. Future releases will include group-level analyses, when there is a BIDS standard for handling derivatives and group models.",
      "label": "BIDS-APP: C-PAC (Configurable Pipeline for the Analysis of Connectomes)",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "c-pac",
      "source": "https://github.com/flywheel-apps/c-pac",
      "url": "https://github.com/BIDS-Apps/CPAC",
      "version": "0.0.1"
    }
  ],
  [
    {
      "author": "Scientific Transparency (RF Dougherty, K Hahn, R Bowen, G Schaefer, LM Perry, H Wu)",
      "description": "CNI-DCM-CONVERT uses SciTran's data library (https://github.com/vistalab/scitran-data) to convert raw DICOM data (within a zip archive) to NIfTI, Montage, and PNG (screenshot acquisitions) formats. DCM-CONVERT supports Siemens and GE DICOM data. This gear will also use dcm2niix to generate bids-sidecar metadata. Those metadata will be added to the output NIfTI file's info object in Flywheel.",
      "label": "CNI-DCM-CONVERT: DICOM Conversion Utility",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "cni-dcm-convert",
      "source": "https://github.com/cni/cni-dcm-convert",
      "url": "https://github.com/vistalab/scitran-data",
      "version": "2.6.0"
    },
    {
      "author": "Scientific Transparency (RF Dougherty, K Hahn, R Bowen, G Schaefer, LM Perry, H Wu)",
      "description": "CNI-DCM-CONVERT uses SciTran's data library (https://github.com/vistalab/scitran-data) to convert raw DICOM data (within a zip archive) to NIfTI, Montage, and PNG (screenshot acquisitions) formats. DCM-CONVERT supports Siemens and GE DICOM data. This gear will also use dcm2niix to generate bids-sidecar metadata. Those metadata will be added to the output NIfTI file's info object in Flywheel.",
      "label": "CNI-DCM-CONVERT: DICOM Conversion Utility",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry, Stanford CNI <lmperry@stanford.edu>",
      "name": "cni-dcm-convert",
      "source": "https://github.com/cni/cni-dcm-convert",
      "url": "https://github.com/vistalab/scitran-data",
      "version": "2.5.0"
    },
    {
      "author": "Scientific Transparency (RF Dougherty, K Hahn, R Bowen, G Schaefer, LM Perry, H Wu)",
      "description": "CNI-DCM-CONVERT uses SciTran's data library (https://github.com/vistalab/scitran-data) to convert raw DICOM data (within a zip archive) to NIfTI, Montage, and PNG (screenshot acquisitions) formats. DCM-CONVERT supports Siemens and GE DICOM data. This gear will also use dcm2niix to generate bids-sidecar metadata. Those metadata will be added to the output NIfTI file's info object in Flywheel.",
      "label": "CNI-DCM-CONVERT - DICOM Conversion Utility",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "cni-dcm-convert",
      "source": "https://github.com/cni/cni-dcm-convert",
      "url": "https://github.com/vistalab/scitran-data",
      "version": "2.4.0"
    },
    {
      "author": "Scientific Transparency (RF Dougherty, K Hahn, R Bowen, G Schaefer, LM Perry, H Wu)",
      "description": "CNI-DCM-CONVERT uses SciTran's data library (https://github.com/vistalab/scitran-data) to convert raw DICOM data (within a zip archive) to NIfTI, Montage, and PNG (screenshot acquisitions) formats. DCM-CONVERT supports Siemens and GE DICOM data.",
      "label": "CNI-DCM-CONVERT - DICOM conversion tool",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "cni-dcm-convert",
      "source": "https://github.com/cni/cni-dcm-convert",
      "url": "https://github.com/vistalab/scitran-data",
      "version": "2.3.2"
    },
    {
      "author": "Scientific Transparency (RF Dougherty, K Hahn, R Bowen, G Schaefer, LM Perry, H Wu)",
      "description": "CNI-DCM-CONVERT uses SciTran's data library (https://github.com/vistalab/scitran-data) to convert raw DICOM data (within a zip archive) to NIfTI, Montage, and PNG (screenshot acquisitions) formats. DCM-CONVERT supports Siemens and GE DICOM data.",
      "label": "CNI: DCM-CONVERT - DICOM conversion tool",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "cni-dcm-convert",
      "source": "https://github.com/cni/cni-dcm-convert",
      "url": "https://github.com/vistalab/scitran-data",
      "version": "2.3.1"
    },
    {
      "author": "Scientific Transparency (RF Dougherty, K Hahn, R Bowen, G Schaefer, LM Perry, H Wu)",
      "description": "CNI-DCM-CONVERT uses SciTran's data library (https://github.com/vistalab/scitran-data) to convert raw DICOM data (within a zip archive) to NIfTI, Montage, and PNG (screenshot acquisitions) formats. DCM-CONVERT supports Siemens and GE DICOM data.",
      "label": "CNI: DCM-CONVERT - DICOM conversion tool",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "cni-dcm-convert",
      "source": "https://github.com/cni/cni-dcm-convert",
      "url": "https://github.com/vistalab/scitran-data",
      "version": "2.3.0"
    },
    {
      "author": "Scientific Transparency (RF Dougherty, K Hahn, R Bowen, G Schaefer, LM Perry)",
      "description": "CNI-DCM-CONVERT uses SciTran's data library (https://github.com/scitran/data) to convert raw DICOM data (within a zip archive) to NIfTI, Montage, and PNG (screenshot acquisitions) formats. DCM-CONVERT supports Siemens and GE DICOM data.",
      "label": "CNI: DCM-CONVERT - DICOM conversion tool",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "cni-dcm-convert",
      "source": "https://github.com/cni/cni-dcm-convert",
      "url": "https://github.com/scitran/data",
      "version": "2.2.0"
    },
    {
      "author": "Scientific Transparency (RF Dougherty, K Hahn, R Bowen, G Schaefer, LM Perry)",
      "description": "CNI-DCM-CONVERT uses SciTran's data library (https://github.com/scitran/data) to convert raw DICOM data (within a zip archive) to NIfTI, Montage, and PNG (screenshot acquisitions) formats. DCM-CONVERT supports Siemens and GE DICOM data.",
      "label": "CNI: DCM-CONVERT - DICOM conversion tool",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "cni-dcm-convert",
      "source": "https://github.com/cni/cni-dcm-convert",
      "url": "https://github.com/scitran/data",
      "version": "2.1.2"
    },
    {
      "author": "Scientific Transparency (RF Dougherty, K Hahn, R Bowen, G Schaefer, LM Perry)",
      "description": "CNI-DCM-CONVERT uses SciTran's data library (https://github.com/scitran/data) to convert raw DICOM data (within a zip archive) to NIfTI, Montage, and PNG (screenshot acquisitions) formats. DCM-CONVERT supports Siemens and GE DICOM data.",
      "label": "CNI: DCM-CONVERT - DICOM conversion tool",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "cni-dcm-convert",
      "source": "https://github.com/cni/cni-dcm-convert",
      "url": "https://github.com/scitran/data",
      "version": "2.1.1"
    },
    {
      "author": "Scientific Transparency (RF Dougherty, K Hahn, R Bowen, G Schaefer, LM Perry)",
      "description": "CNI-DCM-CONVERT uses SciTran's data library (https://github.com/scitran/data) to convert raw DICOM data (within a zip archive) to NIfTI, Montage, and PNG (screenshot acquisitions) formats. DCM-CONVERT supports Siemens and GE DICOM data.",
      "label": "CNI: DCM-CONVERT - DICOM conversion tool",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "cni-dcm-convert",
      "source": "https://github.com/cni/cni-dcm-convert",
      "url": "https://github.com/scitran/data",
      "version": "2.1.0"
    },
    {
      "author": "Scientific Transparency (RF Dougherty, K Hahn, R Bowen, G Schaefer, LM Perry)",
      "description": "DCM-CONVERT uses SciTran's data library (https://github.com/scitran/data) to convert raw DICOM data (within a zip archive) to NIfTI, Montage, and PNG (screenshot acquisitions) formats. DCM-CONVERT supports Siemens and GE DICOM data.",
      "label": "CNI: DCM-CONVERT - DICOM conversion tool",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "cni-dcm-convert",
      "source": "https://github.com/cni/cni-dcm-convert",
      "url": "https://github.com/scitran/data",
      "version": "2.0.1"
    }
  ],
  [
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from GE DICOM data.",
      "label": "CNI: DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "cni-dicom-mr-classifier",
      "source": "https://github.com/cni/cni-dicom-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "3.3.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from GE DICOM data.",
      "label": "CNI: DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "cni-dicom-mr-classifier",
      "source": "https://github.com/cni/cni-dicom-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "3.2.1"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from GE DICOM data.",
      "label": "CNI: DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "cni-dicom-mr-classifier",
      "source": "https://github.com/cni/cni-dicom-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "3.2.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from GE DICOM data.",
      "label": "CNI: DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "cni-dicom-mr-classifier",
      "source": "https://github.com/cni/cni-dicom-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "3.1.2"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from GE DICOM data.",
      "label": "CNI: DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "cni-dicom-mr-classifier",
      "source": "https://github.com/cni/cni-dicom-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "3.1.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from GE DICOM data.",
      "label": "CNI: DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "cni-dicom-mr-classifier",
      "source": "https://github.com/cni/cni-dicom-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "3.0.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from GE DICOM data.",
      "label": "CNI: DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "cni-dicom-mr-classifier",
      "source": "https://github.com/cni/cni-dicom-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "2.1.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from GE DICOM data.",
      "label": "CNI: DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "cni-dicom-mr-classifier",
      "source": "https://github.com/cni/cni-dicom-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "2.0.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from GE DICOM data.",
      "label": "CNI: DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "cni-dicom-mr-classifier",
      "source": "https://github.com/cni/cni-dicom-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "1.0.2"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from GE DICOM data.",
      "label": "CNI: DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "cni-dicom-mr-classifier",
      "source": "https://github.com/cni/cni-dicom-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "1.0.1"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from GE DICOM data.",
      "label": "CNI: DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "cni-dicom-mr-classifier",
      "source": "https://github.com/cni/cni-dicom-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "1.0.0"
    }
  ],
  [
    {
      "author": "Robert F. Dougherty, Hua Wu",
      "description": "Run QA metrics (displacement, signal spikes) to create a quality assurance report (png) for an fMRI NIfTI using CNI/NIMS code.",
      "label": "CNI: Quality Assurance Report (fMRI)",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "cni-qa-report-fmri",
      "source": "https://github.com/cni/cni-qa-report-fmri",
      "url": "https://cni.stanford.edu/wiki/QA",
      "version": "1.0.4"
    },
    {
      "author": "Robert F. Dougherty, Hua Wu",
      "description": "Run QA metrics (displacement, signal spikes) to create a quality assurance report (png) for an fMRI NIfTI using CNI/NIMS code.",
      "label": "CNI: Quality Assurance Report (fMRI)",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "cni-qa-report-fmri",
      "source": "https://github.com/cni/cni-qa-report-fmri",
      "url": "https://cni.stanford.edu/wiki/QA",
      "version": "1.0.3"
    },
    {
      "author": "Robert F. Dougherty, Hua Wu",
      "description": "Run QA metrics (displacement, signal spikes) to create a quality assurance report (png) for an fMRI NIfTI using CNI/NIMS code.",
      "label": "CNI: Quality Assurance Report (fMRI)",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "cni-qa-report-fmri",
      "source": "https://github.com/cni/cni-qa-report-fmri",
      "url": "https://cni.stanford.edu/wiki/QA",
      "version": "1.0.2"
    },
    {
      "author": "Robert F. Dougherty, Hua Wu",
      "description": "Run QA metrics (displacement, signal spikes) to create a quality assurance report (png) for an fMRI NIfTI using CNI/NIMS code.",
      "label": "CNI: Quality Assurance Report (fMRI)",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "cni-qa-report-fmri",
      "source": "https://github.com/cni/cni-qa-report-fmri",
      "url": "https://cni.stanford.edu/wiki/QA",
      "version": "1.0.1"
    }
  ],
  [
    {
      "author": "Flywheel <support@flywheel.io>",
      "command": "python3 run.py",
      "description": "Use this gear to initialize BIDS filenames and attributes on all files within a given project.",
      "label": "BIDS Curation",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "curate-bids",
      "source": "https://github.com/flywheel-apps/curate-bids",
      "url": "http://bids.neuroimaging.io/",
      "version": "1.0.0_0.9.1"
    },
    {
      "author": "Flywheel <support@flywheel.io>",
      "command": "python3 run.py",
      "description": "Use this gear to initialize BIDS filenames and attributes on all files within a given project.",
      "label": "BIDS Curation",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "curate-bids",
      "source": "https://github.com/flywheel-apps/curate-bids",
      "url": "http://bids.neuroimaging.io/",
      "version": "1.0.0_0.9.0"
    },
    {
      "author": "Flywheel <support@flywheel.io>",
      "command": "python run.py",
      "description": "Use this gear to initialize BIDS filenames and attributes on all files within a given project.",
      "label": "BIDS Curation",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "curate-bids",
      "source": "https://github.com/flywheel-apps/curate-bids",
      "url": "http://bids.neuroimaging.io/",
      "version": "0.6.8"
    },
    {
      "author": "Flywheel <support@flywheel.io>",
      "command": "python run.py",
      "description": "Use this gear to initialize BIDS filenames and attributes on all files within a given project.",
      "label": "BIDS Curation",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "curate-bids",
      "source": "https://github.com/flywheel-apps/curate-bids",
      "url": "http://bids.neuroimaging.io/",
      "version": "0.6.7"
    },
    {
      "author": "Flywheel <support@flywheel.io>",
      "command": "python run.py",
      "description": "Use this gear to initialize BIDS filenames and attributes on all files within a given project.",
      "label": "BIDS Curation",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "curate-bids",
      "source": "https://github.com/flywheel-apps/curate-bids",
      "url": "http://bids.neuroimaging.io/",
      "version": "0.6.5"
    },
    {
      "author": "Flywheel <support@flywheel.io>",
      "command": "python run.py",
      "description": "Use this gear to initialize BIDS filenames and attributes on all files within a given project.",
      "label": "BIDS Curation",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "curate-bids",
      "source": "https://github.com/flywheel-apps/curate-bids",
      "url": "http://bids.neuroimaging.io/",
      "version": "0.6.4"
    },
    {
      "author": "Flywheel <support@flywheel.io>",
      "command": "python run.py",
      "description": "Use this gear to initialize BIDS filenames and attributes on all files within a given project.",
      "label": "BIDS Curation",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "curate-bids",
      "source": "https://github.com/flywheel-apps/curate-bids",
      "url": "http://bids.neuroimaging.io/",
      "version": "0.6.3"
    },
    {
      "author": "Flywheel <support@flywheel.io>",
      "description": "Use this gear to initialize BIDS filenames and attributes on all files within a given project.",
      "label": "BIDS Curation",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "curate-bids",
      "source": "https://github.com/flywheel-apps/curate-bids",
      "url": "http://bids.neuroimaging.io/",
      "version": "0.6.2"
    },
    {
      "author": "Flywheel <support@flywheel.io>",
      "description": "Use this gear to initialize BIDS filenames and attributes on all files within a given project.",
      "label": "BIDS Curation",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "curate-bids",
      "source": "https://github.com/flywheel-apps/curate-bids",
      "url": "http://bids.neuroimaging.io/",
      "version": "0.6.0"
    },
    {
      "author": "Flywheel <support@flywheel.io>",
      "description": "Use this gear to initialize BIDS filenames and attributes on all files within a given project.",
      "label": "BIDS Curation",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "curate-bids",
      "source": "https://github.com/flywheel-apps/curate-bids",
      "url": "http://bids.neuroimaging.io/",
      "version": "0.5.0"
    },
    {
      "author": "Flywheel <support@flywheel.io>",
      "description": "Use this gear to initialize BIDS filenames and attributes on all files within a given project.",
      "label": "BIDS Curation",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "curate-bids",
      "source": "https://github.com/flywheel-apps/curate-bids",
      "url": "http://bids.neuroimaging.io/",
      "version": "0.3.6"
    },
    {
      "author": "Flywheel <support@flywheel.io>",
      "description": "Use this gear to initialize BIDS filenames and attributes on all files within a given project.",
      "label": "BIDS Curation",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "curate-bids",
      "source": "https://github.com/flywheel-apps/curate-bids",
      "url": "http://bids.neuroimaging.io/",
      "version": "0.3.5"
    },
    {
      "author": "Flywheel <support@flywheel.io>",
      "description": "Use this gear to initialize BIDS filenames and attributes on all files within a given project.",
      "label": "BIDS Curation",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "curate-bids",
      "source": "https://github.com/flywheel-apps/curate-bids",
      "url": "http://bids.neuroimaging.io/",
      "version": "0.3.4"
    },
    {
      "author": "Flywheel <support@flywheel.io>",
      "description": "Use this gear to initialize BIDS filenames and attributes on all files within a given project.",
      "label": "BIDS Curation",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "curate-bids",
      "source": "https://github.com/flywheel-apps/curate-bids",
      "url": "http://bids.neuroimaging.io/",
      "version": "0.3.3"
    },
    {
      "author": "Flywheel <support@flywheel.io>",
      "description": "Use this gear to initialize BIDS filenames and attributes on all files within a given project.",
      "label": "BIDS Curation",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "curate-bids",
      "source": "https://github.com/flywheel-apps/curate-bids",
      "url": "http://bids.neuroimaging.io/",
      "version": "0.3.2"
    },
    {
      "author": "Flywheel <support@flywheel.io>",
      "description": "Use this gear to initialize BIDS filenames and attributes on all files within a given project.",
      "label": "BIDS Curation",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "curate-bids",
      "source": "https://github.com/flywheel-apps/curate-bids",
      "url": "http://bids.neuroimaging.io/",
      "version": "0.3.1"
    },
    {
      "author": "Flywheel <support@flywheel.io>",
      "description": "Use this gear to initialize BIDS filenames and attributes on all files within a given project.",
      "label": "BIDS Curation",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "curate-bids",
      "source": "https://github.com/flywheel-apps/curate-bids",
      "url": "http://bids.neuroimaging.io/",
      "version": "0.3.0"
    },
    {
      "author": "Flywheel <support@flywheel.io>",
      "description": "Use this gear to initialize BIDS filenames and attributes on all files within a given project.",
      "label": "BIDS Curation",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "curate-bids",
      "source": "https://github.com/flywheel-apps/curate-bids",
      "url": "http://bids.neuroimaging.io/",
      "version": "0.2.0"
    },
    {
      "author": "Flywheel <support@flywheel.io>",
      "description": "Use this gear to initialize BIDS filenames and attributes on all files within a given project.",
      "label": "BIDS Curation",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "curate-bids",
      "source": "https://github.com/flywheel-apps/curate-bids",
      "url": "http://bids.neuroimaging.io/",
      "version": "0.1.0"
    }
  ],
  [
    {
      "author": "Scientific Transparency (RF Dougherty, K Hahn, R Bowen, G Schaefer, LM Perry)",
      "description": "DCM-CONVERT uses SciTran's data library (https://github.com/scitran/data) to convert raw DICOM data (zip archive) to NIfTI, Montage, and PNG (screenshot acquisitions) formats. DCM-CONVERT supports Siemens and GE DICOM data.",
      "label": "SciTran: DCM-CONVERT - DICOM conversion tool",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm-convert",
      "source": "https://github.com/scitran-apps/dcm-convert",
      "url": "https://github.com/scitran/data",
      "version": "1.1.3"
    },
    {
      "author": "Scientific Transparency (RF Dougherty, K Hahn, R Bowen, G Schaefer, LM Perry)",
      "description": "DCM-CONVERT uses SciTran's data library (https://github.com/scitran/data) to convert raw DICOM data (zip archive) to NIfTI, Montage, and PNG (screenshot acquisitions) formats. DCM-CONVERT supports Siemens and GE DICOM data.",
      "label": "SciTran: DCM-CONVERT - DICOM conversion tool",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm-convert",
      "source": "https://github.com/scitran-apps/dcm-convert",
      "url": "https://github.com/scitran/data",
      "version": "1.1.2"
    },
    {
      "author": "Scientific Transparency (RF Dougherty, K Hahn, R Bowen, G Schaefer, LM Perry)",
      "description": "Uses SciTran's data library (https://github.com/scitran/data) to convert raw DICOM data to a Montage. Can be configured to optionally convert data to NIfTI, or PNG (screenshots) format. Supports Siemens or GE DICOM data.",
      "label": "SciTran: DCM-CONVERT - DICOM conversion tool",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm-convert",
      "source": "https://github.com/scitran-apps/dcm-convert",
      "url": "https://github.com/scitran/data",
      "version": "1.1.1"
    },
    {
      "author": "Scientific Transparency (RF Dougherty, K Hahn, R Bowen, G Schaefer, LM Perry)",
      "description": "Uses SciTran's data library (https://github.com/scitran/data) to convert raw DICOM data to a Montage. Can be configured to optionally convert data to NIfTI, or PNG (screenshots) format. Supports Siemens or GE DICOM data.",
      "label": "SciTran: DCM-CONVERT - DICOM conversion tool",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm-convert",
      "source": "https://github.com/scitran-apps/dcm-convert",
      "url": "https://github.com/scitran/data",
      "version": "1.1.0"
    },
    {
      "author": "Scientific Transparency (RF Dougherty, K Hahn, R Bowen, LM Perry)",
      "description": "Uses SciTran's data library (https://github.com/scitran/data) to convert raw DICOM data to a Montage. Can be configured to optionally convert data to NIfTI, or PNG (screenshots) format. Supports Siemens or GE DICOM data.",
      "label": "SciTran: dcm-convert - DICOM conversion tool",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm-convert",
      "source": "https://github.com/scitran-apps/dcm-convert",
      "url": "https://github.com/scitran/data",
      "version": "1.0.0"
    }
  ],
  [
    {
      "author": "Chris Rorden",
      "description": "Chris Rorden's dcm2nii (4AUGUST2014 64-bit) is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2nii works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NII: v.4AUGUST2014",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2nii",
      "source": "https://github.com/scitran-apps/dcm2nii",
      "url": "https://www.nitrc.org/projects/dcm2nii/",
      "version": "0.1.0"
    }
  ],
  [
    {
      "author": "Flywheel",
      "cite": "dcm2niix doi: 10.1016/j.jneumeth.2016.03.001 & PyDeface doi: 10.5281/zenodo.3524401",
      "command": "python3 run.py",
      "description": "Implementation of Chris Rorden's dcm2niix tool for converting DICOM (or PAR/REC) to NIfTI (or NRRD), with an optional implementation of Poldrack Lab's PyDeface to remove facial structures from NIfTI.",
      "environment": {
        "FSLDIR": "/usr/share/fsl/5.0",
        "FSLOUTPUTTYPE": "NIFTI_GZ",
        "LD_LIBRARY_PATH": "/usr/lib/fsl/5.0",
        "PATH": "/usr/lib/fsl/5.0:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
      },
      "label": "dcm2niix: DICOM to NIfTI conversion (with PyDeface)",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "dcm2niix",
      "source": "https://github.com/flywheel-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix",
      "version": "1.2.1_1.0.20201102"
    },
    {
      "author": "Flywheel",
      "cite": "dcm2niix doi: 10.1016/j.jneumeth.2016.03.001 & PyDeface doi: 10.5281/zenodo.3524401",
      "command": "python3 run.py",
      "description": "Implementation of Chris Rorden's dcm2niix tool for converting DICOM (or PAR/REC) to NIfTI (or NRRD), with an optional implementation of Poldrack Lab's PyDeface to remove facial structures from NIfTI.",
      "environment": {
        "FSLDIR": "/usr/share/fsl/5.0",
        "FSLOUTPUTTYPE": "NIFTI_GZ",
        "LD_LIBRARY_PATH": "/usr/lib/fsl/5.0",
        "PATH": "/usr/lib/fsl/5.0:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
      },
      "label": "dcm2niix: DICOM to NIfTI conversion (with PyDeface)",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "dcm2niix",
      "source": "https://github.com/flywheel-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix",
      "version": "1.2.0_1.0.20201102"
    },
    {
      "author": "Flywheel",
      "cite": "dcm2niix doi: 10.1016/j.jneumeth.2016.03.001 & PyDeface doi: 10.5281/zenodo.3524401",
      "command": "python3 run.py",
      "description": "Implementation of Chris Rorden's dcm2niix for converting DICOM to NIfTI, with an optional implementation of Poldrack Lab's PyDeface to remove facial structures from NIfTI.",
      "environment": {
        "FSLDIR": "/usr/share/fsl/5.0",
        "FSLOUTPUTTYPE": "NIFTI_GZ",
        "LD_LIBRARY_PATH": "/usr/lib/fsl/5.0",
        "PATH": "/usr/lib/fsl/5.0:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
      },
      "label": "DICOM to NIfTI conversion using dcm2niix with an optional implementation of PyDeface.",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "dcm2niix",
      "source": "https://github.com/flywheel-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix",
      "version": "1.1.0_1.0.20201102"
    },
    {
      "author": "Flywheel",
      "cite": "dcm2niix doi: 10.1016/j.jneumeth.2016.03.001 & PyDeface doi: 10.5281/zenodo.3524401",
      "command": "python3 run.py",
      "description": "Implementation of Chris Rorden's dcm2niix for converting DICOM to NIfTI, with an optional implementation of Poldrack Lab's PyDeface to remove facial structures from NIfTI.",
      "environment": {
        "FSLDIR": "/usr/share/fsl/5.0",
        "FSLOUTPUTTYPE": "NIFTI_GZ",
        "LD_LIBRARY_PATH": "/usr/lib/fsl/5.0",
        "PATH": "/usr/lib/fsl/5.0:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
      },
      "label": "DICOM to NIfTI conversion using dcm2niix with an optional implementation of PyDeface.",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "dcm2niix",
      "source": "https://github.com/flywheel-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix & https://github.com/poldracklab/pydeface",
      "version": "1.0.0_1.0.20200331"
    },
    {
      "author": "Chris Rorden (@neurolabusc)",
      "description": "Chris Rorden's dcm2niix (OpenJPEG build, 64-bit Linux). dcm2niix is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2niix works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NIIX: DICOM to NIfTI converter",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2niix",
      "source": "https://github.com/scitran-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix",
      "version": "0.8.0_1.0.20200331"
    },
    {
      "author": "Chris Rorden (@neurolabusc)",
      "description": "Chris Rorden's dcm2niix (OpenJPEG build, 64-bit Linux). dcm2niix is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2niix works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NIIX: dcm2nii DICOM to NIfTI converter",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2niix",
      "source": "https://github.com/scitran-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix",
      "version": "0.8.0_1.0.20190902"
    },
    {
      "author": "Chris Rorden (@neurolabusc)",
      "description": "Chris Rorden's dcm2niix (OpenJPEG build, 64-bit Linux). dcm2niix is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2niix works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NIIX: dcm2nii DICOM to NIfTI converter",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2niix",
      "source": "https://github.com/scitran-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix",
      "version": "0.7.9_1.0.20190410"
    },
    {
      "author": "Chris Rorden (@neurolabusc)",
      "description": "Chris Rorden's dcm2niix (OpenJPEG build, 64-bit Linux). dcm2niix is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2niix works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NIIX: dcm2nii DICOM to NIfTI converter",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2niix",
      "source": "https://github.com/scitran-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix",
      "version": "0.7.8_1.0.20190410"
    },
    {
      "author": "Chris Rorden (@neurolabusc)",
      "description": "Chris Rorden's dcm2niix (OpenJPEG build, 64-bit Linux). dcm2niix is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2niix works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NIIX: dcm2nii DICOM to NIfTI converter",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2niix",
      "source": "https://github.com/scitran-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix",
      "version": "0.7.8_1.0.20181114"
    },
    {
      "author": "Chris Rorden (@neurolabusc)",
      "description": "Chris Rorden's dcm2niiX (OpenJPEG build, 64-bit Linux). dcm2niix is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2niix works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NIIX: dcm2nii DICOM to NIfTI converter",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2niix",
      "source": "https://github.com/scitran-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix",
      "version": "0.7.7_1.0.20181114"
    },
    {
      "author": "Chris Rorden (@neurolabusc)",
      "description": "Chris Rorden's dcm2niiX (OpenJPEG build, 64-bit Linux). dcm2niix is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2niix works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NIIX: dcm2nii DICOM to NIfTI converter",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2niix",
      "source": "https://github.com/scitran-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix",
      "version": "0.7.6_1.0.20180622_5af76a9"
    },
    {
      "author": "Chris Rorden (@neurolabusc)",
      "description": "Chris Rorden's dcm2niiX (OpenJPEG build, 64-bit Linux). dcm2niix is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2niix works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NIIX: dcm2nii DICOM to NIfTI converter",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2niix",
      "source": "https://github.com/scitran-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix",
      "version": "0.7.5_1.0.20180622_5af76a9"
    },
    {
      "author": "Chris Rorden (@neurolabusc)",
      "description": "Chris Rorden's dcm2niiX (OpenJPEG build, 64-bit Linux). dcm2niix is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2niix works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NIIX: dcm2nii DICOM to NIfTI converter",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2niix",
      "source": "https://github.com/scitran-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix",
      "version": "0.7.4_1.0.20180622_5af76a9"
    },
    {
      "author": "Chris Rorden (@neurolabusc)",
      "description": "Chris Rorden's dcm2niiX (OpenJPEG build, 64-bit Linux). dcm2niix is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2niix works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NIIX: dcm2nii DICOM to NIfTI converter",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2niix",
      "source": "https://github.com/scitran-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix",
      "version": "0.7.3_1.0.20180622"
    },
    {
      "author": "Chris Rorden (@neurolabusc)",
      "description": "Chris Rorden's dcm2niiX (OpenJPEG build, 64-bit Linux). dcm2niix is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2niix works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NIIX: dcm2nii DICOM to NIfTI converter",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2niix",
      "source": "https://github.com/scitran-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix",
      "version": "0.7.2_1.0.20180622"
    },
    {
      "author": "Chris Rorden (@neurolabusc)",
      "description": "Chris Rorden's dcm2niiX (OpenJPEG build, 64-bit Linux). dcm2niix is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2niix works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NIIX: dcm2nii DICOM to NIfTI converter",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2niix",
      "source": "https://github.com/scitran-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix",
      "version": "0.7.1_1.0.20180622"
    },
    {
      "author": "Chris Rorden (@neurolabusc)",
      "description": "Chris Rorden's dcm2niix (OpenJPEG build, 64-bit Linux). dcm2niix is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2niix works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NIIX: dcm2nii DICOM to NIfTI converter",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2niix",
      "source": "https://github.com/scitran-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix",
      "version": "0.7.10_1.0.20190410"
    },
    {
      "author": "Chris Rorden (@neurolabusc)",
      "description": "Chris Rorden's dcm2niiX (OpenJPEG build, 64-bit Linux). dcm2niix is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2niix works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NIIX: dcm2nii DICOM to NIfTI converter",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2niix",
      "source": "https://github.com/scitran-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix",
      "version": "0.7.0_1.0.20180622"
    },
    {
      "author": "Chris Rorden (@neurolabusc)",
      "description": "Chris Rorden's dcm2niiX (OpenJPEG build, 64-bit Linux). dcm2niix is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2niix works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NIIX: dcm2nii DICOM to NIfTI converter",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2niix",
      "source": "https://github.com/scitran-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix",
      "version": "0.6.1_1.0.20180622"
    },
    {
      "author": "Chris Rorden (@neurolabusc)",
      "description": "Chris Rorden's dcm2niiX (OpenJPEG build, 64-bit Linux). dcm2niix is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2niix works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NIIX: dcm2nii DICOM to NIfTI converter",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2niix",
      "source": "https://github.com/scitran-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix",
      "version": "0.6.0_1.0.20180622"
    },
    {
      "author": "Chris Rorden (@neurolabusc)",
      "description": "Chris Rorden's dcm2niiX (OpenJPEG build, 64-bit Linux). dcm2niix is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2niix works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NIIX: dcm2nii DICOM to NIfTI converter",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2niix",
      "source": "https://github.com/scitran-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix",
      "version": "0.5.4_1.0.20180328"
    },
    {
      "author": "Chris Rorden (@neurolabusc)",
      "description": "Chris Rorden's dcm2niiX (OpenJPEG build, 64-bit Linux). dcm2niix is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2niix works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NIIX: dcm2nii DICOM to NIfTI converter",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2niix",
      "source": "https://github.com/scitran-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix",
      "version": "0.5.2_1.0.20180328"
    },
    {
      "author": "Chris Rorden (@neurolabusc)",
      "description": "Chris Rorden's dcm2niiX (OpenJPEG build, 64-bit Linux). dcm2niix is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2niix works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NIIX: dcm2nii DICOM to NIfTI converter",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2niix",
      "source": "https://github.com/scitran-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix",
      "version": "0.5.1_1.0.20180328"
    },
    {
      "author": "Chris Rorden (@neurolabusc)",
      "description": "Chris Rorden's dcm2niiX (OpenJPEG build, 64-bit Linux). dcm2niix is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2niix works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NIIX: dcm2nii DICOM to NIfTI converter",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2niix",
      "source": "https://github.com/scitran-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix",
      "version": "0.5.0_1.0.20171215"
    },
    {
      "author": "Chris Rorden (@neurolabusc)",
      "description": "Chris Rorden's dcm2niiX (OpenJPEG build, 64-bit Linux). dcm2niix is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2niix works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NIIX: dcm2nii DICOM to NIfTI converter",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2niix",
      "source": "https://github.com/scitran-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix",
      "version": "0.3.4_1.0.20171215"
    },
    {
      "author": "Chris Rorden (@neurolabusc)",
      "description": "Chris Rorden's dcm2niiX version v1.0.20170923 (OpenJPEG build) GCC4.8.4 (64-bit Linux). dcm2niix is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2niix works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NIIX: v1.0.20170923",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2niix",
      "source": "https://github.com/scitran-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix",
      "version": "0.3.3_1.0.20171215"
    },
    {
      "author": "Chris Rorden (@neurolabusc)",
      "description": "Chris Rorden's dcm2niiX version v1.0.20170923 (OpenJPEG build) GCC4.8.4 (64-bit Linux). dcm2niix is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2niix works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NIIX: v1.0.20170923",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2niix",
      "source": "https://github.com/scitran-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix",
      "version": "0.3.2"
    },
    {
      "author": "Chris Rorden (@neurolabusc)",
      "description": "Chris Rorden's dcm2niiX version v1.0.20170923 (OpenJPEG build) GCC4.8.4 (64-bit Linux). dcm2niix is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2niix works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NIIX: v1.0.20170923",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2niix",
      "source": "https://github.com/scitran-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix",
      "version": "0.3.1"
    },
    {
      "author": "Chris Rorden (@neurolabusc)",
      "description": "Chris Rorden's dcm2niiX version v1.0.20170923 (OpenJPEG build) GCC4.8.4 (64-bit Linux). dcm2niix is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2niix works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NIIX: v1.0.20170923",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2niix",
      "source": "https://github.com/scitran-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix",
      "version": "0.3"
    },
    {
      "author": "Chris Rorden (@neurolabusc)",
      "description": "Chris Rorden's dcm2niiX version v1.0.20170821 (OpenJPEG build) GCC4.8.4 (64-bit Linux). dcm2niix is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2niix works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NIIX: v1.0.20170821",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2niix",
      "source": "https://github.com/scitran-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix",
      "version": "0.2.1"
    },
    {
      "author": "Chris Rorden (@neurolabusc)",
      "description": "Chris Rorden's dcm2niiX version v1.0.20170818 (OpenJPEG build) GCC4.8.4 (64-bit Linux). dcm2niix is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2niix works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NIIX: v1.0.20170818",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2niix",
      "source": "https://github.com/scitran-apps/dcm2niix",
      "url": "https://github.com/rordenlab/dcm2niix",
      "version": "0.2"
    },
    {
      "author": "Chris Rorden",
      "description": "Chris Rorden's dcm2niiX version v1.0.20170130 (64-bit Linux). dcm2niix is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2niix works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NIIX: v1.0.20170130",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2niix",
      "source": "https://github.com/scitran-apps/dcm2niix",
      "url": "https://www.nitrc.org/projects/dcm2nii",
      "version": "0.1.1"
    },
    {
      "author": "Chris Rorden",
      "description": "Chris Rorden's dcm2niiX version v1.0.20170130 (64-bit Linux). dcm2niix is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2niix works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NIIX: v1.0.20170130",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2niix",
      "source": "https://github.com/scitran-apps/dcm2niiix",
      "url": "https://www.nitrc.org/projects/dcm2nii",
      "version": "0.1.0"
    },
    {
      "author": "Chris Rorden",
      "description": "Chris Rorden's dcm2niiX version 6June2016 (64-bit). dcm2niix is a popular tool for converting images from the complicated formats used by scanner manufacturers (DICOM, PAR/REC) to the simple NIfTI format used by many scientific tools. dcm2niix works for all modalities (CT, MRI, PET, SPECT) and sequence types.",
      "label": "DCM2NIIX: v.6June2016",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dcm2niix",
      "source": "https://github.com/scitran-apps/dcm2niiix",
      "url": "https://www.nitrc.org/projects/dcm2nii",
      "version": "0.0.3"
    }
  ],
  [
    {
      "author": "Jennifer Reiter <jenniferreiter@invenshure.com>",
      "description": "This Gear produces a 1GB .txt file.",
      "label": "Debug File Generator: Creating a 1 GB file",
      "license": "Other",
      "maintainer": "Jennifer Reiter <jenniferreiter@invenshure.com>",
      "name": "debug-generatefile",
      "source": "https://github.com/flywheel-apps/debug-generatefile",
      "url": "https://github.com/flywheel-apps/debug-generatefile",
      "version": "0.0.1"
    }
  ],
  [
    {
      "author": "Flywheel, Inc.",
      "command": "poetry run python /flywheel/v0/run.py",
      "description": "Profile-based anonymization and export of files within a project. Files within the source project will be anonymized (according to a required template) and exported to a specified project. Output is a csv file reporting the status of all exported items.",
      "environment": {
        "LANG": "C.UTF-8",
        "PYTHONPATH": "/flywheel/v0"
      },
      "label": "De-identified Export",
      "license": "MIT",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "deid-export",
      "source": "https://gitlab.com/flywheel-io/flywheel-apps/fw-gear-deid-export",
      "url": "https://gitlab.com/flywheel-io/flywheel-apps/fw-gear-deid-export/-/blob/master/README.md",
      "version": "1.0.0"
    }
  ],
  [
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from raw DICOM data. Compatible with Siemens, Philips, and GE DICOMs.",
      "label": "SciTran: DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier/releases",
      "url": "https://github.com/scitran-apps/dicom-mr-classifier",
      "version": "1.3.2"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from raw DICOM data. Compatible with Siemens, Philips, and GE DICOMs.",
      "label": "SciTran: DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier/releases",
      "url": "https://github.com/scitran-apps/dicom-mr-classifier",
      "version": "1.3.1"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from raw DICOM data. Compatible with Siemens, Philips, and GE DICOMs.",
      "label": "SciTran: DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier/releases/tag/1.3.0",
      "url": "https://github.com/scitran-apps/dicom-mr-classifier",
      "version": "1.3.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from raw DICOM data. Compatible with Siemens, Philips, and GE DICOMs.",
      "label": "SciTran: DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "1.2.2"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from raw DICOM data. Compatible with Siemens, Philips, and GE DICOMs.",
      "label": "SciTran: DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "1.2.1"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from raw DICOM data. Compatible with Siemens, Philips, and GE DICOMs.",
      "label": "SciTran: DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "1.2.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from raw DICOM data. Compatible with Siemens, Philips, and GE DICOMs.",
      "label": "SciTran: DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "1.1.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from raw DICOM data. Compatible with Siemens, Philips, and GE DICOMs.",
      "label": "SciTran: DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "1.0.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from raw DICOM data. Compatible with Siemens, Philips, and GE DICOMs.",
      "label": "SciTran: DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.9.1"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from raw DICOM data. Compatible with Siemens, Philips, and GE DICOMs.",
      "label": "SciTran: DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.9.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from raw DICOM data. Compatible with Siemens, Philips, and GE DICOMs.",
      "label": "SciTran: DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.8.2"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from raw DICOM data. Compatible with Siemens, Philips, and GE DICOMs.",
      "label": "SciTran: DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.8.1"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from raw DICOM data. Compatible with Siemens, Philips, and GE DICOMs.",
      "label": "SciTran: DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.8.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from raw DICOM data. Compatible with Siemens, Philips, and GE DICOMs.",
      "label": "SciTran: DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.7.6"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from raw DICOM data. Compatible with Siemens, Philips, and GE DICOMs.",
      "label": "SciTran: DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.7.5"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from raw DICOM data. Compatible with Siemens, Philips, and GE DICOMs.",
      "label": "SciTran DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.7.4"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from raw DICOM data. Compatible with Siemens, Philips, and GE DICOMs.",
      "label": "SciTran DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.7.3"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from raw DICOM data. Compatible with Siemens, Philips, and GE DICOMs.",
      "label": "SciTran DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.7.1"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from raw DICOM data. Compatible with Siemens, Philips, and GE DICOMs.",
      "label": "SciTran DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.7.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from raw DICOM data. Compatible with Siemens, Philips, and GE DICOMs.",
      "label": "SciTran DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.6.1"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from raw DICOM data. Compatible with Siemens, Philips, and GE DICOMs.",
      "label": "SciTran DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.6.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata and determine classification from raw DICOM data. Compatible with Siemens, Philips, and GE DICOMs.",
      "label": "SciTran DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.5.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract DICOM header metadata and determine measurement classification. Works with Siemens, Philips, and GE DICOM data.",
      "label": "SciTran DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.4.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract DICOM header metadata and determine measurement classification. Works with Siemens, Philips, and GE DICOM data.",
      "label": "SciTran DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.3.3"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract DICOM header metadata and determine measurement classification. Works with Siemens, Philips, and GE DICOM data.",
      "label": "SciTran DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.3.2"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract DICOM header metadata and determine measurement classification. Works with Siemens, Philips, and GE DICOM data.",
      "label": "SciTran DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.3.1"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract DICOM header metadata and determine measurement classification. Works with Siemens, Philips, and GE DICOM data.",
      "label": "SciTran DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.3.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract DICOM header metadata and determine measurement classification. Works with Siemens, Philips, and GE DICOM data.",
      "label": "SciTran DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.2.7"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract DICOM header metadata and determine measurement classification. Works with Siemens, Philips, and GE DICOM data.",
      "label": "SciTran DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.2.6"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract DICOM header metadata and determine measurement classification. Works with Siemens, Philips, and GE DICOM data.",
      "label": "SciTran DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.2.5"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract DICOM header metadata and determine measurement classification. Works with Siemens, Philips, and GE DICOM data.",
      "label": "SciTran DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.2.4"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata from raw DICOM data from Siemens, Philips, or GE.",
      "label": "SciTran DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.2.3"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata from raw DICOM data from Siemens, Philips, or GE.",
      "label": "SciTran DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.2.2"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata from raw DICOM data from Siemens, Philips, or GE.",
      "label": "SciTran DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.2.1"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata from raw DICOM data from Siemens, Philips, or GE.",
      "label": "SciTran DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.2"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata from raw DICOM data from Siemens, Philips, or GE.",
      "label": "SciTran DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.1.9"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata from raw DICOM data from Siemens, Philips, or GE.",
      "label": "SciTran DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.1.8"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata from raw DICOM data from Siemens, Philips, or GE.",
      "label": "SciTran DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.1.12"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata from raw DICOM data from Siemens, Philips, or GE.",
      "label": "SciTran DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.1.11"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata from raw DICOM data from Siemens, Philips, or GE.",
      "label": "SciTran DICOM MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dicom-mr-classifier",
      "source": "https://github.com/scitran-apps/dicom-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.1.10"
    }
  ],
  [
    {
      "author": "Flywheel",
      "command": "python3 run.py",
      "description": "DICOM Send utilizes DCMTK's storescu to send DICOM data from a Flywheel instance to a destination DICOM server, hosted externally. This Gear supports the transmission of individual DICOM files and archives, as well as the transmission of an entire session when a specific input is not provided. Note that a private tag is added to each DICOM file to be transmitted (Flywheel:DICOM Send, at group 0x0021). Importantly, the external DICOM server must be reachable from the engine host of the Flywheel instance.",
      "label": "DCMTK: DICOM Send",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "dicom-send",
      "source": "https://github.com/flywheel-apps/dicom-send",
      "url": "http://support.dcmtk.org/docs/storescu.html",
      "version": "1.1.2"
    },
    {
      "author": "Flywheel",
      "command": "python3 run.py",
      "description": "DICOM Send utilizes DCMTK's storescu to send DICOM data from a Flywheel instance to a destination DICOM server, hosted externally. This Gear supports the transmission of individual DICOM files and archives, as well as the transmission of an entire session when a specific input is not provided. Note that a private tag is added to each DICOM file to be transmitted (Flywheel:DICOM Send, at group 0x0021). Importantly, the external DICOM server must be reachable from the engine host of the Flywheel instance.",
      "label": "DCMTK: DICOM Send",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "dicom-send",
      "source": "https://github.com/flywheel-apps/dicom-send",
      "url": "http://support.dcmtk.org/docs/storescu.html",
      "version": "1.1.1"
    },
    {
      "author": "Flywheel",
      "command": "python3 run.py",
      "description": "DICOM Send utilizes DCMTK's storescu to send DICOM data from a Flywheel instance to a destination DICOM server, hosted externally. This Gear supports the transmission of individual DICOM files and archives, as well as the transmission of an entire session when a specific input is not provided. Note that a private tag is added to each DICOM file to be transmitted (Flywheel:DICOM Send, at group 0x0021). Importantly, the external DICOM server must be reachable from the engine host of the Flywheel instance.",
      "label": "DCMTK: DICOM Send",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "dicom-send",
      "source": "https://github.com/flywheel-apps/dicom-send",
      "url": "http://support.dcmtk.org/docs/storescu.html",
      "version": "1.1.0"
    },
    {
      "author": "Flywheel",
      "command": "python3 run.py",
      "description": "DICOM Send utilizes DCMTK's storescu to send DICOM data from a Flywheel instance to a destination DICOM server, hosted externally. This Gear supports the transmission of individual DICOM files and archives, as well as the transmission of an entire session when a specific input is not provided. Note that a private tag is added to each DICOM file to be transmitted (Flywheel:DICOM Send, at group 0x0021). Importantly, the external DICOM server must be reachable from the engine host of the Flywheel instance.",
      "label": "DCMTK: DICOM Send",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "dicom-send",
      "source": "https://github.com/flywheel-apps/dicom-send",
      "url": "http://support.dcmtk.org/docs/storescu.html",
      "version": "1.0.0"
    },
    {
      "author": "Imad Nijim",
      "description": "The DICOM Send Gear uses DCMTK dcmstoresu to send DICOM data from Flywheel to a DICOM server.  The DICOM server must be reachable from the host of the Flywheel instance.",
      "label": "DICOM Send",
      "license": "Other",
      "maintainer": "support@flywheel.io",
      "name": "dicom-send",
      "source": "https://flywheel.io",
      "url": "http://support.dcmtk.org/docs/storescu.html",
      "version": "0.9"
    },
    {
      "author": "Imad Nijim",
      "description": "The DICOM Send Gear uses DCMTK dcmstoresu to send DICOM data from Flywheel to a DICOM server.  The DICOM server must be reachable from the host of the Flywheel instance.",
      "label": "DICOM Send",
      "license": "Other",
      "maintainer": "support@flywheel.io",
      "name": "dicom-send",
      "source": "https://flywheel.io",
      "url": "http://support.dcmtk.org/docs/storescu.html",
      "version": "0.6.2"
    },
    {
      "author": "Flywheel",
      "description": "The DICOM Send Gear uses DCMTK storescu to send DICOM data from a Flywheel instance to a DICOM server. The DICOM server must be reachable from the host of the Flywheel instance.",
      "label": "DCMTK: DICOM Send - storescu",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "dicom-send",
      "source": "https://flywheel.io",
      "url": "http://support.dcmtk.org/docs/storescu.html",
      "version": "0.14.1"
    },
    {
      "author": "Flywheel",
      "description": "The DICOM Send Gear uses DCMTK storescu to send DICOM data from a Flywheel instance to a DICOM server. The DICOM server must be reachable from the host of the Flywheel instance.",
      "label": "DCMTK: DICOM Send - storescu",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "dicom-send",
      "source": "https://flywheel.io",
      "url": "http://support.dcmtk.org/docs/storescu.html",
      "version": "0.14.0"
    },
    {
      "author": "Flywheel",
      "description": "The DICOM Send Gear uses DCMTK storescu to send DICOM data from a Flywheel instance to a DICOM server. The DICOM server must be reachable from the host of the Flywheel instance.",
      "label": "DCMTK: DICOM Send - storescu",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "dicom-send",
      "source": "https://flywheel.io",
      "url": "http://support.dcmtk.org/docs/storescu.html",
      "version": "0.13.0"
    },
    {
      "author": "Flywheel",
      "description": "The DICOM Send Gear uses DCMTK storescu to send DICOM data from a Flywheel instance to a DICOM server. The DICOM server must be reachable from the host of the Flywheel instance.",
      "label": "DCMTK: DICOM Send - storescu",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "dicom-send",
      "source": "https://flywheel.io",
      "url": "http://support.dcmtk.org/docs/storescu.html",
      "version": "0.12.0"
    },
    {
      "author": "Flywheel",
      "description": "The DICOM Send Gear uses DCMTK storescu to send DICOM data from a Flywheel instance to a DICOM server. The DICOM server must be reachable from the host of the Flywheel instance.",
      "label": "DCMTK: DICOM Send - storescu",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "dicom-send",
      "source": "https://flywheel.io",
      "url": "http://support.dcmtk.org/docs/storescu.html",
      "version": "0.11.0"
    },
    {
      "author": "Flywheel",
      "description": "The DICOM Send Gear uses DCMTK storescu to send DICOM data from a Flywheel instance to a DICOM server. The DICOM server must be reachable from the host of the Flywheel instance.",
      "label": "DCMTK: DICOM Send - storescu",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "dicom-send",
      "source": "https://flywheel.io",
      "url": "http://support.dcmtk.org/docs/storescu.html",
      "version": "0.10.0"
    }
  ],
  [
    {
      "author": "Brian Wandell <wandell@stanford.edu>, Michael Perry <lmperry@stanford.edu>",
      "description": "Find RMSE between the measured and ADC (or dSIG) based on tensor model. Calculate the histogram of differences between dti based predictions (ADC or dSig) with the actual ADC or dSig data. Larger deviations suggest noisier data.",
      "label": "VISTALAB: DTI Error",
      "license": "GPL-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dti-error",
      "source": "https://github.com/scitran-apps/dtiError/src",
      "url": "https://github.com/scitran-apps/dtiError",
      "version": "0.1.0"
    }
  ],
  [
    {
      "author": "VISTA Lab, Stanford University",
      "description": "VISTALAB's dtiInit (DTI Initialization) runs the VISTASOFT/mrDiffusion pre-processing pipeline on raw DWI data. This Gear allows all dtiInit parameters to be set from within the configuration UI. All outputs are archived in a zip file for easy download. dtiInit.json is saved for easy reference to configuration parameters used at runtime.",
      "label": "VISTALAB: dtiInit - Diffusion Data Initialization Pipeline",
      "license": "GPL-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dtiinit",
      "source": "https://github.com/scitran-apps/dtiinit",
      "url": "https://github.com/vistalab/vistasoft/wiki/dwi-Initialization",
      "version": "0.2.2"
    },
    {
      "author": "Stanford VISTA Lab",
      "description": "VISTALAB's dtiInit (DTI Initialization) runs the VISTASOFT/mrDiffusion pre-processing pipeline on raw DWI data. This Gear allows all dtiInit parameters to be set from within the configuration UI. All outputs are archived in a zip file for easy download. dtiInit.json is saved for easy reference to configuration parameters used at runtime.",
      "label": "VISTALAB: dtiInit - Diffusion Data Initialization Pipeline",
      "license": "GPL-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dtiinit",
      "source": "https://github.com/scitran-apps/dtiinit",
      "url": "https://github.com/vistalab/vistasoft/wiki/dwi-Initialization",
      "version": "0.2.1"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "dtiInit (DTI Initialization) runs the VISTASOFT/mrDiffusion pre-processing pipeline on raw DWI data. See: http://white.stanford.edu/newlm/index.php/DTI_Preprocessing for more information regarding the pipeline. This dtiInit gear will output motion-corrected diffusion data (nifti, bval, bvecs) aligned to the first b0 image in the acquisition. It will also calculate FA, MD, RD, and AD maps. Tensors, vector RGB, brain mask, white-matter mask, and white-matter probability maps will also be output. All outputs will be included in a zip file.",
      "label": "Diffusion Data Initialization Pipeline",
      "license": "GPL-2.0",
      "name": "dtiinit",
      "source": "https://github.com/scitran-apps/dtiinit",
      "url": "https://github.com/vistalab/vistasoft/wiki",
      "version": "0.1.2"
    }
  ],
  [
    {
      "author": "Stanford VISTA Lab (vistalab.stanford.edu)",
      "command": "/usr/local/bin/run_dtiinitDiffusionMaps.sh /opt/mcr/v92 /flywheel/v0/config.json",
      "description": "Generate diffusion maps, including Fractional Anisotropy (FA), Axial Diffusivity (AD), Mean Diffusivity (MD), and Radial Diffusivity (RD). The input to this Gear is a dtiInit archive, containing a 'dt6.mat' file. This archive is generated from either the dtiInit Flywheel Gear, or from the Flywheel Gear which executes the AFQ processing pipeline. Outputs are fa, md, rd, and ad files (in gzipped NIfTI format).",
      "environment": {
        "LD_LIBRARY_PATH": "/opt/mcr/v92/runtime/glnxa64:/opt/mcr/v92/bin/glnxa64:/opt/mcr/v92/sys/os/glnxa64",
        "XAPPLRESDIR": "XAPPLRESDIR"
      },
      "label": "dtiInit: Diffusion Map Generation",
      "license": "GPL-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "dtiinit-diffusion-maps",
      "source": "https://github.com/vistalab/fw-gear-dtiinit-diffusion-maps",
      "url": "https://github.com/vistalab/vistasoft/wiki",
      "version": "1.0.0"
    }
  ],
  [
    {
      "author": "GLU <glerma@stanford.edu>",
      "description": "Flips the sign of the the specified B-vector(s).",
      "label": "VISTA Lab: DWI Flip BVEC",
      "license": "MIT",
      "maintainer": "GLU <glerma@stanford.edu>",
      "name": "dwi-flip-bvec",
      "source": "https://github.com/vistalab/dwi-flip-bvec",
      "url": "https://github.com/vistalab/dwi-flip-bvec",
      "version": "1.0.0"
    }
  ],
  [
    {
      "author": "GLU <glerma@stanford.edu>",
      "description": "Extract individual diffusion shells from multi-shell DWI data. Output includes a NIfTI, BVEC, and BVAL file for each diffusion shell found in the data. By default this gear will normalize the bvalues (e.g., b=998 will become b=1000).",
      "label": "SCITRAN: DWI Split Shells",
      "license": "MIT",
      "maintainer": "GLU <glerma@stanford.edu>",
      "name": "dwi-split-shells",
      "source": "https://github.com/scitran-apps/dwi-split-shells",
      "url": "https://github.com/scitran-apps/dwi-split-shells",
      "version": "2.0.0"
    },
    {
      "author": "GLU <glerma@stanford.edu>",
      "description": "Extract individual diffusion shells from multi-shell DWI data. Output includes a NIfTI, BVEC, and BVAL file for each diffusion shell found in the data.",
      "label": "SCITRAN: DWI Split Shells",
      "license": "MIT",
      "maintainer": "GLU <glerma@stanford.edu>",
      "name": "dwi-split-shells",
      "source": "https://github.com/scitran-apps/dwi-split-shells",
      "url": "https://github.com/scitran-apps/dwi-split-shells",
      "version": "1.1.0"
    },
    {
      "author": "GLU <glerma@stanford.edu>",
      "description": "Extracts individual shells from multi-shell DWI images. Automatically outputs a NIfTI, BVEC, and BVAL file for each shell.",
      "label": "SCITRAN: DWI Split Shells",
      "license": "MIT",
      "maintainer": "GLU <glerma@stanford.edu>",
      "name": "dwi-split-shells",
      "source": "https://github.com/scitran-apps/dwi-split-shells",
      "url": "https://github.com/scitran-apps/dwi-split-shells",
      "version": "1.0.0"
    }
  ],
  [
    {
      "author": "Travis Richardson",
      "description": "Classifies Brain Vision EEG data and appends metadata attributes to the file's custom info structure within Flywheel. Input to this gear is a Flywheel packaged EEG archive (.eeg.zip) containing Brain Vision EEG data (in .vhdr format). Output is a JSON file (.metadata.json) containing metadata that will be used by the Flywheel platform to populate the input file's custom info fields.",
      "label": "Brain Vision EEG Classifier",
      "license": "MIT",
      "maintainer": "Travis Richardson",
      "name": "eeg-classifier",
      "source": "https://github.com/flywheel-apps/eeg-classifier",
      "url": "https://github.com/flywheel-apps/eeg-classifier",
      "version": "1.0.0"
    }
  ],
  [
    {
      "author": "E. Auerbach, CMRR, 2016",
      "command": "python /flywheel/v0/run.py",
      "description": "Extract physiological log files from encoded '_PHYSIO' DICOM file generated by CMRR MB sequences (>=R015, >=VD13A), Generate BIDs compliant files if desired",
      "label": "CMRR: Extract CMRR Physio",
      "license": "MIT",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "extract-cmrr-physio",
      "source": "https://github.com/flywheel-apps/extract-cmrr-physio/releases",
      "url": "https://github.com/CMRR-C2P/MB",
      "version": "1.2.4"
    },
    {
      "author": "E. Auerbach, CMRR, 2016",
      "command": "python /flywheel/v0/run.py",
      "description": "Extract physiological log files from encoded '_PHYSIO' DICOM file generated by CMRR MB sequences (>=R015, >=VD13A), Generate BIDs compliant files if desired",
      "label": "CMRR: Extract CMRR Physio",
      "license": "MIT",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "extract-cmrr-physio",
      "source": "https://github.com/flywheel-apps/extract-cmrr-physio/releases",
      "url": "https://github.com/CMRR-C2P/MB",
      "version": "1.2.3"
    },
    {
      "author": "E. Auerbach, CMRR, 2016",
      "command": "python /flywheel/v0/run.py",
      "description": "Extract physiological log files from encoded '_PHYSIO' DICOM file generated by CMRR MB sequences (>=R015, >=VD13A), Generate BIDs compliant files if desired",
      "label": "CMRR: Extract CMRR Physio",
      "license": "MIT",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "extract-cmrr-physio",
      "source": "https://github.com/flywheel-apps/extract-cmrr-physio/releases/tag/1.2.2",
      "url": "https://github.com/CMRR-C2P/MB",
      "version": "1.2.2"
    },
    {
      "author": "E. Auerbach, CMRR, 2016",
      "command": "python /flywheel/v0/run.py",
      "description": "Extract physiological log files from encoded '_PHYSIO' DICOM file generated by CMRR MB sequences (>=R015, >=VD13A), Generate BIDs compliant files if desired",
      "label": "CMRR: Extract CMRR Physio",
      "license": "MIT",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "extract-cmrr-physio",
      "source": "https://github.com/flywheel-apps/extract-cmrr-physio/releases/tag/1.1.0",
      "url": "https://github.com/CMRR-C2P/MB",
      "version": "1.2.1"
    },
    {
      "author": "E. Auerbach, CMRR, 2016",
      "command": "python /flywheel/v0/run.py",
      "description": "Extract physiological log files from encoded '_PHYSIO' DICOM file generated by CMRR MB sequences (>=R015, >=VD13A), Generate BIDs compliant files if desired",
      "label": "CMRR: Extract CMRR Physio",
      "license": "MIT",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "extract-cmrr-physio",
      "source": "https://github.com/flywheel-apps/extract-cmrr-physio/releases/tag/1.0.0",
      "url": "https://github.com/CMRR-C2P/MB",
      "version": "1.0.0"
    },
    {
      "author": "E. Auerbach, CMRR, 2016",
      "description": "Extract physiological log files from encoded '_PHYSIO' DICOM file generated by CMRR MB sequences (>=R015, >=VD13A)",
      "label": "CMRR: Extract CMRR Physio",
      "license": "MIT",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "extract-cmrr-physio",
      "source": "https://github.com/flywheel-apps/extract-cmrr-physio",
      "url": "https://github.com/CMRR-C2P/MB",
      "version": "0.1.1"
    },
    {
      "author": "E. Auerbach, CMRR, 2016",
      "description": "Extract physiological log files from encoded '_PHYSIO' DICOM file generated by CMRR MB sequences (>=R015, >=VD13A)",
      "label": "CMRR: Extract CMRR Physio",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "extract-cmrr-physio",
      "source": "https://github.com/flywheel-apps/extract-cmrr-physio",
      "url": "https://github.com/CMRR-C2P/MB",
      "version": "0.1"
    }
  ],
  [
    {
      "author": "Flywheel",
      "cite": "",
      "command": "poetry run python run.py",
      "description": "Curates a given file, to be used as a gear rule",
      "environment": {},
      "label": "File Curator",
      "license": "MIT",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "file-curator",
      "source": "https://gitlab.com/flywheel-io/flywheel-apps/file-curator",
      "url": "https://gitlab.com/flywheel-io/flywheel-apps/file-curator",
      "version": "0.1.0"
    }
  ],
  [
    {
      "author": "Anthony Stigliani, VPNL, Stanford",
      "cite": "Temporal Processing Capacity in High-Level Visual Cortex Is Domain Specific. Anthony Stigliani, Kevin S. Weiner and Kalanit Grill-Spector. Journal of Neuroscience 9 September 2015, 35 (36) 12412-12424; DOI: https://doi.org/10.1523/JNEUROSCI.4822-14.2015",
      "description": "Automated analysis of fMRI data from fLoc funcional localizer experiment used to define category-selective cortical regions. By default the Gear generates the following voxel-wise parameters maps: Beta values, model residual error, proportion of variance explained, and GLM contrasts (t-values). All parameter maps are saved as .mat and nifti files in session/Inplane/GLMs/ and can be viewed in Vistasoft. The Gear also writes a file named 'fLocAnalysis_log.txt' that logs progress and saves input and glm parameters as fLocAnalysisParams.mat. If there are 10 conditions specified, 15 contrast maps will be generated. 10 maps will contrast each individual condition versus all others. The other 5 maps will contrast conditions 1 and 2 vs all others, 3 and 4 versus all others, and so on. If there are not 10 conditions specified in the parfiles, then the maps generated will contrast each individual condition versus all others.",
      "label": "VPNL: fLoc - Face Localizer Analysis Pipeline",
      "license": "Other",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "floc",
      "source": "https://github.com/VPNL/fLoc",
      "url": "https://github.com/VPNL/fLoc",
      "version": "0.3.0"
    },
    {
      "author": "Anthony Stigliani, VPNL, Stanford",
      "cite": "Temporal Processing Capacity in High-Level Visual Cortex Is Domain Specific. Anthony Stigliani, Kevin S. Weiner and Kalanit Grill-Spector. Journal of Neuroscience 9 September 2015, 35 (36) 12412-12424; DOI: https://doi.org/10.1523/JNEUROSCI.4822-14.2015",
      "description": "Automated analysis of fMRI data from fLoc funcional localizer experiment used to define category-selective cortical regions. By default the Gear generates the following voxel-wise parameters maps: Beta values, model residual error, proportion of variance explained, and GLM contrasts (t-values). All parameter maps are saved as .mat and nifti files in session/Inplane/GLMs/ and can be viewed in Vistasoft. The Gear also writes a file named 'fLocAnalysis_log.txt' that logs progress and saves input and glm parameters as fLocAnalysisParams.mat. If there are 10 conditions specified, 15 contrast maps will be generated. 10 maps will contrast each individual condition versus all others. The other 5 maps will contrast conditions 1 and 2 vs all others, 3 and 4 versus all others, and so on. If there are not 10 conditions specified in the parfiles, then the maps generated will contrast each individual condition versus all others.",
      "label": "VPNL: fLoc - Face Localizer Analysis Pipeline",
      "license": "Other",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "floc",
      "source": "https://github.com/VPNL/fLoc",
      "url": "https://github.com/VPNL/fLoc",
      "version": "0.2.1"
    },
    {
      "author": "Anthony Stigliani, VPNL, Stanford",
      "cite": "Temporal Processing Capacity in High-Level Visual Cortex Is Domain Specific. Anthony Stigliani, Kevin S. Weiner and Kalanit Grill-Spector. Journal of Neuroscience 9 September 2015, 35 (36) 12412-12424; DOI: https://doi.org/10.1523/JNEUROSCI.4822-14.2015",
      "description": "Automated analysis of fMRI data from fLoc funcional localizer experiment used to define category-selective cortical regions. By default the Gear generates the following voxel-wise parameters maps: Beta values, model residual error, proportion of variance explained, and GLM contrasts (t-values). All parameter maps are saved as .mat and nifti files in session/Inplane/GLMs/ and can be viewed in Vistasoft. The Gear also writes a file named 'fLocAnalysis_log.txt' that logs progress and saves input and glm parameters as fLocAnalysisParams.mat. If there are 10 conditions specified, 15 contrast maps will be generated. 10 maps will contrast each individual condition versus all others. The other 5 maps will contrast conditions 1 and 2 vs all others, 3 and 4 versus all others, and so on. If there are not 10 conditions specified in the parfiles, then the maps generated will contrast each individual condition versus all others.",
      "label": "VPNL: fLoc - Face Localizer Analysis Pipeline",
      "license": "Other",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "floc",
      "source": "https://github.com/VPNL/fLoc",
      "url": "https://github.com/VPNL/fLoc",
      "version": "0.2.0"
    },
    {
      "author": "Anthony Stigliani, VPNL, Stanford",
      "cite": "Temporal Processing Capacity in High-Level Visual Cortex Is Domain Specific. Anthony Stigliani, Kevin S. Weiner and Kalanit Grill-Spector. Journal of Neuroscience 9 September 2015, 35 (36) 12412-12424; DOI: https://doi.org/10.1523/JNEUROSCI.4822-14.2015",
      "description": "Automated analysis of fMRI data from fLoc funcional localizer experiment used to define category-selective cortical regions. By default the Gear generates the following voxel-wise parameters maps: Beta values, model residual error, proportion of variance explained, and GLM contrasts (t-values). All parameter maps are saved as .mat and nifti files in session/Inplane/GLMs/ and can be viewed in Vistasoft. The Gear also writes a file named 'fLocAnalysis_log.txt' that logs progress and saves input and glm parameters as fLocAnalysisParams.mat. If there are 10 conditions specified, 15 contrast maps will be generated. 10 maps will contrast each individual condition versus all others. The other 5 maps will contrast conditions 1 and 2 vs all others, 3 and 4 versus all others, and so on. If there are not 10 conditions specified in the parfiles, then the maps generated will contrast each individual condition versus all others.",
      "label": "VPNL: fLoc - Face Localizer Analysis Pipeline",
      "license": "Other",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "floc",
      "source": "https://github.com/VPNL/fLoc",
      "url": "https://github.com/VPNL/fLoc",
      "version": "0.1.0"
    }
  ],
  [
    {
      "author": "Flywheel <support@flywheel.io>",
      "description": "Sample gear to demonstrate a simple use case of outputting the name of each input file.",
      "label": "Flywheel Example Gear",
      "license": "MIT",
      "maintainer": "Ryan Sanford <ryansanford@flywheel.io>",
      "name": "flywheel-example-gear",
      "source": "https://github.com/flywheel-apps/example-gear",
      "url": "https://flywheel.io/",
      "version": "0.0.4"
    },
    {
      "author": "Flywheel <support@flywheel.io>",
      "description": "Sample gear to demonstrate a simple use case of outputting the name of each input file.",
      "label": "Flywheel Example Gear",
      "license": "MIT",
      "maintainer": "Ryan Sanford <ryansanford@flywheel.io>",
      "name": "flywheel-example-gear",
      "source": "https://github.com/flywheel-apps/example-gear",
      "url": "https://flywheel.io/",
      "version": "0.0.3"
    }
  ],
  [
    {
      "author": "Poldrack Lab, Stanford University",
      "cite": "Esteban O, Markiewicz CJ, Blair RW, Moodie CA, Isik AI, Erramuzpe A, Kent JD, Goncalves M, DuPre E, Snyder M, Oya H, Ghosh SS, Wright J, Durnez J, Poldrack RA, Gorgolewski KJ. fMRIPrep: a robust preprocessing pipeline for functional MRI. Nat Meth. 2018; doi:10.1038/s41592-018-0235-4. FOR MORE INFORMATION SEE: http://fmriprep.readthedocs.io/en/stable/citing.html.",
      "command": "/usr/local/miniconda/bin/python3.7 /flywheel/v0/run.py",
      "description": "fmriprep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that can be easily submitted to a variety of group level analyses, including task-based or resting-state fMRI, graph theory measures, surface or volume-based statistics, etc.",
      "label": "fMRIPREP: A Robust Preprocessing Pipeline for fMRI Data",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fmriprep",
      "source": "https://github.com/flywheel-apps/fmriprep",
      "url": "https://fmriprep.readthedocs.io/en/1.5.5/",
      "version": "6.1.2_1.5.5"
    },
    {
      "author": "Poldrack Lab, Stanford University",
      "cite": "Esteban O, Markiewicz CJ, Blair RW, Moodie CA, Isik AI, Erramuzpe A, Kent JD, Goncalves M, DuPre E, Snyder M, Oya H, Ghosh SS, Wright J, Durnez J, Poldrack RA, Gorgolewski KJ. fMRIPrep: a robust preprocessing pipeline for functional MRI. Nat Meth. 2018; doi:10.1038/s41592-018-0235-4. FOR MORE INFORMATION SEE: http://fmriprep.readthedocs.io/en/stable/citing.html.",
      "command": "/usr/local/miniconda/bin/python3.7 /flywheel/v0/run.py",
      "description": "fmriprep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that can be easily submitted to a variety of group level analyses, including task-based or resting-state fMRI, graph theory measures, surface or volume-based statistics, etc.",
      "label": "fMRIPREP: A Robust Preprocessing Pipeline for fMRI Data",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fmriprep",
      "source": "https://github.com/flywheel-apps/fmriprep",
      "url": "https://fmriprep.readthedocs.io/en/1.5.5/",
      "version": "6.1.1_1.5.5"
    },
    {
      "author": "Poldrack Lab, Stanford University",
      "cite": "Esteban O, Markiewicz CJ, Blair RW, Moodie CA, Isik AI, Erramuzpe A, Kent JD, Goncalves M, DuPre E, Snyder M, Oya H, Ghosh SS, Wright J, Durnez J, Poldrack RA, Gorgolewski KJ. fMRIPrep: a robust preprocessing pipeline for functional MRI. Nat Meth. 2018; doi:10.1038/s41592-018-0235-4. FOR MORE INFORMATION SEE: http://fmriprep.readthedocs.io/en/stable/citing.html.",
      "command": "/usr/local/miniconda/bin/python3.7 /flywheel/v0/run.py",
      "description": "fmriprep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that can be easily submitted to a variety of group level analyses, including task-based or resting-state fMRI, graph theory measures, surface or volume-based statistics, etc.",
      "label": "fMRIPREP: A Robust Preprocessing Pipeline for fMRI Data",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fmriprep",
      "source": "https://github.com/flywheel-apps/fmriprep",
      "url": "https://fmriprep.readthedocs.io/en/1.5.5/",
      "version": "6.0.0_1.5.5"
    },
    {
      "author": "Poldrack Lab, Stanford University",
      "cite": "Esteban O, Markiewicz CJ, Blair RW, Moodie CA, Isik AI, Erramuzpe A, Kent JD, Goncalves M, DuPre E, Snyder M, Oya H, Ghosh SS, Wright J, Durnez J, Poldrack RA, Gorgolewski KJ. fMRIPrep: a robust preprocessing pipeline for functional MRI. Nat Meth. 2018; doi:10.1038/s41592-018-0235-4. FOR MORE INFORMATION SEE: http://fmriprep.readthedocs.io/en/stable/citing.html.",
      "description": "fmriprep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that can be easily submitted to a variety of group level analyses, including task-based or resting-state fMRI, graph theory measures, surface or volume-based statistics, etc.",
      "label": "fMRIPREP: A Robust Preprocessing Pipeline for fMRI Data",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fmriprep",
      "source": "https://github.com/flywheel-apps/fmriprep",
      "url": "https://fmriprep.readthedocs.io/en/1.2.6-1/",
      "version": "5.7.1_1.2.6-1"
    },
    {
      "author": "Poldrack Lab, Stanford University",
      "cite": "Esteban O, Markiewicz CJ, Blair RW, Moodie CA, Isik AI, Erramuzpe A, Kent JD, Goncalves M, DuPre E, Snyder M, Oya H, Ghosh SS, Wright J, Durnez J, Poldrack RA, Gorgolewski KJ. fMRIPrep: a robust preprocessing pipeline for functional MRI. Nat Meth. 2018; doi:10.1038/s41592-018-0235-4. FOR MORE INFORMATION SEE: http://fmriprep.readthedocs.io/en/stable/citing.html.",
      "description": "fmriprep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that can be easily submitted to a variety of group level analyses, including task-based or resting-state fMRI, graph theory measures, surface or volume-based statistics, etc.",
      "label": "fMRIPREP: A Robust Preprocessing Pipeline for fMRI Data",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fmriprep",
      "source": "https://github.com/flywheel-apps/fmriprep",
      "url": "https://fmriprep.readthedocs.io/en/1.2.6-1/",
      "version": "5.7.0_1.2.6-1"
    },
    {
      "author": "Poldrack Lab, Stanford University",
      "cite": "Esteban O, Markiewicz CJ, Blair RW, Moodie CA, Isik AI, Erramuzpe A, Kent JD, Goncalves M, DuPre E, Snyder M, Oya H, Ghosh SS, Wright J, Durnez J, Poldrack RA, Gorgolewski KJ. fMRIPrep: a robust preprocessing pipeline for functional MRI. Nat Meth. 2018; doi:10.1038/s41592-018-0235-4. FOR MORE INFORMATION SEE: http://fmriprep.readthedocs.io/en/stable/citing.html.",
      "description": "fmriprep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that can be easily submitted to a variety of group level analyses, including task-based or resting-state fMRI, graph theory measures, surface or volume-based statistics, etc.",
      "label": "fMRIPREP: A Robust Preprocessing Pipeline for fMRI Data",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fmriprep",
      "source": "https://github.com/flywheel-apps/fmriprep",
      "url": "https://fmriprep.readthedocs.io/en/1.2.6-1/",
      "version": "5.6.3_1.2.6-1"
    },
    {
      "author": "Poldrack Lab, Stanford University",
      "cite": "Esteban O, Markiewicz CJ, Blair RW, Moodie CA, Isik AI, Erramuzpe A, Kent JD, Goncalves M, DuPre E, Snyder M, Oya H, Ghosh SS, Wright J, Durnez J, Poldrack RA, Gorgolewski KJ. fMRIPrep: a robust preprocessing pipeline for functional MRI. Nat Meth. 2018; doi:10.1038/s41592-018-0235-4. FOR MORE INFORMATION SEE: http://fmriprep.readthedocs.io/en/stable/citing.html.",
      "description": "fmriprep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that can be easily submitted to a variety of group level analyses, including task-based or resting-state fMRI, graph theory measures, surface or volume-based statistics, etc.",
      "label": "fMRIPREP: A Robust Preprocessing Pipeline for fMRI Data",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fmriprep",
      "source": "https://github.com/flywheel-apps/fmriprep",
      "url": "https://fmriprep.readthedocs.io/en/1.2.6-1/",
      "version": "5.6.2_1.2.6-1"
    },
    {
      "author": "Poldrack Lab, Stanford University",
      "cite": "Esteban O, Blair R, Markiewicz CJ, Berleant SL, Moodie C, Ma F, Isik AI, Erramuzpe A, Kent JD, Goncalves M, Poldrack RA, Gorgolewski KJ; poldracklab/fmriprep: 1.0.0-rc9. Zenodo; 2017. doi:10.5281/zenodo.1041020  FOR MORE INFORMATION SEE: http://fmriprep.readthedocs.io/en/stable/citing.html.",
      "description": "fmriprep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that can be easily submitted to a variety of group level analyses, including task-based or resting-state fMRI, graph theory measures, surface or volume-based statistics, etc.",
      "label": "fMRIPREP: A Robust Preprocessing Pipeline for fMRI Data",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fmriprep",
      "source": "https://github.com/flywheel-apps/fmriprep",
      "url": "https://fmriprep.readthedocs.io/en/1.1.4/",
      "version": "5.6.1_1.1.4"
    },
    {
      "author": "Poldrack Lab, Stanford University",
      "cite": "Esteban O, Blair R, Markiewicz CJ, Berleant SL, Moodie C, Ma F, Isik AI, Erramuzpe A, Kent JD, Goncalves M, Poldrack RA, Gorgolewski KJ; poldracklab/fmriprep: 1.0.0-rc9. Zenodo; 2017. doi:10.5281/zenodo.1041020  FOR MORE INFORMATION SEE: http://fmriprep.readthedocs.io/en/stable/citing.html.",
      "description": "fmriprep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that can be easily submitted to a variety of group level analyses, including task-based or resting-state fMRI, graph theory measures, surface or volume-based statistics, etc.",
      "label": "fMRIPREP: A Robust Preprocessing Pipeline for fMRI Data",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fmriprep",
      "source": "https://github.com/flywheel-apps/fmriprep",
      "url": "https://fmriprep.readthedocs.io/en/1.1.4/",
      "version": "5.6.0_1.1.4"
    },
    {
      "author": "Poldrack Lab, Stanford University",
      "cite": "Esteban O, Blair R, Markiewicz CJ, Berleant SL, Moodie C, Ma F, Isik AI, Erramuzpe A, Kent JD, Goncalves M, Poldrack RA, Gorgolewski KJ; poldracklab/fmriprep: 1.0.0-rc9. Zenodo; 2017. doi:10.5281/zenodo.1041020  FOR MORE INFORMATION SEE: http://fmriprep.readthedocs.io/en/stable/citing.html.",
      "description": "fmriprep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that can be easily submitted to a variety of group level analyses, including task-based or resting-state fMRI, graph theory measures, surface or volume-based statistics, etc.",
      "label": "fMRIPREP: A Robust Preprocessing Pipeline for fMRI Data",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fmriprep",
      "source": "https://github.com/flywheel-apps/fmriprep",
      "url": "https://fmriprep.readthedocs.io/en/1.1.4/",
      "version": "5.5.0_1.1.4"
    },
    {
      "author": "Poldrack Lab, Stanford University",
      "cite": "Esteban O, Blair R, Markiewicz CJ, Berleant SL, Moodie C, Ma F, Isik AI, Erramuzpe A, Kent JD, Goncalves M, Poldrack RA, Gorgolewski KJ; poldracklab/fmriprep: 1.0.0-rc9. Zenodo; 2017. doi:10.5281/zenodo.1041020  FOR MORE INFORMATION SEE: http://fmriprep.readthedocs.io/en/stable/citing.html.",
      "description": "fmriprep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that can be easily submitted to a variety of group level analyses, including task-based or resting-state fMRI, graph theory measures, surface or volume-based statistics, etc.",
      "label": "fMRIPREP: A Robust Preprocessing Pipeline for fMRI Data",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fmriprep",
      "source": "https://github.com/flywheel-apps/fmriprep",
      "url": "https://github.com/poldracklab/fmriprep",
      "version": "5.4.2_1.1.2"
    },
    {
      "author": "Poldrack Lab, Stanford University",
      "cite": "Esteban O, Blair R, Markiewicz CJ, Berleant SL, Moodie C, Ma F, Isik AI, Erramuzpe A, Kent JD, Goncalves M, Poldrack RA, Gorgolewski KJ; poldracklab/fmriprep: 1.0.0-rc9. Zenodo; 2017. doi:10.5281/zenodo.1041020  FOR MORE INFORMATION SEE: http://fmriprep.readthedocs.io/en/stable/citing.html.",
      "description": "fmriprep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that can be easily submitted to a variety of group level analyses, including task-based or resting-state fMRI, graph theory measures, surface or volume-based statistics, etc.",
      "label": "fMRIPREP: A Robust Preprocessing Pipeline for fMRI Data",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fmriprep",
      "source": "https://github.com/flywheel-apps/fmriprep",
      "url": "https://github.com/poldracklab/fmriprep",
      "version": "5.4.1_1.1.2"
    },
    {
      "author": "Poldrack Lab, Stanford University",
      "cite": "Esteban O, Blair R, Markiewicz CJ, Berleant SL, Moodie C, Ma F, Isik AI, Erramuzpe A, Kent JD, Goncalves M, Poldrack RA, Gorgolewski KJ; poldracklab/fmriprep: 1.0.0-rc9. Zenodo; 2017. doi:10.5281/zenodo.1041020  FOR MORE INFORMATION SEE: http://fmriprep.readthedocs.io/en/stable/citing.html.",
      "description": "fmriprep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that can be easily submitted to a variety of group level analyses, including task-based or resting-state fMRI, graph theory measures, surface or volume-based statistics, etc.",
      "label": "fMRIPREP: A Robust Preprocessing Pipeline for fMRI Data",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fmriprep",
      "source": "https://github.com/flywheel-apps/fmriprep",
      "url": "https://github.com/poldracklab/fmriprep",
      "version": "5.4.0_1.1.2"
    },
    {
      "author": "Poldrack Lab, Stanford University",
      "cite": "Esteban O, Blair R, Markiewicz CJ, Berleant SL, Moodie C, Ma F, Isik AI, Erramuzpe A, Kent JD, Goncalves M, Poldrack RA, Gorgolewski KJ; poldracklab/fmriprep: 1.0.0-rc9. Zenodo; 2017. doi:10.5281/zenodo.1041020  FOR MORE INFORMATION SEE: http://fmriprep.readthedocs.io/en/stable/citing.html.",
      "description": "fmriprep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that can be easily submitted to a variety of group level analyses, including task-based or resting-state fMRI, graph theory measures, surface or volume-based statistics, etc.",
      "label": "fMRIPREP: A Robust Preprocessing Pipeline for fMRI Data",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fmriprep",
      "source": "https://github.com/flywheel-apps/fmriprep",
      "url": "https://github.com/poldracklab/fmriprep",
      "version": "5.3.0_1.1.2"
    },
    {
      "author": "Poldrack Lab, Stanford University",
      "cite": "Esteban O, Blair R, Markiewicz CJ, Berleant SL, Moodie C, Ma F, Isik AI, Erramuzpe A, Kent JD, Goncalves M, Poldrack RA, Gorgolewski KJ; poldracklab/fmriprep: 1.0.0-rc9. Zenodo; 2017. doi:10.5281/zenodo.1041020",
      "description": "fmriprep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that can be easily submitted to a variety of group level analyses, including task-based or resting-state fMRI, graph theory measures, surface or volume-based statistics, etc.",
      "label": "fMRIPREP: A Robust Preprocessing Pipeline for fMRI Data",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fmriprep",
      "source": "https://github.com/flywheel-apps/fmriprep",
      "url": "https://github.com/poldracklab/fmriprep",
      "version": "5.2.2_1.1.1"
    },
    {
      "author": "Poldrack Lab, Stanford University",
      "cite": "Esteban O, Blair R, Markiewicz CJ, Berleant SL, Moodie C, Ma F, Isik AI, Erramuzpe A, Kent JD, Goncalves M, Poldrack RA, Gorgolewski KJ; poldracklab/fmriprep: 1.0.0-rc9. Zenodo; 2017. doi:10.5281/zenodo.1041020",
      "description": "fmriprep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that can be easily submitted to a variety of group level analyses, including task-based or resting-state fMRI, graph theory measures, surface or volume-based statistics, etc.",
      "label": "fMRIPREP: A Robust Preprocessing Pipeline for fMRI Data",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fmriprep",
      "source": "https://github.com/flywheel-apps/fmriprep",
      "url": "https://github.com/poldracklab/fmriprep",
      "version": "5.2.0_1.0.15"
    },
    {
      "author": "Poldrack Lab, Stanford University",
      "cite": "Esteban O, Blair R, Markiewicz CJ, Berleant SL, Moodie C, Ma F, Isik AI, Erramuzpe A, Kent JD, Goncalves M, Poldrack RA, Gorgolewski KJ; poldracklab/fmriprep: 1.0.0-rc9. Zenodo; 2017. doi:10.5281/zenodo.1041020",
      "description": "fmriprep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that can be easily submitted to a variety of group level analyses, including task-based or resting-state fMRI, graph theory measures, surface or volume-based statistics, etc.",
      "label": "fMRIPREP: A Robust Preprocessing Pipeline for fMRI Data",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fmriprep",
      "source": "https://github.com/flywheel-apps/fmriprep",
      "url": "https://github.com/poldracklab/fmriprep",
      "version": "5.1.0_1.0.15"
    },
    {
      "author": "Poldrack Lab, Stanford University",
      "cite": "Esteban O, Blair R, Markiewicz CJ, Berleant SL, Moodie C, Ma F, Isik AI, Erramuzpe A, Kent JD, Goncalves M, Poldrack RA, Gorgolewski KJ; poldracklab/fmriprep: 1.0.0-rc9. Zenodo; 2017. doi:10.5281/zenodo.1041020",
      "description": "fmriprep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that can be easily submitted to a variety of group level analyses, including task-based or resting-state fMRI, graph theory measures, surface or volume-based statistics, etc.",
      "label": "fMRIPREP: A Robust Preprocessing Pipeline for fMRI Data",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fmriprep",
      "source": "https://github.com/flywheel-apps/fmriprep",
      "url": "https://github.com/poldracklab/fmriprep",
      "version": "5.0.0_1.0.6"
    },
    {
      "author": "Poldrack Lab, Stanford University",
      "cite": "Esteban O, Blair R, Markiewicz CJ, Berleant SL, Moodie C, Ma F, Isik AI, Erramuzpe A, Kent JD, Goncalves M, Poldrack RA, Gorgolewski KJ; poldracklab/fmriprep: 1.0.0-rc9. Zenodo; 2017. doi:10.5281/zenodo.1041020",
      "description": "fmriprep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that can be easily submitted to a variety of group level analyses, including task-based or resting-state fMRI, graph theory measures, surface or volume-based statistics, etc.",
      "label": "fMRIPREP: A Robust Preprocessing Pipeline for fMRI Data",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fmriprep",
      "source": "https://github.com/flywheel-apps/fmriprep",
      "url": "https://github.com/poldracklab/fmriprep",
      "version": "0.4.7_1.0.15"
    },
    {
      "author": "Poldrack Lab, Stanford University",
      "cite": "Esteban O, Blair R, Markiewicz CJ, Berleant SL, Moodie C, Ma F, Isik AI, Erramuzpe A, Kent JD, Goncalves M, Poldrack RA, Gorgolewski KJ; poldracklab/fmriprep: 1.0.0-rc9. Zenodo; 2017. doi:10.5281/zenodo.1041020",
      "description": "fmriprep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that can be easily submitted to a variety of group level analyses, including task-based or resting-state fMRI, graph theory measures, surface or volume-based statistics, etc.",
      "label": "fMRIPREP: A Robust Preprocessing Pipeline for fMRI Data",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fmriprep",
      "source": "https://github.com/flywheel-apps/fmriprep",
      "url": "https://github.com/poldracklab/fmriprep",
      "version": "0.4.6_1.0.15"
    },
    {
      "author": "Poldrack Lab, Stanford University",
      "cite": "Esteban O, Blair R, Markiewicz CJ, Berleant SL, Moodie C, Ma F, Isik AI, Erramuzpe A, Kent JD, Goncalves M, Poldrack RA, Gorgolewski KJ; poldracklab/fmriprep: 1.0.0-rc9. Zenodo; 2017. doi:10.5281/zenodo.1041020",
      "description": "fmriprep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that can be easily submitted to a variety of group level analyses, including task-based or resting-state fMRI, graph theory measures, surface or volume-based statistics, etc.",
      "label": "fMRIPREP: A Robust Preprocessing Pipeline for fMRI Data",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fmriprep",
      "source": "https://github.com/flywheel-apps/fmriprep",
      "url": "https://github.com/poldracklab/fmriprep",
      "version": "0.4.5_1.0.6"
    },
    {
      "author": "Poldrack Lab, Stanford University",
      "cite": "Esteban O, Blair R, Markiewicz CJ, Berleant SL, Moodie C, Ma F, Isik AI, Erramuzpe A, Kent JD, Goncalves M, Poldrack RA, Gorgolewski KJ; poldracklab/fmriprep: 1.0.0-rc9. Zenodo; 2017. doi:10.5281/zenodo.1041020",
      "description": "fmriprep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that can be easily submitted to a variety of group level analyses, including task-based or resting-state fMRI, graph theory measures, surface or volume-based statistics, etc.",
      "label": "fMRIPREP: A Robust Preprocessing Pipeline for fMRI Data",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fmriprep",
      "source": "https://github.com/flywheel-apps/fmriprep",
      "url": "https://github.com/poldracklab/fmriprep",
      "version": "0.4.4_1.0.6"
    },
    {
      "author": "Poldrack Lab, Stanford University",
      "cite": "Esteban O, Blair R, Markiewicz CJ, Berleant SL, Moodie C, Ma F, Isik AI, Erramuzpe A, Kent JD, Goncalves M, Poldrack RA, Gorgolewski KJ; poldracklab/fmriprep: 1.0.0-rc9. Zenodo; 2017. doi:10.5281/zenodo.1041020",
      "description": "fmriprep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that can be easily submitted to a variety of group level analyses, including task-based or resting-state fMRI, graph theory measures, surface or volume-based statistics, etc.",
      "label": "fMRIPREP: A Robust Preprocessing Pipeline for fMRI Data",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fmriprep",
      "source": "https://github.com/flywheel-apps/fmriprep",
      "url": "https://github.com/poldracklab/fmriprep",
      "version": "0.4.3_1.0.6"
    },
    {
      "author": "Poldrack Lab, Stanford University",
      "cite": "Esteban O, Blair R, Markiewicz CJ, Berleant SL, Moodie C, Ma F, Isik AI, Erramuzpe A, Kent JD, Goncalves M, Poldrack RA, Gorgolewski KJ; poldracklab/fmriprep: 1.0.0-rc9. Zenodo; 2017. doi:10.5281/zenodo.1041020",
      "description": "fmriprep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that can be easily submitted to a variety of group level analyses, including task-based or resting-state fMRI, graph theory measures, surface or volume-based statistics, etc.",
      "label": "fMRIPREP: A Robust Preprocessing Pipeline for fMRI Data (1.0.4)",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fmriprep",
      "source": "https://github.com/flywheel-apps/fmriprep",
      "url": "https://github.com/poldracklab/fmriprep",
      "version": "0.4.2"
    },
    {
      "author": "Poldrack Lab, Stanford University",
      "cite": "Esteban O, Blair R, Markiewicz CJ, Berleant SL, Moodie C, Ma F, Isik AI, Erramuzpe A, Kent JD, Goncalves M, Poldrack RA, Gorgolewski KJ; poldracklab/fmriprep: 1.0.0-rc9. Zenodo; 2017. doi:10.5281/zenodo.1041020",
      "description": "fmriprep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that can be easily submitted to a variety of group level analyses, including task-based or resting-state fMRI, graph theory measures, surface or volume-based statistics, etc.",
      "label": "fMRIPREP: A Robust Preprocessing Pipeline for fMRI Data (1.0.0-rc5)",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fmriprep",
      "source": "https://github.com/flywheel-apps/fmriprep",
      "url": "https://github.com/poldracklab/fmriprep",
      "version": "0.3.3"
    },
    {
      "author": "Poldrack lab at Stanford University",
      "description": "fmriprep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to differences in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that make running a variety of group level analyses (task based or resting state fMRI, graph theory measures, surface or volume, etc.) easy.",
      "label": "fMRIPREP: A Robust Preprocessing Pipeline for fMRI Data (1.0.0-rc5)",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fmriprep",
      "source": "https://github.com/flywheel-apps/fmriprep",
      "url": "https://github.com/poldracklab/fmriprep",
      "version": "0.3.2"
    },
    {
      "author": "Poldrack lab at Stanford University",
      "description": "fmriprep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to differences in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that make running a variety of group level analyses (task based or resting state fMRI, graph theory measures, surface or volume, etc.) easy.",
      "label": "fMRIPREP: A Robust Preprocessing Pipeline for fMRI Data (1.0.0-rc5)",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fmriprep",
      "source": "https://github.com/flywheel-apps/fmriprep",
      "url": "https://github.com/poldracklab/fmriprep",
      "version": "0.3"
    },
    {
      "author": "Poldrack lab at Stanford University",
      "description": "fmriprep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to differences in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that make running a variety of group level analyses (task based or resting state fMRI, graph theory measures, surface or volume, etc.) easy.",
      "label": "fMRIPREP: A Robust Preprocessing Pipeline for fMRI Data (1.0.0-rc1)",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fmriprep",
      "source": "https://github.com/flywheel-apps/fmriprep",
      "url": "https://github.com/poldracklab/fmriprep",
      "version": "0.2"
    },
    {
      "author": "Poldrack lab at Stanford University",
      "description": "fmriprep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to differences in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting. It performs basic processing steps (coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc.) providing outputs that make running a variety of group level analyses (task based or resting state fMRI, graph theory measures, surface or volume, etc.) easy.",
      "label": "fMRIPREP: A Robust Preprocessing Pipeline for fMRI Data (1.0.0-rc1)",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fmriprep",
      "source": "https://github.com/flywheel-apps/fmriprep",
      "url": "https://github.com/poldracklab/fmriprep",
      "version": "0.1"
    }
  ],
  [
    {
      "author": "Laboratory for Computational Neuroimaging <freesurfer@nmr.mgh.harvard.edu>",
      "cite": "For citation information, please visit: https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferMethodsCitation.",
      "command": "/root/miniconda3/bin/python3 run.py",
      "description": "FreeSurfer version 7.1.1 Release (July 27, 2020). This gear takes an anatomical NIfTI file and performs all of the FreeSurfer cortical reconstruction process. Outputs are provided in a zip file and include the entire output directory tree from Recon-All. Configuration options exist for setting the subject ID and for converting outputs to NIfTI, OBJ, and CSV. FreeSurfer is a software package for the analysis and visualization of structural and functional neuroimaging data from cross-sectional or longitudinal studies. It is developed by the Laboratory for Computational Neuroimaging at the Athinoula A. Martinos Center for Biomedical Imaging. Please see https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferSoftwareLicense for license information.",
      "environment": {
        "PYTHONUNBUFFERED": "1"
      },
      "label": "FreeSurfer 7.1.1: run recon-all",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "freesurfer-recon-all",
      "source": "https://github.com/flywheel-apps/freesurfer-recon-all",
      "url": "https://surfer.nmr.mgh.harvard.edu",
      "version": "1.1.0_7.1.1"
    },
    {
      "author": "Laboratory for Computational Neuroimaging <freesurfer@nmr.mgh.harvard.edu>",
      "cite": "For citation information, please visit: https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferMethodsCitation.",
      "command": "/root/miniconda3/bin/python3 run.py",
      "description": "FreeSurfer version 7.1.1 Release (July 27, 2020). This gear takes an anatomical NIfTI file and performs all of the FreeSurfer cortical reconstruction process. Outputs are provided in a zip file and include the entire output directory tree from Recon-All. Configuration options exist for setting the subject ID and for converting outputs to NIfTI, OBJ, and CSV. FreeSurfer is a software package for the analysis and visualization of structural and functional neuroimaging data from cross-sectional or longitudinal studies. It is developed by the Laboratory for Computational Neuroimaging at the Athinoula A. Martinos Center for Biomedical Imaging. Please see https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferSoftwareLicense for license information.",
      "environment": {
        "PYTHONUNBUFFERED": "1"
      },
      "label": "FreeSurfer 7.1.1: run recon-all",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "freesurfer-recon-all",
      "source": "https://github.com/flywheel-apps/freesurfer-recon-all",
      "url": "https://surfer.nmr.mgh.harvard.edu",
      "version": "1.0.0_7.1.1_rc0"
    },
    {
      "author": "Laboratory for Computational Neuroimaging <freesurfer@nmr.mgh.harvard.edu>",
      "cite": "For citation information, please visit: https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferMethodsCitation.",
      "command": "/root/miniconda3/bin/python3 run.py",
      "description": "FreeSurfer version 7.1.1 Release (July 27, 2020). This gear takes an anatomical NIfTI file and performs all of the FreeSurfer cortical reconstruction process. Outputs are provided in a zip file and include the entire output directory tree from Recon-All. Configuration options exist for setting the subject ID and for converting outputs to NIfTI, OBJ, and CSV. FreeSurfer is a software package for the analysis and visualization of structural and functional neuroimaging data from cross-sectional or longitudinal studies. It is developed by the Laboratory for Computational Neuroimaging at the Athinoula A. Martinos Center for Biomedical Imaging. Please see https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferSoftwareLicense for license information.",
      "environment": {
        "PYTHONUNBUFFERED": "1"
      },
      "label": "FreeSurfer 7.1.1: run recon-all",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "freesurfer-recon-all",
      "source": "https://github.com/flywheel-apps/freesurfer-recon-all",
      "url": "https://surfer.nmr.mgh.harvard.edu",
      "version": "1.0.0_7.1.1"
    },
    {
      "author": "Laboratory for Computational Neuroimaging <freesurfer@nmr.mgh.harvard.edu>",
      "cite": "For citation information, please visit: https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferMethodsCitation.",
      "description": "This gear takes an anatomical NIfTI file and performs all of the FreeSurfer cortical reconstruction process. Outputs are provided in a zip file and include the entire output directory tree from Recon-All. Configuration options exist for setting the subject ID and for converting outputs to NIfTI, OBJ, and CSV. FreeSurfer is a software package for the analysis and visualization of structural and functional neuroimaging data from cross-sectional or longitudinal studies. It is developed by the Laboratory for Computational Neuroimaging at the Athinoula A. Martinos Center for Biomedical Imaging. Please see https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferSoftwareLicense for license information.",
      "label": "FreeSurfer (v6.0.1): Recon-All",
      "license": "Other",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "freesurfer-recon-all",
      "source": "https://github.com/scitran-apps/freesurfer-recon-all",
      "url": "https://surfer.nmr.mgh.harvard.edu",
      "version": "0.4.2_6.0.1"
    },
    {
      "author": "Laboratory for Computational Neuroimaging <freesurfer@nmr.mgh.harvard.edu>",
      "cite": "For citation information, please visit: https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferMethodsCitation.",
      "description": "This gear takes an anatomical NIfTI file and performs all of the FreeSurfer cortical reconstruction process. Outputs are provided in a zip file and include the entire output directory tree from Recon-All. Configuration options exist for setting the subject ID and for converting outputs to NIfTI, OBJ, and CSV. FreeSurfer is a software package for the analysis and visualization of structural and functional neuroimaging data from cross-sectional or longitudinal studies. It is developed by the Laboratory for Computational Neuroimaging at the Athinoula A. Martinos Center for Biomedical Imaging. Please see https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferSoftwareLicense for license information.",
      "label": "FreeSurfer (v6.0.1): Recon-All",
      "license": "Other",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "freesurfer-recon-all",
      "source": "https://github.com/scitran-apps/freesurfer-recon-all",
      "url": "https://surfer.nmr.mgh.harvard.edu",
      "version": "0.4.1_6.0.1"
    },
    {
      "author": "Laboratory for Computational Neuroimaging <freesurfer@nmr.mgh.harvard.edu>",
      "cite": "For citation information, please visit: https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferMethodsCitation.",
      "description": "This gear takes an anatomical NIfTI file and performs all of the FreeSurfer cortical reconstruction process. Outputs are provided in a zip file and include the entire output directory tree from Recon-All. Configuration options exist for setting the subject ID and for converting outputs to NIfTI, OBJ, and CSV. FreeSurfer is a software package for the analysis and visualization of structural and functional neuroimaging data from cross-sectional or longitudinal studies. It is developed by the Laboratory for Computational Neuroimaging at the Athinoula A. Martinos Center for Biomedical Imaging. Please see https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferSoftwareLicense for license information.",
      "label": "FreeSurfer (v6.0.1): Recon-All",
      "license": "Other",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "freesurfer-recon-all",
      "source": "https://github.com/scitran-apps/freesurfer-recon-all",
      "url": "https://surfer.nmr.mgh.harvard.edu",
      "version": "0.4.0_6.0.1"
    },
    {
      "author": "Laboratory for Computational Neuroimaging <freesurfer@nmr.mgh.harvard.edu>",
      "cite": "For citation information, please visit: https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferMethodsCitation.",
      "description": "This gear takes an anatomical NIfTI file and performs all of the FreeSurfer cortical reconstruction process. Outputs are provided in a zip file and include the entire output directory tree from Recon-All. Configuration options exist for setting the subject ID and for converting outputs to NIfTI, OBJ, and CSV. FreeSurfer is a software package for the analysis and visualization of structural and functional neuroimaging data from cross-sectional or longitudinal studies. It is developed by the Laboratory for Computational Neuroimaging at the Athinoula A. Martinos Center for Biomedical Imaging. Please see https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferSoftwareLicense for license information.",
      "label": "FreeSurfer (v6.0.1): Recon-All",
      "license": "Other",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "freesurfer-recon-all",
      "source": "https://github.com/scitran-apps/freesurfer-recon-all",
      "url": "https://surfer.nmr.mgh.harvard.edu",
      "version": "0.3.1_6.0.1"
    },
    {
      "author": "Laboratory for Computational Neuroimaging <freesurfer@nmr.mgh.harvard.edu>",
      "cite": "For citation information, please visit: https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferMethodsCitation.",
      "description": "This gear takes an anatomical NIfTI file and performs all of the FreeSurfer cortical reconstruction process. Outputs are provided in a zip file and include the entire output directory tree from Recon-All. Configuration options exist for setting the subject ID and for converting outputs to NIfTI, OBJ, and CSV. FreeSurfer is a software package for the analysis and visualization of structural and functional neuroimaging data from cross-sectional or longitudinal studies. It is developed by the Laboratory for Computational Neuroimaging at the Athinoula A. Martinos Center for Biomedical Imaging. Please see https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferSoftwareLicense for license information.",
      "label": "FreeSurfer (v6.0.0): Recon-All",
      "license": "Other",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "freesurfer-recon-all",
      "source": "https://github.com/scitran-apps/freesurfer-recon-all",
      "url": "https://surfer.nmr.mgh.harvard.edu",
      "version": "0.3.0"
    },
    {
      "author": "Laboratory for Computational Neuroimaging <freesurfer@nmr.mgh.harvard.edu>",
      "cite": "For citation information, please visit: https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferMethodsCitation.",
      "description": "This gear takes an anatomical NIfTI file and performs all of the FreeSurfer cortical reconstruction process. Outputs are provided in a zip file and include the entire output directory tree from Recon-All. Configuration options exist for setting the subject ID and for converting outputs to NIfTI, OBJ, and CSV. FreeSurfer is a software package for the analysis and visualization of structural and functional neuroimaging data from cross-sectional or longitudinal studies. It is developed by the Laboratory for Computational Neuroimaging at the Athinoula A. Martinos Center for Biomedical Imaging. Please see https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferSoftwareLicense for license information.",
      "label": "FreeSurfer (v6.0.0): Recon-All",
      "license": "Other",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "freesurfer-recon-all",
      "source": "https://github.com/scitran-apps/freesurfer-recon-all",
      "url": "https://surfer.nmr.mgh.harvard.edu",
      "version": "0.2.0"
    },
    {
      "author": "Laboratory for Computational Neuroimaging <freesurfer@nmr.mgh.harvard.edu>",
      "cite": "For citation information, please visit: https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferMethodsCitation.",
      "description": "This gear takes an anatomical NIfTI file and performs all of the FreeSurfer cortical reconstruction process. Outputs are provided in a zip file and include the entire output directory tree from Recon-All. Configuration options exist for setting the subject ID and for converting outputs to NIfTI, OBJ, and CSV. FreeSurfer is a software package for the analysis and visualization of structural and functional neuroimaging data from cross-sectional or longitudinal studies. It is developed by the Laboratory for Computational Neuroimaging at the Athinoula A. Martinos Center for Biomedical Imaging. Please see https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferSoftwareLicense for license information.",
      "label": "FreeSurfer (v6.0.0): Recon-All",
      "license": "Other",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "freesurfer-recon-all",
      "source": "https://github.com/scitran-apps/freesurfer-recon-all",
      "url": "https://surfer.nmr.mgh.harvard.edu",
      "version": "0.1.4"
    },
    {
      "author": "Laboratory for Computational Neuroimaging <freesurfer@nmr.mgh.harvard.edu>",
      "cite": "For citation information, please visit: https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferMethodsCitation.",
      "description": "This gear takes an anatomical NIfTI file and performs all of the FreeSurfer cortical reconstruction process. Outputs are provided in a zip file and include the entire output directory tree from Recon-All. Configuration options exist for setting the subject ID and for converting outputs to NIfTI, OBJ, and CSV. FreeSurfer is a software package for the analysis and visualization of structural and functional neuroimaging data from cross-sectional or longitudinal studies. It is developed by the Laboratory for Computational Neuroimaging at the Athinoula A. Martinos Center for Biomedical Imaging. Please see https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferSoftwareLicense for license information.",
      "label": "FreeSurfer (v6.0.0): Recon-All",
      "license": "Other",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "freesurfer-recon-all",
      "source": "https://github.com/scitran-apps/freesurfer-recon-all",
      "url": "https://surfer.nmr.mgh.harvard.edu",
      "version": "0.1.3"
    },
    {
      "author": "Laboratory for Computational Neuroimaging <freesurfer@nmr.mgh.harvard.edu>",
      "description": "This gear takes an anatomical NIfTI file and performs all of the FreeSurfer cortical reconstruction process. Outputs are provided in a zip file and include the entire output directory tree from Recon-All. Configuration options exist for setting the subject ID and for converting outputs to NIfTI, OBJ, and CSV. FreeSurfer is a software package for the analysis and visualization of structural and functional neuroimaging data from cross-sectional or longitudinal studies. It is developed by the Laboratory for Computational Neuroimaging at the Athinoula A. Martinos Center for Biomedical Imaging. Please see https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferSoftwareLicense for license information.",
      "label": "FreeSurfer (v6.0.0): Recon-All",
      "license": "GPL-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "freesurfer-recon-all",
      "source": "https://github.com/scitran-apps/freesurfer-recon-all",
      "url": "https://surfer.nmr.mgh.harvard.edu",
      "version": "0.1.2"
    },
    {
      "author": "Laboratory for Computational Neuroimaging <freesurfer@nmr.mgh.harvard.edu>",
      "cite": "For citation information, please visit: https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferMethodsCitation.",
      "command": "/root/miniconda3/bin/python3 run.py",
      "description": "FreeSurfer version 7.1.1 Release (July 27, 2020). This gear takes an anatomical NIfTI file and performs all of the FreeSurfer cortical reconstruction process. Outputs are provided in a zip file and include the entire output directory tree from Recon-All. Configuration options exist for setting the subject ID and for converting outputs to NIfTI, OBJ, and CSV. FreeSurfer is a software package for the analysis and visualization of structural and functional neuroimaging data from cross-sectional or longitudinal studies. It is developed by the Laboratory for Computational Neuroimaging at the Athinoula A. Martinos Center for Biomedical Imaging. Please see https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferSoftwareLicense for license information.",
      "environment": {
        "PYTHONUNBUFFERED": "1"
      },
      "label": "FreeSurfer 7.1.1: run recon-all",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "freesurfer-recon-all",
      "source": "https://github.com/flywheel-apps/freesurfer-recon-all",
      "url": "https://surfer.nmr.mgh.harvard.edu",
      "version": "0.1.0_7.1.1_rc0"
    },
    {
      "author": "Laboratory for Computational Neuroimaging <freesurfer@nmr.mgh.harvard.edu>",
      "description": " This gear takes an anatomical NIfTI file and performs all of the FreeSurfer cortical reconstruction process. Outputs are provided in a zip file and include the entire output directory tree from Recon-All. Configuration options exist for setting the subejct ID and for converting outputs to NIfTI, OBJ, and CSV. FreeSurfer is a software package for the analysis and visualization of structural and functional neuroimaging data from cross-sectional or longitudinal studies. It is developed by the Laboratory for Computational Neuroimaging at the Athinoula A. Martinos Center for Biomedical Imaging. Please see https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferSoftwareLicense for license information.",
      "label": "FreeSurfer (v6.0.0): Recon-All",
      "license": "GPL-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "freesurfer-recon-all",
      "source": "https://github.com/scitran-apps/freesurfer-recon-all",
      "url": "https://surfer.nmr.mgh.harvard.edu",
      "version": "0.1.0"
    }
  ],
  [
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "cite": "M.W. Woolrich, S. Jbabdi, B. Patenaude, M. Chappell, S. Makni, T. Behrens, C. Beckmann, M. Jenkinson, S.M. Smith. Bayesian analysis of neuroimaging data in FSL. NeuroImage, 45:S173-86, 2009.",
      "command": "/flywheel/v0/run.py",
      "description": "This tool provides a general pipeline for processing anatomical images (e.g. T1-weighted scans).",
      "environment": {
        "DEBIAN_FRONTEND": "noninteractive",
        "FLYWHEEL": "/flywheel/v0",
        "FSLDIR": "/usr/share/fsl/6.0",
        "FSLMULTIFILEQUIT": "TRUE",
        "FSLOUTPUTTYPE": "NIFTI_GZ",
        "FSLTCLSH": "/usr/bin/tclsh",
        "FSLWISH": "/usr/bin/wish",
        "FSL_DIR": "/usr/share/fsl/6.0",
        "GPG_KEY": "0D96DF4D4110E5C43FBFB17F2D347EA6AA65421D",
        "LANG": "C.UTF-8",
        "LD_LIBRARY_PATH": "/usr/share/fsl/6.0/lib",
        "PATH": "/usr/share/fsl/6.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
        "POSSUMDIR": "/usr/share/fsl/6.0",
        "PYTHON_PIP_VERSION": "19.1.1",
        "PYTHON_VERSION": "3.7.3",
        "TZ": "Etc/UTC"
      },
      "label": "FSL-ANAT - Anatomical Processing Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fsl-anat",
      "source": "https://github.com/flywheel-apps/fsl-anat",
      "url": "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/fsl_anat",
      "version": "1.1.2_6.0.1"
    },
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "cite": "M.W. Woolrich, S. Jbabdi, B. Patenaude, M. Chappell, S. Makni, T. Behrens, C. Beckmann, M. Jenkinson, S.M. Smith. Bayesian analysis of neuroimaging data in FSL. NeuroImage, 45:S173-86, 2009.",
      "command": "/flywheel/v0/run.py",
      "description": "This tool provides a general pipeline for processing anatomical images (e.g. T1-weighted scans).",
      "environment": {
        "DEBIAN_FRONTEND": "noninteractive",
        "FLYWHEEL": "/flywheel/v0",
        "FSLDIR": "/usr/share/fsl/6.0",
        "FSLMULTIFILEQUIT": "TRUE",
        "FSLOUTPUTTYPE": "NIFTI_GZ",
        "FSLTCLSH": "/usr/bin/tclsh",
        "FSLWISH": "/usr/bin/wish",
        "FSL_DIR": "/usr/share/fsl/6.0",
        "GPG_KEY": "0D96DF4D4110E5C43FBFB17F2D347EA6AA65421D",
        "LANG": "C.UTF-8",
        "LD_LIBRARY_PATH": "/usr/share/fsl/6.0/lib",
        "PATH": "/usr/share/fsl/6.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
        "POSSUMDIR": "/usr/share/fsl/6.0",
        "PYTHON_PIP_VERSION": "19.1.1",
        "PYTHON_VERSION": "3.7.3",
        "TZ": "Etc/UTC"
      },
      "label": "FSL-ANAT - Anatomical Processing Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fsl-anat",
      "source": "https://github.com/flywheel-apps/fsl-anat",
      "url": "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/fsl_anat",
      "version": "1.1.1_6.0.1"
    },
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "cite": "M.W. Woolrich, S. Jbabdi, B. Patenaude, M. Chappell, S. Makni, T. Behrens, C. Beckmann, M. Jenkinson, S.M. Smith. Bayesian analysis of neuroimaging data in FSL. NeuroImage, 45:S173-86, 2009.",
      "command": "/flywheel/v0/run.py",
      "description": "This tool provides a general pipeline for processing anatomical images (e.g. T1-weighted scans).",
      "environment": {
        "DEBIAN_FRONTEND": "noninteractive",
        "FLYWHEEL": "/flywheel/v0",
        "FSLDIR": "/usr/share/fsl/5.0",
        "FSLMULTIFILEQUIT": "TRUE",
        "FSLOUTPUTTYPE": "NIFTI_GZ",
        "FSLTCLSH": "/usr/bin/tclsh",
        "FSLWISH": "/usr/bin/wish",
        "FSL_DIR": "/usr/share/fsl/5.0",
        "GPG_KEY": "0D96DF4D4110E5C43FBFB17F2D347EA6AA65421D",
        "LANG": "C.UTF-8",
        "LD_LIBRARY_PATH": "/usr/share/fsl/5.0/lib",
        "PATH": "/usr/share/fsl/5.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
        "POSSUMDIR": "/usr/share/fsl/5.0",
        "PYTHON_PIP_VERSION": "19.1.1",
        "PYTHON_VERSION": "3.7.3",
        "TZ": "Etc/UTC"
      },
      "label": "FSL-ANAT - Anatomical Processing Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fsl-anat",
      "source": "https://github.com/flywheel-apps/fsl-anat",
      "url": "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/fsl_anat",
      "version": "1.1.1_5.0.9"
    },
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "cite": "M.W. Woolrich, S. Jbabdi, B. Patenaude, M. Chappell, S. Makni, T. Behrens, C. Beckmann, M. Jenkinson, S.M. Smith. Bayesian analysis of neuroimaging data in FSL. NeuroImage, 45:S173-86, 2009.",
      "command": "/flywheel/v0/run.py",
      "description": "This tool provides a general pipeline for processing anatomical images (e.g. T1-weighted scans).",
      "environment": {
        "DEBIAN_FRONTEND": "noninteractive",
        "FLYWHEEL": "/flywheel/v0",
        "FSLDIR": "/usr/share/fsl/6.0",
        "FSLMULTIFILEQUIT": "TRUE",
        "FSLOUTPUTTYPE": "NIFTI_GZ",
        "FSLTCLSH": "/usr/bin/tclsh",
        "FSLWISH": "/usr/bin/wish",
        "FSL_DIR": "/usr/share/fsl/6.0",
        "GPG_KEY": "0D96DF4D4110E5C43FBFB17F2D347EA6AA65421D",
        "LANG": "C.UTF-8",
        "LD_LIBRARY_PATH": "/usr/share/fsl/6.0/lib",
        "PATH": "/usr/share/fsl/6.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
        "POSSUMDIR": "/usr/share/fsl/6.0",
        "PYTHON_PIP_VERSION": "19.1.1",
        "PYTHON_VERSION": "3.7.3",
        "TZ": "Etc/UTC"
      },
      "label": "FSL-ANAT - Anatomical Processing Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fsl-anat",
      "source": "https://github.com/flywheel-apps/fsl-anat",
      "url": "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/fsl_anat",
      "version": "1.1.0_6.0.1"
    },
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "cite": "M.W. Woolrich, S. Jbabdi, B. Patenaude, M. Chappell, S. Makni, T. Behrens, C. Beckmann, M. Jenkinson, S.M. Smith. Bayesian analysis of neuroimaging data in FSL. NeuroImage, 45:S173-86, 2009.",
      "command": "/flywheel/v0/run.py",
      "description": "This tool provides a general pipeline for processing anatomical images (e.g. T1-weighted scans).",
      "environment": {
        "DEBIAN_FRONTEND": "noninteractive",
        "FLYWHEEL": "/flywheel/v0",
        "FSLDIR": "/usr/share/fsl/5.0",
        "FSLMULTIFILEQUIT": "TRUE",
        "FSLOUTPUTTYPE": "NIFTI_GZ",
        "FSLTCLSH": "/usr/bin/tclsh",
        "FSLWISH": "/usr/bin/wish",
        "FSL_DIR": "/usr/share/fsl/5.0",
        "GPG_KEY": "0D96DF4D4110E5C43FBFB17F2D347EA6AA65421D",
        "LANG": "C.UTF-8",
        "LD_LIBRARY_PATH": "/usr/share/fsl/5.0/lib",
        "PATH": "/usr/share/fsl/5.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
        "POSSUMDIR": "/usr/share/fsl/5.0",
        "PYTHON_PIP_VERSION": "19.1.1",
        "PYTHON_VERSION": "3.7.3",
        "TZ": "Etc/UTC"
      },
      "label": "FSL-ANAT - Anatomical Processing Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fsl-anat",
      "source": "https://github.com/flywheel-apps/fsl-anat",
      "url": "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/fsl_anat",
      "version": "1.1.0_5.0.9"
    },
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "cite": "M.W. Woolrich, S. Jbabdi, B. Patenaude, M. Chappell, S. Makni, T. Behrens, C. Beckmann, M. Jenkinson, S.M. Smith. Bayesian analysis of neuroimaging data in FSL. NeuroImage, 45:S173-86, 2009.",
      "command": "/flywheel/v0/run.py",
      "description": "This tool provides a general pipeline for processing anatomical images (e.g. T1-weighted scans).",
      "environment": {
        "DEBIAN_FRONTEND": "noninteractive",
        "FLYWHEEL": "/flywheel/v0",
        "FSLDIR": "/usr/share/fsl/6.0",
        "FSLMULTIFILEQUIT": "TRUE",
        "FSLOUTPUTTYPE": "NIFTI_GZ",
        "FSLTCLSH": "/usr/bin/tclsh",
        "FSLWISH": "/usr/bin/wish",
        "FSL_DIR": "/usr/share/fsl/5.0",
        "GPG_KEY": "0D96DF4D4110E5C43FBFB17F2D347EA6AA65421D",
        "LANG": "C.UTF-8",
        "LD_LIBRARY_PATH": "/usr/share/fsl/6.0/lib",
        "PATH": "/usr/share/fsl/6.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
        "POSSUMDIR": "/usr/share/fsl/6.0",
        "PYTHON_PIP_VERSION": "19.1.1",
        "PYTHON_VERSION": "3.7.3",
        "TZ": "Etc/UTC"
      },
      "label": "FSL-ANAT - Anatomical Processing Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fsl-anat",
      "source": "https://github.com/flywheel-apps/fsl-anat",
      "url": "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/fsl_anat",
      "version": "1.0.0_6.0.1"
    },
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "cite": "M.W. Woolrich, S. Jbabdi, B. Patenaude, M. Chappell, S. Makni, T. Behrens, C. Beckmann, M. Jenkinson, S.M. Smith. Bayesian analysis of neuroimaging data in FSL. NeuroImage, 45:S173-86, 2009.",
      "command": "/flywheel/v0/run.py",
      "description": "This tool provides a general pipeline for processing anatomical images (e.g. T1-weighted scans).<br>Most of the pipeline involves standard use of FSL tools, but the bias-field correction has been substantially improved, especially for strong bias-fields typical of multi-coil arrays and high-field scanners.<br>The stages in the pipeline (in order) are:<br>reorient the images to the standard (MNI) orientation [fslreorient2std]\nautomatically crop the image [robustfov]\nbias-field correction (RF/B1-inhomogeneity-correction) [FAST]\nregistration to standard space (linear and non-linear) [FLIRT and FNIRT]\nbrain-extraction [FNIRT-based or BET]\ntissue-type segmentation [FAST]\nsubcortical structure segmentation [FIRST]<br>The overall run-time is heavily dependent on the resolution of the image but anything between 30 and 90 minutes would be typical. Outputs include a zipped archive and output file manifest.",
      "environment": {
        "DEBIAN_FRONTEND": "noninteractive",
        "FLYWHEEL": "/flywheel/v0",
        "FSLDIR": "/usr/share/fsl/5.0",
        "FSLMULTIFILEQUIT": "TRUE",
        "FSLOUTPUTTYPE": "NIFTI_GZ",
        "FSLTCLSH": "/usr/bin/tclsh",
        "FSLWISH": "/usr/bin/wish",
        "FSL_DIR": "/usr/share/fsl/5.0",
        "GPG_KEY": "0D96DF4D4110E5C43FBFB17F2D347EA6AA65421D",
        "LANG": "C.UTF-8",
        "LD_LIBRARY_PATH": "/usr/lib/fsl/5.0:/usr/lib/fsl/5.0:",
        "PATH": "/usr/lib/fsl/5.0:/usr/lib/fsl/5.0:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
        "POSSUMDIR": "/usr/share/fsl/5.0",
        "PYTHON_PIP_VERSION": "19.1.1",
        "PYTHON_VERSION": "3.7.3",
        "TZ": "Etc/UTC"
      },
      "label": "FSL-ANAT - Anatomical Processing Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fsl-anat",
      "source": "https://github.com/flywheel-apps/fsl-anat",
      "url": "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/fsl_anat",
      "version": "1.0.0_5.0.9"
    }
  ],
  [
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "description": "Brain Extraction Tool (BET2) from FMRIB Software Library (FSL) v5.0. BET (Brain Extraction Tool) deletes non-brain tissue from an image of the whole head. It can also estimate the inner and outer skull surfaces, and outer scalp surface, if you have good quality T1 and T2 input images.",
      "label": "FSL: Brain Extraction Tool (BET2)",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "fsl-bet",
      "source": "https://github.com/scitran-apps/fsl-bet",
      "url": "http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/BET",
      "version": "0.2.3"
    },
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "description": "Brain Extraction Tool (BET2) from FMRIB Software Library (FSL) v5.0. BET (Brain Extraction Tool) deletes non-brain tissue from an image of the whole head. It can also estimate the inner and outer skull surfaces, and outer scalp surface, if you have good quality T1 and T2 input images.",
      "label": "FSL: Brain Extraction Tool (BET2)",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "fsl-bet",
      "source": "https://github.com/scitran-apps/fsl-bet",
      "url": "http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/BET",
      "version": "0.2.2"
    },
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "description": "Brain Extraction Tool (BET2) from FMRIB Software Library (FSL) v5.0. BET (Brain Extraction Tool) deletes non-brain tissue from an image of the whole head. It can also estimate the inner and outer skull surfaces, and outer scalp surface, if you have good quality T1 and T2 input images.",
      "label": "FSL: Brain Extraction Tool (BET2)",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "fsl-bet",
      "source": "https://github.com/scitran-apps/fsl-bet",
      "url": "http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/BET",
      "version": "0.2.1"
    },
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "description": "Brain Extraction Tool (BET2) from FMRIB Software Library (FSL) v5.0. BET (Brain Extraction Tool) deletes non-brain tissue from an image of the whole head. It can also estimate the inner and outer skull surfaces, and outer scalp surface, if you have good quality T1 and T2 input images.",
      "label": "FSL: Brain Extraction Tool (BET2)",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "fsl-bet",
      "source": "https://github.com/scitran-apps/fsl-bet",
      "url": "http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/BET",
      "version": "0.2.0"
    },
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "description": "Brain Extraction Tool (BET2) from FMRIB Software Library (FSL) v5.0. BET (Brain Extraction Tool) deletes non-brain tissue from an image of the whole head. It can also estimate the inner and outer skull surfaces, and outer scalp surface, if you have good quality T1 and T2 input images.",
      "label": "FSL: Brain Extraction Tool (BET2)",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "fsl-bet",
      "source": "https://github.com/scitran-apps/fsl-bet",
      "url": "http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/BET",
      "version": "0.1.0"
    }
  ],
  [
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "cite": "Zhang, Y. and Brady, M. and Smith, S. Segmentation of brain MR images through a hidden Markov random field model and the expectation-maximization algorithm. IEEE Trans Med Imag, 20(1):45-57, 2001.",
      "description": "FAST (FMRIB's Automated Segmentation Tool) segments a 3D image of the brain into different tissue types (Grey Matter, White Matter, CSF, etc.), whilst also correcting for spatial intensity variations (also known as bias field or RF inhomogeneities). The underlying method is based on a hidden Markov random field model and an associated Expectation-Maximization algorithm. The whole process is fully automated and can also produce a bias field-corrected input image and a probabilistic and/or partial volume tissue segmentation. It is robust and reliable, compared to most finite mixture model-based methods, which are sensitive to noise.",
      "label": "FSL: FMRIB Automated Segmentation Tool (FAST4, v5.0.9)",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "fsl-fast",
      "source": "https://github.com/scitran-apps/fsl-fast",
      "url": "http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FAST",
      "version": "0.1.1"
    },
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "description": "FAST (FMRIB's Automated Segmentation Tool) segments a 3D image of the brain into different tissue types (Grey Matter, White Matter, CSF, etc.), whilst also correcting for spatial intensity variations (also known as bias field or RF inhomogeneities). The underlying method is based on a hidden Markov random field model and an associated Expectation-Maximization algorithm. The whole process is fully automated and can also produce a bias field-corrected input image and a probabilistic and/or partial volume tissue segmentation. It is robust and reliable, compared to most finite mixture model-based methods, which are sensitive to noise.",
      "label": "FSL: FMRIB Automated Segmentation Tool (FAST4, v5.0.9)",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "fsl-fast",
      "source": "https://github.com/scitran-apps/fsl-fast",
      "url": "http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FAST",
      "version": "0.1"
    }
  ],
  [
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "description": "FSL's FEAT (FMRI Expert Analysis Tool). As implemented in this Gear FEAT allows for basic preprocessing of an fMRI dataset including motion correction using MCFLIRT [Jenkinson 2002]; slice-timing correction using Fourier-space time-series phase-shifting; non-brain removal using BET [Smith 2002]; spatial smoothing using a Gaussian kernel; multiplicative mean intensity normalization of the volume at each timepoint; and highpass temporal filtering (Gaussian-weighted least-squares straight line fitting), brain extraction, and registration to a standard image (MNI152).",
      "label": "FSL: FEAT - fMRI preprocessing (v6.0)",
      "license": "Apache-2.0",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fsl-feat",
      "source": "https://github.com/flywheel-apps/fsl-feat",
      "url": "http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FEAT",
      "version": "0.1.4"
    },
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "description": "FSL's FEAT (FMRI Expert Analysis Tool). As implemented in this Gear FEAT allows for basic preprocessing of an fMRI dataset including motion correction using MCFLIRT [Jenkinson 2002]; slice-timing correction using Fourier-space time-series phase-shifting; non-brain removal using BET [Smith 2002]; spatial smoothing using a Gaussian kernel; multiplicative mean intensity normalization of the volume at each timepoint; and highpass temporal filtering (Gaussian-weighted least-squares straight line fitting), brain extraction, and registration to a standard image (MNI152).",
      "label": "FSL: FEAT - fMRI preprocessing (v6.0)",
      "license": "Apache-2.0",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fsl-feat",
      "source": "https://github.com/flywheel-apps/fsl-feat",
      "url": "http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FEAT",
      "version": "0.1.3"
    },
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "description": "FSL's FEAT (FMRI Expert Analysis Tool). As implemented in this Gear FEAT allows for basic preprocessing of an fMRI dataset including motion correction using MCFLIRT [Jenkinson 2002]; slice-timing correction using Fourier-space time-series phase-shifting; non-brain removal using BET [Smith 2002]; spatial smoothing using a Gaussian kernel; multiplicative mean intensity normalization of the volume at each timepoint; and highpass temporal filtering (Gaussian-weighted least-squares straight line fitting), brain extraction, and registration to a standard image (MNI152).",
      "label": "FSL: FEAT - fMRI preprocessing (v6.0)",
      "license": "Apache-2.0",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fsl-feat",
      "source": "https://github.com/flywheel-apps/fsl-feat",
      "url": "http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FEAT",
      "version": "0.1.1"
    },
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "description": "FSL's FEAT (FMRI Expert Analysis Tool). As implemented in this Gear FEAT allows for basic preprocessing of an fMRI dataset including motion correction using MCFLIRT [Jenkinson 2002]; slice-timing correction using Fourier-space time-series phase-shifting; non-brain removal using BET [Smith 2002]; spatial smoothing using a Gaussian kernel; multiplicative mean intensity normalization of the volume at each timepoint; and highpass temporal filtering (Gaussian-weighted least-squares straight line fitting).",
      "label": "FSL: FEAT - fMRI preprocessing (v6.0)",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "fsl-feat",
      "source": "https://github.com/flywheel-apps/fsl-feat",
      "url": "http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FEAT",
      "version": "0.1"
    }
  ],
  [
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "description": "FSL's fslhd reads fields from a NIfTI file header. This Gear takes that header and generates metadata that is placed upon the input file's info field in the Flywheel database. FSLHD reports every field of an Analyze or Nifti header (note that the fields are different although some are common, e.g. pixdims). The reported values are those used internally in FSL programs and are sometimes different from the raw values stored in the file to avoid incorrect settings (e.g. dimN has a minimum value of 1, not 0).",
      "label": "FSL: FSLHD - NIfTI File Header Extraction",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fsl-fslhd",
      "source": "https://github.com/flywheel-apps/fsl-fslhd",
      "url": "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Fslutils",
      "version": "1.1.1"
    },
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "description": "FSL's fslhd reads fields from a NIfTI file header. This Gear takes that header and generates metadata that is placed upon the input file's info field in the Flywheel database. FSLHD reports every field of an Analyze or Nifti header (note that the fields are different although some are common, e.g. pixdims). The reported values are those used internally in FSL programs and are sometimes different from the raw values stored in the file to avoid incorrect settings (e.g. dimN has a minimum value of 1, not 0).",
      "label": "FSL: FSLHD - NIfTI File Header Extraction",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fsl-fslhd",
      "source": "https://github.com/flywheel-apps/fsl-fslhd",
      "url": "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Fslutils",
      "version": "1.1.0"
    },
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "description": "FSL's fslhd reads fields from a NIfTI file header. This Gear takes that header and generates metadata that is placed upon the input file's info field in the Flywheel database. FSLHD reports every field of an Analyze or Nifti header (note that the fields are different although some are common, e.g. pixdims). The reported values are those used internally in FSL programs and are sometimes different from the raw values stored in the file to avoid incorrect settings (e.g. dimN has a minimum value of 1, not 0).",
      "label": "FSL: FSLHD - NIfTI File Header Extraction",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fsl-fslhd",
      "source": "https://github.com/flywheel-apps/fsl-fslhd",
      "url": "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Fslutils",
      "version": "1.0.1"
    },
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "description": "FSL's fslhd reads fields from a NIfTI file header. This Gear takes that header and generates metadata that is placed upon the input file's info field in the Flywheel database. FSLHD reports every field of an Analyze or Nifti header (note that the fields are different although some are common, e.g. pixdims). The reported values are those used internally in FSL programs and are sometimes different from the raw values stored in the file to avoid incorrect settings (e.g. dimN has a minimum value of 1, not 0).",
      "label": "FSL: FSLHD - NIfTI File Header Extraction",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fsl-fslhd",
      "source": "https://github.com/flywheel-apps/fsl-fslhd",
      "url": "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Fslutils",
      "version": "1.0.0"
    }
  ],
  [
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "description": "fslreorient2std is a tool for reorienting the image to match the approximate orientation of the standard template images (MNI152). It only applies 0, 90, 180 or 270 degree rotations. It is not a registration tool. It requires NIfTI images with valid orientation information in them (seen by valid labels in FSLView).  This tool assumes the labels are correct - if not, fix that before using this Gear.",
      "label": "FSL: fslreorient2std - Reorient Image to Standard Template",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fsl-fslreorient2std",
      "source": "https://github.com/flywheel-apps/fsl-fslreorient2std",
      "url": "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Fslutils",
      "version": "1.0.0"
    }
  ],
  [
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "cite": "S.M. Smith, Y. Zhang, M. Jenkinson, J. Chen, P.M. Matthews, A. Federico, and N. De Stefano. Accurate, robust and automated longitudinal and cross-sectional brain change analysis. NeuroImage, 17(1):479-489, 2002.  S.M. Smith, M. Jenkinson, M.W. Woolrich, C.F. Beckmann, T.E.J. Behrens, H. Johansen-Berg, P.R. Bannister, M. De Luca, I. Drobnjak, D.E. Flitney, R. Niazy, J. Saunders, J. Vickers, Y. Zhang, N. De Stefano, J.M. Brady, and P.M. Matthews. Advances in functional and structural MR image analysis and implementation as FSL. NeuroImage, 23(S1):208-219, 2004.",
      "command": "python3 run.py",
      "description": "Siena estimates percentage brain volume change (PBVC) betweem two input images, taken of the same subject, at different points in time. It calls a series of FSL programs to strip the non-brain tissue from the two images, register the two brains (under the constraint that the skulls are used to hold the scaling constant during the registration) and analyse the brain change between the two time points. As implemented in this Gear Siena allows for analysis of 14 subcortical regions as well as the Brain-Stem/4th Ventricle (with VENT option). Inputs should be structural images (T1-weighted, T2-weighted, PD, etc) where the in-plane resolution is better than 2mm (ideally 1mm). Outputs consist of an archive containing the results of the analysis, as well as an HTML report summarizing the analysis findings.",
      "environment": {
        "FSLBROWSER": "/etc/alternatives/x-www-browser",
        "FSLDIR": "/usr/share/fsl/5.0",
        "FSLLOCKDIR": "",
        "FSLMACHINELIST": "",
        "FSLMULTIFILEQUIT": "TRUE",
        "FSLOUTPUTTYPE": "NIFTI_GZ",
        "FSLREMOTECALL": "",
        "FSLTCLSH": "/usr/bin/tclsh",
        "FSLWISH": "/usr/bin/wish",
        "LD_LIBRARY_PATH": "/usr/lib/fsl/5.0",
        "PATH": "/usr/lib/fsl/5.0:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
        "POSSUMDIR": "/usr/share/fsl/5.0"
      },
      "label": "FSL: SIENA - Longitudinal analysis of brain change",
      "license": "Apache-2.0",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fsl-siena",
      "source": "https://github.com/flywheel-apps/fsl-siena-sienax",
      "url": "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/SIENA",
      "version": "1.0.2_5.0"
    },
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "cite": "S.M. Smith, Y. Zhang, M. Jenkinson, J. Chen, P.M. Matthews, A. Federico, and N. De Stefano. Accurate, robust and automated longitudinal and cross-sectional brain change analysis. NeuroImage, 17(1):479-489, 2002.  S.M. Smith, M. Jenkinson, M.W. Woolrich, C.F. Beckmann, T.E.J. Behrens, H. Johansen-Berg, P.R. Bannister, M. De Luca, I. Drobnjak, D.E. Flitney, R. Niazy, J. Saunders, J. Vickers, Y. Zhang, N. De Stefano, J.M. Brady, and P.M. Matthews. Advances in functional and structural MR image analysis and implementation as FSL. NeuroImage, 23(S1):208-219, 2004.",
      "command": "python3 run.py",
      "description": "Siena estimates percentage brain volume change (PBVC) betweem two input images, taken of the same subject, at different points in time. It calls a series of FSL programs to strip the non-brain tissue from the two images, register the two brains (under the constraint that the skulls are used to hold the scaling constant during the registration) and analyse the brain change between the two time points. As implemented in this Gear Siena allows for analysis of 14 subcortical regions as well as the Brain-Stem/4th Ventricle (with VENT option). Inputs should be structural images (T1-weighted, T2-weighted, PD, etc) where the in-plane resolution is better than 2mm (ideally 1mm). Outputs consist of an archive containing the results of the analysis, as well as an HTML report summarizing the analysis findings.",
      "environment": {
        "FSLBROWSER": "/etc/alternatives/x-www-browser",
        "FSLDIR": "/usr/share/fsl/5.0",
        "FSLLOCKDIR": "",
        "FSLMACHINELIST": "",
        "FSLMULTIFILEQUIT": "TRUE",
        "FSLOUTPUTTYPE": "NIFTI_GZ",
        "FSLREMOTECALL": "",
        "FSLTCLSH": "/usr/bin/tclsh",
        "FSLWISH": "/usr/bin/wish",
        "LD_LIBRARY_PATH": "/usr/lib/fsl/5.0",
        "PATH": "/usr/lib/fsl/5.0:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
        "POSSUMDIR": "/usr/share/fsl/5.0"
      },
      "label": "FSL: SIENA - Longitudinal analysis of brain change",
      "license": "Apache-2.0",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fsl-siena",
      "source": "https://github.com/flywheel-apps/fsl-siena-sienax",
      "url": "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/SIENA",
      "version": "1.0.1_5.0"
    },
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "cite": "S.M. Smith, Y. Zhang, M. Jenkinson, J. Chen, P.M. Matthews, A. Federico, and N. De Stefano. Accurate, robust and automated longitudinal and cross-sectional brain change analysis. NeuroImage, 17(1):479-489, 2002.  S.M. Smith, M. Jenkinson, M.W. Woolrich, C.F. Beckmann, T.E.J. Behrens, H. Johansen-Berg, P.R. Bannister, M. De Luca, I. Drobnjak, D.E. Flitney, R. Niazy, J. Saunders, J. Vickers, Y. Zhang, N. De Stefano, J.M. Brady, and P.M. Matthews. Advances in functional and structural MR image analysis and implementation as FSL. NeuroImage, 23(S1):208-219, 2004.",
      "command": "python3 run.py",
      "description": "Siena estimates percentage brain volume change (PBVC) betweem two input images, taken of the same subject, at different points in time. It calls a series of FSL programs to strip the non-brain tissue from the two images, register the two brains (under the constraint that the skulls are used to hold the scaling constant during the registration) and analyse the brain change between the two time points. As implemented in this Gear Siena allows for analysis of 14 subcortical regions as well as the Brain-Stem/4th Ventricle (with VENT option). Inputs should be structural images (T1-weighted, T2-weighted, PD, etc) where the in-plane resolution is better than 2mm (ideally 1mm). Outputs consist of an archive containing the results of the analysis, as well as an HTML report summarizing the analysis findings.",
      "environment": {
        "FSLBROWSER": "/etc/alternatives/x-www-browser",
        "FSLDIR": "/usr/share/fsl/5.0",
        "FSLLOCKDIR": "",
        "FSLMACHINELIST": "",
        "FSLMULTIFILEQUIT": "TRUE",
        "FSLOUTPUTTYPE": "NIFTI_GZ",
        "FSLREMOTECALL": "",
        "FSLTCLSH": "/usr/bin/tclsh",
        "FSLWISH": "/usr/bin/wish",
        "LD_LIBRARY_PATH": "/usr/lib/fsl/5.0",
        "PATH": "/usr/lib/fsl/5.0:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
        "POSSUMDIR": "/usr/share/fsl/5.0"
      },
      "label": "FSL: SIENA - Longitudinal analysis of brain change",
      "license": "Apache-2.0",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fsl-siena",
      "source": "https://github.com/flywheel-apps/fsl-siena-sienax",
      "url": "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/SIENA",
      "version": "1.0.0_5.0"
    }
  ],
  [
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "cite": "S.M. Smith, Y. Zhang, M. Jenkinson, J. Chen, P.M. Matthews, A. Federico, and N. De Stefano. Accurate, robust and automated longitudinal and cross-sectional brain change analysis. NeuroImage, 17(1):479-489, 2002.  S.M. Smith, M. Jenkinson, M.W. Woolrich, C.F. Beckmann, T.E.J. Behrens, H. Johansen-Berg, P.R. Bannister, M. De Luca, I. Drobnjak, D.E. Flitney, R. Niazy, J. Saunders, J. Vickers, Y. Zhang, N. De Stefano, J.M. Brady, and P.M. Matthews. Advances in functional and structural MR image analysis and implementation as FSL. NeuroImage, 23(S1):208-219, 2004.",
      "command": "python3 run.py",
      "description": "FSL's SIENAX. Sienax estimates total brain tissue volume, from a single image, normalised for skull size. It calls a series of FSL programs: It first strips non-brain tissue, and then uses the brain and skull images to estimate the scaling between the subject's image and standard space. It then runs tissue segmentation to estimate the volume of brain tissue, and multiplies this by the estimated scaling factor, to reduce head-size-related variability between subjects. Inputs should be structural image (T1-weighted, T2-weighted, PD, etc) where the in-plane resolution is better than 2mm (ideally 1mm). Outputs consist of an archive containing the results of the analysis, as well as an HTML report summarizing the analysis findings.",
      "environment": {
        "FSLBROWSER": "/etc/alternatives/x-www-browser",
        "FSLDIR": "/usr/share/fsl/5.0",
        "FSLLOCKDIR": "",
        "FSLMACHINELIST": "",
        "FSLMULTIFILEQUIT": "TRUE",
        "FSLOUTPUTTYPE": "NIFTI_GZ",
        "FSLREMOTECALL": "",
        "FSLTCLSH": "/usr/bin/tclsh",
        "FSLWISH": "/usr/bin/wish",
        "LD_LIBRARY_PATH": "/usr/lib/fsl/5.0",
        "PATH": "/usr/lib/fsl/5.0:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
        "POSSUMDIR": "/usr/share/fsl/5.0"
      },
      "label": "FSL: SIENAX - Brain tissue volume, normalised for subject head size",
      "license": "Apache-2.0",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fsl-sienax",
      "source": "https://github.com/flywheel-apps/fsl-siena-sienax",
      "url": "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/SIENA",
      "version": "1.0.2_5.0"
    },
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "cite": "S.M. Smith, Y. Zhang, M. Jenkinson, J. Chen, P.M. Matthews, A. Federico, and N. De Stefano. Accurate, robust and automated longitudinal and cross-sectional brain change analysis. NeuroImage, 17(1):479-489, 2002.  S.M. Smith, M. Jenkinson, M.W. Woolrich, C.F. Beckmann, T.E.J. Behrens, H. Johansen-Berg, P.R. Bannister, M. De Luca, I. Drobnjak, D.E. Flitney, R. Niazy, J. Saunders, J. Vickers, Y. Zhang, N. De Stefano, J.M. Brady, and P.M. Matthews. Advances in functional and structural MR image analysis and implementation as FSL. NeuroImage, 23(S1):208-219, 2004.",
      "command": "python3 run.py",
      "description": "FSL's SIENAX. Sienax estimates total brain tissue volume, from a single image, normalised for skull size. It calls a series of FSL programs: It first strips non-brain tissue, and then uses the brain and skull images to estimate the scaling between the subject's image and standard space. It then runs tissue segmentation to estimate the volume of brain tissue, and multiplies this by the estimated scaling factor, to reduce head-size-related variability between subjects. Inputs should be structural image (T1-weighted, T2-weighted, PD, etc) where the in-plane resolution is better than 2mm (ideally 1mm). Outputs consist of an archive containing the results of the analysis, as well as an HTML report summarizing the analysis findings.",
      "environment": {
        "FSLBROWSER": "/etc/alternatives/x-www-browser",
        "FSLDIR": "/usr/share/fsl/5.0",
        "FSLLOCKDIR": "",
        "FSLMACHINELIST": "",
        "FSLMULTIFILEQUIT": "TRUE",
        "FSLOUTPUTTYPE": "NIFTI_GZ",
        "FSLREMOTECALL": "",
        "FSLTCLSH": "/usr/bin/tclsh",
        "FSLWISH": "/usr/bin/wish",
        "LD_LIBRARY_PATH": "/usr/lib/fsl/5.0",
        "PATH": "/usr/lib/fsl/5.0:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
        "POSSUMDIR": "/usr/share/fsl/5.0"
      },
      "label": "FSL: SIENAX - Brain tissue volume, normalised for subject head size",
      "license": "Apache-2.0",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fsl-sienax",
      "source": "https://github.com/flywheel-apps/fsl-siena-sienax",
      "url": "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/SIENA",
      "version": "1.0.1_5.0"
    },
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "cite": "S.M. Smith, Y. Zhang, M. Jenkinson, J. Chen, P.M. Matthews, A. Federico, and N. De Stefano. Accurate, robust and automated longitudinal and cross-sectional brain change analysis. NeuroImage, 17(1):479-489, 2002.  S.M. Smith, M. Jenkinson, M.W. Woolrich, C.F. Beckmann, T.E.J. Behrens, H. Johansen-Berg, P.R. Bannister, M. De Luca, I. Drobnjak, D.E. Flitney, R. Niazy, J. Saunders, J. Vickers, Y. Zhang, N. De Stefano, J.M. Brady, and P.M. Matthews. Advances in functional and structural MR image analysis and implementation as FSL. NeuroImage, 23(S1):208-219, 2004.",
      "command": "python3 run.py",
      "description": "FSL's SIENAX. Sienax estimates total brain tissue volume, from a single image, normalised for skull size. It calls a series of FSL programs: It first strips non-brain tissue, and then uses the brain and skull images to estimate the scaling between the subject's image and standard space. It then runs tissue segmentation to estimate the volume of brain tissue, and multiplies this by the estimated scaling factor, to reduce head-size-related variability between subjects. Inputs should be structural image (T1-weighted, T2-weighted, PD, etc) where the in-plane resolution is better than 2mm (ideally 1mm). Outputs consist of an archive containing the results of the analysis, as well as an HTML report summarizing the analysis findings.",
      "environment": {
        "FSLBROWSER": "/etc/alternatives/x-www-browser",
        "FSLDIR": "/usr/share/fsl/5.0",
        "FSLLOCKDIR": "",
        "FSLMACHINELIST": "",
        "FSLMULTIFILEQUIT": "TRUE",
        "FSLOUTPUTTYPE": "NIFTI_GZ",
        "FSLREMOTECALL": "",
        "FSLTCLSH": "/usr/bin/tclsh",
        "FSLWISH": "/usr/bin/wish",
        "LD_LIBRARY_PATH": "/usr/lib/fsl/5.0",
        "PATH": "/usr/lib/fsl/5.0:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
        "POSSUMDIR": "/usr/share/fsl/5.0"
      },
      "label": "FSL: SIENAX - Brain tissue volume, normalised for subject head size",
      "license": "Apache-2.0",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fsl-sienax",
      "source": "https://github.com/flywheel-apps/fsl-siena-sienax",
      "url": "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/SIENA",
      "version": "1.0.0_5.0"
    }
  ],
  [
    {
      "author": "Sina Aslan, Ph.D.",
      "description": "Modified Brain Extraction Tool 2 (BET2) from FMRIB Software Library (FSL) v5.0 called SuperBET2 deletes non-brain tissue from an image of the whole head. It can also estimate the inner and outer skull surfaces, and outer scalp surface, if you have good quality T1.",
      "label": "FSL: SUPER Brain Extraction Tool (BET2)",
      "license": "Apache-2.0",
      "maintainer": "Flywheel Support <support@flywheel.io>",
      "name": "fsl-superbet2",
      "source": "https://github.com/flywheel-apps/fsl-superbet2",
      "url": "https://github.com/saslan-7/super-bet2",
      "version": "1.0.0_5.0.7"
    }
  ],
  [
    {
      "author": "FSL",
      "command": "python3 run.py",
      "description": "Estimates a distortion correction field given one or more pairs of images with opposite PE directions",
      "environment": {},
      "label": "FSL: TOPUP correction for susceptibility induced distortions",
      "license": "MIT",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fsl-topup",
      "source": "https://github.com/flywheel-apps/fsl-topup",
      "url": "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/topup",
      "version": "0.0.3"
    },
    {
      "author": "FSL",
      "command": "python3 run.py",
      "description": "Estimates a distortion correction field given one or more pairs of images with opposite PE directions",
      "environment": {},
      "label": "FSL: TOPUP correction for susceptibility induced distortions",
      "license": "MIT",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "fsl-topup",
      "source": "https://github.com/flywheel-apps/fsl-topup",
      "url": "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/topup",
      "version": "0.0.2"
    }
  ],
  [
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "description": "FSLMERGE (FMRIB) concatenates image files into a single output. This concatenation can be in time, or in X, Y or Z. All image dimensions (except for the one being concatenated over) must be the same in all input images. For example, this can be used to take multiple 3D files (eg as output by SPM) and create a single 4D image file. This Gear also supports the merger of diffusion data with bvec/bval files.",
      "label": "FSL: FSLMERGE - FMRIB Merge Tool (FSL v5.0)",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "fslmerge",
      "source": "https://github.com/scitran-apps/fslmerge",
      "url": "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Fslutils",
      "version": "0.1.2"
    },
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "description": "FSLMERGE (FMRIB) concatenates image files into a single output. This concatenation can be in time, or in X, Y or Z. All image dimensions (except for the one being concatenated over) must be the same in all input images. For example, this can be used to take multiple 3D files (eg as output by SPM) and create a single 4D image file. This Gear also supports the merger of diffusion data with bvec/bval files.",
      "label": "FSL: FSLMERGE - FMRIB Merge Tool (FSL v5.0)",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "fslmerge",
      "source": "https://github.com/scitran-apps/fslmerge",
      "url": "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Fslutils",
      "version": "0.1.1"
    },
    {
      "author": "Analysis Group, FMRIB, Oxford, UK.",
      "description": "FSLMERGE (FMRIB) concatenates image files into a single output. This concatenation can be in time, or in X, Y or Z. All image dimensions (except for the one being concatenated over) must be the same in all input images. For example, this can be used to take multiple 3D files (eg as output by SPM) and create a single 4D image file. This Gear also supports the merger of diffusion data with bvec/bval files.",
      "label": "FSL: FSLMERGE - FMRIB Merge Tool (FSL v5.0)",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "fslmerge",
      "source": "https://github.com/scitran-apps/fslmerge",
      "url": "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Fslutils",
      "version": "0.1"
    }
  ],
  [
    {
      "author": "Tinashe Michael Tapera",
      "cite": "",
      "command": "./fw_heudiconv_run.py",
      "description": "HeuDiConv-style BIDS curation on Flywheel. Flywheel HeuDiConv (or fw-heudiconv, pronounced /fwu di k n(v)/) is a Python-based toolkit that leverages the flexibility and comprehensiveness of HeuDiConv to curate neuroimaging data on Flywheel into a BIDS-valid format.",
      "label": "Flywheel HeuDiConv",
      "license": "Other",
      "maintainer": "Tinashe Michael Tapera",
      "name": "fw-heudiconv",
      "source": "",
      "url": "https://github.com/PennBBL/fw-heudiconv/wiki",
      "version": "0.1.15_0.1.0"
    }
  ],
  [
    {
      "author": "Richard Edden, et. al",
      "description": "Gannet is a software package designed for the analysis of edited magnetic resonance spectroscopy (MRS) data. Gannet runs in Matlab and is available as code rather than executables, empowering users to make local changes. Gannet is designed to run without user intervention, to remove operator variance from the quantification of edited MRS data. This Gear uses a compiled version from huawu02/gannet, which is modified to support latest generation GE P-Files, and is executed using the Matlab Compiler Runtime.",
      "label": "Gannet 3.0: Analysis of edited MRS data",
      "license": "Other",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "gannet",
      "source": "https://github.com/scitran-apps/gannet",
      "url": "http://www.gabamrs.com/",
      "version": "0.1.6_3.0"
    },
    {
      "author": "Richard Edden, et. al",
      "description": "Gannet is a software package designed for the analysis of edited magnetic resonance spectroscopy (MRS) data. Gannet runs in Matlab and is available as code rather than executables, empowering users to make local changes. Gannet is designed to run without user intervention, to remove operator variance from the quantification of edited MRS data. This Gear uses a compiled version from huawu02/gannet, which is modified to support latest generation GE P-Files, and is executed using the Matlab Compiler Runtime.",
      "label": "Gannet 3.0: Analysis of edited MRS data",
      "license": "Other",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "gannet",
      "source": "https://github.com/scitran-apps/gannet",
      "url": "http://www.gabamrs.com/",
      "version": "0.1.5_3.0"
    },
    {
      "author": "Richard Edden, et. al",
      "description": "Gannet is a software package designed for the analysis of edited magnetic resonance spectroscopy (MRS) data. Gannet runs in Matlab and is available as code rather than executables, empowering users to make local changes. Gannet is designed to run without user intervention, to remove operator variance from the quantification of edited MRS data. This Gear uses a compiled version from huawu02/gannet, which is modified to support latest generation GE P-Files, and is executed using the Matlab Compiler Runtime.",
      "label": "Gannet 3.0: Analysis of edited MRS data",
      "license": "Other",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "gannet",
      "source": "https://github.com/scitran-apps/gannet",
      "url": "http://www.gabamrs.com/",
      "version": "0.1.4_3.0"
    },
    {
      "author": "Richard Edden, et. al",
      "description": "Gannet is a software package designed for the analysis of edited magnetic resonance spectroscopy (MRS) data. Gannet runs in Matlab and is available as code rather than executables, empowering users to make local changes. Gannet is designed to run without user intervention, to remove operator variance from the quantification of edited MRS data. This Gear uses a compiled version from huawu02/gannet, which is modified to support latest generation GE P-Files, and is executed using the Matlab Compiler Runtime.",
      "label": "Gannet 2.1: Analysis of edited MRS data",
      "license": "Other",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "gannet",
      "source": "https://github.com/scitran-apps/gannet",
      "url": "http://www.gabamrs.com/",
      "version": "0.1.3_3.0"
    },
    {
      "author": "Richard Edden, et. al",
      "description": "Gannet is a software package designed for the analysis of edited magnetic resonance spectroscopy (MRS) data. Gannet runs in Matlab and is available as code rather than executables, empowering users to make local changes. Gannet is designed to run without user intervention, to remove operator variance from the quantification of edited MRS data. This Gear uses a compiled version from huawu02/gannet, which is modified to support latest generation GE P-Files, and is executed using the Matlab Compiler Runtime.",
      "label": "Gannet 2.1: Analysis of edited MRS data",
      "license": "Other",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "gannet",
      "source": "https://github.com/scitran-apps/gannet",
      "url": "http://www.gabamrs.com/",
      "version": "0.1.2_2.1"
    },
    {
      "author": "Richard Edden, et. al",
      "description": "Gannet is a software package designed for the analysis of edited magnetic resonance spectroscopy (MRS) data. Gannet runs in Matlab and is available as code rather than executables, empowering users to make local changes. Gannet is designed to run without user intervention, to remove operator variance from the quantification of edited MRS data. This Gear uses a compiled version from huawu02/gannet, which is modified to support latest generation GE P-Files, and is executed using the Matlab Compiler Runtime.",
      "label": "Gannet: Analysis of edited MRS data using Gannet version 2.1",
      "license": "Other",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "gannet",
      "source": "https://github.com/scitran-apps/gannet",
      "url": "http://www.gabamrs.com/",
      "version": "0.1.0_2.1"
    }
  ],
  [
    {
      "author": "Human Connectome Project",
      "cite": "Glasser M. F., Sotiropoulos S. N., Wilson J. A., Coalson T. S., Fischl B., Andersson J. L.,  Consortium, W. U.-M. H. (2013). The minimal preprocessing pipelines for the Human Connectome Project. NeuroImage, 80, 105124.",
      "command": "/flywheel/v0/run.py",
      "description": "Runs the diffusion preprocessing steps of the Human Connectome Project Minimal Preprocessing Pipeline described in Glasser et al. 2013. This includes correction for EPI distortion (using FSL topup), correction for motion and eddy-current distortion (using FSL eddy), and registration to subject anatomy. In addition, this Gear generates a QC mosaic. NOTE: This Gear requires that the HCP-Structural Gear has been run - the output of which is used here. This Gear allows input of up to 4 diffusion acquisitions.",
      "label": "HCP: Diffusion Preprocessing Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-diff",
      "source": "https://github.com/flywheel-apps/hcp-diff",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "1.0.1_4.0.1"
    },
    {
      "author": "Human Connectome Project",
      "cite": "Glasser M. F., Sotiropoulos S. N., Wilson J. A., Coalson T. S., Fischl B., Andersson J. L.,  Consortium, W. U.-M. H. (2013). The minimal preprocessing pipelines for the Human Connectome Project. NeuroImage, 80, 105124.",
      "command": "/flywheel/v0/run.py",
      "description": "Runs the diffusion preprocessing steps of the Human Connectome Project Minimal Preprocessing Pipeline described in Glasser et al. 2013. This includes correction for EPI distortion (using FSL topup), correction for motion and eddy-current distortion (using FSL eddy), and registration to subject anatomy. In addition, this Gear generates a QC mosaic. NOTE: This Gear requires that the HCP-Structural Gear has been run - the output of which is used here. This Gear allows input of up to 4 diffusion acquisitions.",
      "label": "HCP: Diffusion Preprocessing Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-diff",
      "source": "https://github.com/flywheel-apps/hcp-diff",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "0.2.0_4.0.1"
    },
    {
      "author": "Human Connectome Project",
      "cite": "Glasser M. F., Sotiropoulos S. N., Wilson J. A., Coalson T. S., Fischl B., Andersson J. L.,  Consortium, W. U.-M. H. (2013). The minimal preprocessing pipelines for the Human Connectome Project. NeuroImage, 80, 105124.",
      "description": "Runs the diffusion preprocessing steps of the Human Connectome Project Minimal Preprocessing Pipeline described in Glasser et al. 2013. This includes correction for EPI distortion (using FSL topup), correction for motion and eddy-current distortion (using FSL eddy), and registration to subject anatomy. In addition, this Gear generates a QC mosaic. NOTE: This Gear requires that the HCP-Structural Gear has been run - the output of which is used here. This Gear allows input of up to 4 diffusion acquisitions.",
      "label": "HCP: Diffusion Preprocessing Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-diff",
      "source": "https://github.com/flywheel-apps/hcp-diff",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "0.1.5"
    },
    {
      "author": "Human Connectome Project",
      "cite": "Glasser M. F., Sotiropoulos S. N., Wilson J. A., Coalson T. S., Fischl B., Andersson J. L.,  Consortium, W. U.-M. H. (2013). The minimal preprocessing pipelines for the Human Connectome Project. NeuroImage, 80, 105124.",
      "description": "Runs the diffusion preprocessing steps of the Human Connectome Project Minimal Preprocessing Pipeline described in Glasser et al. 2013. This includes correction for EPI distortion (using FSL topup), correction for motion and eddy-current distortion (using FSL eddy), and registration to subject anatomy. In addition, this Gear generates a QC mosaic. NOTE: This Gear requires that the HCP-Structural Gear has been run - the output of which is used here. This Gear allows input of up to 4 diffusion acquisitions.",
      "label": "HCP: Diffusion Preprocessing Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-diff",
      "source": "https://github.com/flywheel-apps/hcp-diff",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "0.1.4"
    },
    {
      "author": "Human Connectome Project",
      "cite": "Glasser M. F., Sotiropoulos S. N., Wilson J. A., Coalson T. S., Fischl B., Andersson J. L.,  Consortium, W. U.-M. H. (2013). The minimal preprocessing pipelines for the Human Connectome Project. NeuroImage, 80, 105124.",
      "description": "Runs the diffusion preprocessing steps of the Human Connectome Project Minimal Preprocessing Pipeline described in Glasser et al. 2013. This includes correction for EPI distortion (using FSL topup), correction for motion and eddy-current distortion (using FSL eddy), and registration to subject anatomy. In addition, this Gear generates a QC mosaic. NOTE: This Gear requires that the HCP-Structural Gear has been run - the output of which is used here. This Gear allows input of up to 4 diffusion acquisitions.",
      "label": "HCP: Diffusion Preprocessing Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-diff",
      "source": "https://github.com/flywheel-apps/hcp-diff",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "0.1.3"
    },
    {
      "author": "Human Connectome Project",
      "cite": "Glasser M. F., Sotiropoulos S. N., Wilson J. A., Coalson T. S., Fischl B., Andersson J. L.,  Consortium, W. U.-M. H. (2013). The minimal preprocessing pipelines for the Human Connectome Project. NeuroImage, 80, 105124.",
      "description": "Runs the diffusion preprocessing steps of the Human Connectome Project Minimal Preprocessing Pipeline described in Glasser et al. 2013. This includes correction for EPI distortion (using FSL topup), correction for motion and eddy-current distortion (using FSL eddy), and registration to subject anatomy. In addition, this Gear generates a QC mosaic. This Gear requires that the HCP-Structural gear has been run - the output of which is used here. This Gear allows input of up to 4 diffusion acquisitions.",
      "label": "HCP: Diffusion Preprocessing Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-diff",
      "source": "https://github.com/flywheel-apps/hcp-diff",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "0.1.2"
    },
    {
      "author": "Human Connectome Project",
      "description": "Runs the diffusion preprocessing steps of the Human Connectome Project Minimal Preprocessing Pipeline described in Glasser et al. 2013. This includes correction for EPI distortion (using FSL topup), correction for motion and eddy-current distortion (using FSL eddy), and registration to subject anatomy. In addition, this Gear generates a QC mosaic. This Gear requires that the HCP-Structural gear has been run - the output of which is used here. This Gear allows input of up to 4 diffusion acquisitions.",
      "label": "HCP: Diffusion Preprocessing Pipeline",
      "license": "Apache-2.0",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-diff",
      "source": "https://github.com/flywheel-apps/hcp-diff",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "0.1.0"
    }
  ],
  [
    {
      "author": "Human Connectome Project",
      "cite": "Glasser M. F., Sotiropoulos S. N., Wilson J. A., Coalson T. S., Fischl B., Andersson J. L.,  Consortium, W. U.-M. H. (2013). The minimal preprocessing pipelines for the Human Connectome Project. NeuroImage, 80, 105124.",
      "command": "/flywheel/v0/run.py",
      "description": "Runs the functional preprocessing steps of the Human Connectome Project Minimal Preprocessing Pipeline described in Glasser et al. 2013. Currently, this Gear includes v4.0-alpha release of fMRIVolume and fMRISurface, as well as generating some helpful QC images. NOTE: this Gear requires that the HCP structural preprocessing pipeline has been run, as the output of that pipeline must be provided as input to this Gear.",
      "label": "HCP: Functional Preprocessing Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-func",
      "source": "https://github.com/flywheel-apps/hcp-func",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "1.0.1_4.0.1"
    },
    {
      "author": "Human Connectome Project",
      "cite": "Glasser M. F., Sotiropoulos S. N., Wilson J. A., Coalson T. S., Fischl B., Andersson J. L.,  Consortium, W. U.-M. H. (2013). The minimal preprocessing pipelines for the Human Connectome Project. NeuroImage, 80, 105124.",
      "command": "/flywheel/v0/run.py",
      "description": "Runs the functional preprocessing steps of the Human Connectome Project Minimal Preprocessing Pipeline described in Glasser et al. 2013. Currently, this Gear includes v4.0-alpha release of fMRIVolume and fMRISurface, as well as generating some helpful QC images. NOTE: this Gear requires that the HCP structural preprocessing pipeline has been run, as the output of that pipeline must be provided as input to this Gear.",
      "label": "HCP: Functional Preprocessing Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-func",
      "source": "https://github.com/flywheel-apps/hcp-func",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "0.2.0_4.0.1"
    },
    {
      "author": "Human Connectome Project",
      "cite": "Glasser M. F., Sotiropoulos S. N., Wilson J. A., Coalson T. S., Fischl B., Andersson J. L.,  Consortium, W. U.-M. H. (2013). The minimal preprocessing pipelines for the Human Connectome Project. NeuroImage, 80, 105124.",
      "description": "Runs the functional preprocessing steps of the Human Connectome Project Minimal Preprocessing Pipeline described in Glasser et al. 2013. Currently, this Gear includes v4.0-alpha release of fMRIVolume and fMRISurface, as well as generating some helpful QC images. NOTE: this Gear requires that the HCP structural preprocessing pipeline has been run, as the output of that pipeline must be provided as input to this Gear.",
      "label": "HCP: Functional Preprocessing Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-func",
      "source": "https://github.com/flywheel-apps/hcp-func",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "0.1.7"
    },
    {
      "author": "Human Connectome Project",
      "cite": "Glasser M. F., Sotiropoulos S. N., Wilson J. A., Coalson T. S., Fischl B., Andersson J. L.,  Consortium, W. U.-M. H. (2013). The minimal preprocessing pipelines for the Human Connectome Project. NeuroImage, 80, 105124.",
      "description": "Runs the functional preprocessing steps of the Human Connectome Project Minimal Preprocessing Pipeline described in Glasser et al. 2013. Currently, this Gear includes v4.0-alpha release of fMRIVolume and fMRISurface, as well as generating some helpful QC images. NOTE: this Gear requires that the HCP structural preprocessing pipeline has been run, as the output of that pipeline must be provided as input to this Gear.",
      "label": "HCP: Functional Preprocessing Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-func",
      "source": "https://github.com/flywheel-apps/hcp-func",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "0.1.6"
    },
    {
      "author": "Human Connectome Project",
      "cite": "Glasser M. F., Sotiropoulos S. N., Wilson J. A., Coalson T. S., Fischl B., Andersson J. L.,  Consortium, W. U.-M. H. (2013). The minimal preprocessing pipelines for the Human Connectome Project. NeuroImage, 80, 105124.",
      "description": "Runs the functional preprocessing steps of the Human Connectome Project Minimal Preprocessing Pipeline described in Glasser et al. 2013. Currently, this Gear includes v4.0-alpha release of fMRIVolume and fMRISurface, as well as generating some helpful QC images. NOTE: this Gear requires that the HCP structural preprocessing pipeline has been run, as the output of that pipeline must be provided as input to this Gear.",
      "label": "HCP: Functional Preprocessing Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-func",
      "source": "https://github.com/flywheel-apps/hcp-func",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "0.1.4"
    },
    {
      "author": "Human Connectome Project",
      "cite": "Glasser M. F., Sotiropoulos S. N., Wilson J. A., Coalson T. S., Fischl B., Andersson J. L.,  Consortium, W. U.-M. H. (2013). The minimal preprocessing pipelines for the Human Connectome Project. NeuroImage, 80, 105124.",
      "description": "Runs the functional preprocessing steps of the Human Connectome Project Minimal Preprocessing Pipeline described in Glasser et al. 2013. Currently, this Gear includes v4.0-alpha release of fMRIVolume and fMRISurface, as well as generating some helpful QC images. NOTE: this Gear requires that the HCP structural preprocessing pipeline has been run, as the output of that pipeline must be provided as input to this Gear.",
      "label": "HCP: Functional Preprocessing Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-func",
      "source": "https://github.com/flywheel-apps/hcp-func",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "0.1.3"
    },
    {
      "author": "Human Connectome Project",
      "cite": "Glasser M. F., Sotiropoulos S. N., Wilson J. A., Coalson T. S., Fischl B., Andersson J. L.,  Consortium, W. U.-M. H. (2013). The minimal preprocessing pipelines for the Human Connectome Project. NeuroImage, 80, 105124.",
      "description": "Runs the functional preprocessing steps of the Human Connectome Project Minimal Preprocessing Pipeline described in Glasser et al. 2013. Currently, this Gear includes v4.0-alpha release of fMRIVolume and fMRISurface, as well as generating some helpful QC images. Note this Gear requires that the HCP structural preprocessing pipeline has been run, as the output of that pipeline must be provided as input.",
      "label": "HCP: Functional Preprocessing Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-func",
      "source": "https://github.com/flywheel-apps/hcp-func",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "0.1.2"
    },
    {
      "author": "Human Connectome Project",
      "description": "Runs the functional preprocessing steps of the Human Connectome Project Minimal Preprocessing Pipeline described in Glasser et al. 2013. Currently, this Gear includes v4.0-alpha release of fMRIVolume and fMRISurface, as well as generating some helpful QC images. Note this Gear requires that the HCP structural preprocessing pipeline has been run, as the output of that pipeline must be provided as input.",
      "label": "HCP: Functional Preprocessing Pipeline",
      "license": "Apache-2.0",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-func",
      "source": "https://github.com/flywheel-apps/hcp-func",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "0.1.0"
    }
  ],
  [
    {
      "author": "Human Connectome Project",
      "cite": "(1) G. Salimi-Khorshidi, G. Douaud, C.F. Beckmann, M.F. Glasser, L. Griffanti S.M. Smith. Automatic denoising of functional MRI data: Combining independent component analysis and hierarchical fusion of classifiers. NeuroImage, 90:449-68, 2014 (2) L. Griffanti, G. Salimi-Khorshidi, C.F. Beckmann, E.J. Auerbach, G. Douaud, C.E. Sexton, E. Zsoldos, K. Ebmeier, N. Filippini, C.E. Mackay, S. Moeller, J.G. Xu, E. Yacoub, G. Baselli, K. Ugurbil, K.L. Miller, and S.M. Smith. ICA-based artefact removal and accelerated fMRI acquisition for improved resting state network imaging. NeuroImage, 95:232-47, 2014",
      "description": "Runs ICA-FIX denoising on functional data preprocessed according to the HCP Minimal Preprocessing Pipeline. This Gear is based on scripts from the v4.0-alpha release of the ICAFIX, PostFix, and RestingStateStats pipelines. NOTE: This Gear requires that HCP-STRUCT and HCP-FUNC Gears have been run, as the outputs of those gears are required inputs here. Also note that more than 1 HCP-FUNC output can be provided as input.",
      "label": "HCP: ICAFIX Functional Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-icafix",
      "source": "https://github.com/flywheel-apps/hcp-icafix",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "0.2.0"
    },
    {
      "author": "Human Connectome Project",
      "cite": "(1) G. Salimi-Khorshidi, G. Douaud, C.F. Beckmann, M.F. Glasser, L. Griffanti S.M. Smith. Automatic denoising of functional MRI data: Combining independent component analysis and hierarchical fusion of classifiers. NeuroImage, 90:449-68, 2014 (2) L. Griffanti, G. Salimi-Khorshidi, C.F. Beckmann, E.J. Auerbach, G. Douaud, C.E. Sexton, E. Zsoldos, K. Ebmeier, N. Filippini, C.E. Mackay, S. Moeller, J.G. Xu, E. Yacoub, G. Baselli, K. Ugurbil, K.L. Miller, and S.M. Smith. ICA-based artefact removal and accelerated fMRI acquisition for improved resting state network imaging. NeuroImage, 95:232-47, 2014",
      "description": "Runs ICA-FIX denoising on functional data preprocessed according to the HCP Minimal Preprocessing Pipeline. This Gear is based on scripts from the v4.0-alpha release of the ICAFIX, PostFix, and RestingStateStats pipelines. NOTE: This Gear requires that HCP-STRUCT and HCP-FUNC Gears have been run, as the outputs of those gears are required inputs here. Also note that more than 1 HCP-FUNC output can be provided as input.",
      "label": "HCP: ICAFIX Functional Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-icafix",
      "source": "https://github.com/flywheel-apps/hcp-icafix",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "0.1.7"
    },
    {
      "author": "Human Connectome Project",
      "cite": "(1) G. Salimi-Khorshidi, G. Douaud, C.F. Beckmann, M.F. Glasser, L. Griffanti S.M. Smith. Automatic denoising of functional MRI data: Combining independent component analysis and hierarchical fusion of classifiers. NeuroImage, 90:449-68, 2014 (2) L. Griffanti, G. Salimi-Khorshidi, C.F. Beckmann, E.J. Auerbach, G. Douaud, C.E. Sexton, E. Zsoldos, K. Ebmeier, N. Filippini, C.E. Mackay, S. Moeller, J.G. Xu, E. Yacoub, G. Baselli, K. Ugurbil, K.L. Miller, and S.M. Smith. ICA-based artefact removal and accelerated fMRI acquisition for improved resting state network imaging. NeuroImage, 95:232-47, 2014",
      "description": "Runs ICA-FIX denoising on functional data preprocessed according to the HCP Minimal Preprocessing Pipeline. This Gear is based on scripts from the v4.0-alpha release of the ICAFIX, PostFix, and RestingStateStats pipelines. NOTE: This Gear requires that HCP-STRUCT and HCP-FUNC Gears have been run, as the outputs of those gears are required inputs here. Also note that more than 1 HCP-FUNC output can be provided as input.",
      "label": "HCP: ICAFIX Functional Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-icafix",
      "source": "https://github.com/flywheel-apps/hcp-icafix",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "0.1.6"
    },
    {
      "author": "Human Connectome Project",
      "cite": "(1) G. Salimi-Khorshidi, G. Douaud, C.F. Beckmann, M.F. Glasser, L. Griffanti S.M. Smith. Automatic denoising of functional MRI data: Combining independent component analysis and hierarchical fusion of classifiers. NeuroImage, 90:449-68, 2014 (2) L. Griffanti, G. Salimi-Khorshidi, C.F. Beckmann, E.J. Auerbach, G. Douaud, C.E. Sexton, E. Zsoldos, K. Ebmeier, N. Filippini, C.E. Mackay, S. Moeller, J.G. Xu, E. Yacoub, G. Baselli, K. Ugurbil, K.L. Miller, and S.M. Smith. ICA-based artefact removal and accelerated fMRI acquisition for improved resting state network imaging. NeuroImage, 95:232-47, 2014",
      "description": "Runs ICA-FIX denoising on functional data preprocessed according to the HCP Minimal Preprocessing Pipeline. This Gear is based on scripts from the v4.0-alpha release of the ICAFIX, PostFix, and RestingStateStats pipelines. NOTE: This Gear requires that HCP-STRUCT and HCP-FUNC Gears have been run, as the outputs of those gears are required inputs here. Also note that more than 1 HCP-FUNC output can be provided as input.",
      "label": "HCP: ICAFIX Functional Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-icafix",
      "source": "https://github.com/flywheel-apps/hcp-icafix",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "0.1.5"
    },
    {
      "author": "Human Connectome Project",
      "cite": "(1) G. Salimi-Khorshidi, G. Douaud, C.F. Beckmann, M.F. Glasser, L. Griffanti S.M. Smith. Automatic denoising of functional MRI data: Combining independent component analysis and hierarchical fusion of classifiers. NeuroImage, 90:449-68, 2014 (2) L. Griffanti, G. Salimi-Khorshidi, C.F. Beckmann, E.J. Auerbach, G. Douaud, C.E. Sexton, E. Zsoldos, K. Ebmeier, N. Filippini, C.E. Mackay, S. Moeller, J.G. Xu, E. Yacoub, G. Baselli, K. Ugurbil, K.L. Miller, and S.M. Smith. ICA-based artefact removal and accelerated fMRI acquisition for improved resting state network imaging. NeuroImage, 95:232-47, 2014",
      "description": "Runs ICA-FIX denoising on functional data preprocessed according to the HCP Minimal Preprocessing Pipeline. This Gear is based on scripts from the v4.0-alpha release of the ICAFIX, PostFix, and RestingStateStats pipelines. NOTE: This Gear requires that HCP-STRUCT and HCP-FUNC Gears have been run, as the outputs of those gears are required inputs here. Also note that more than 1 HCP-FUNC output can be provided as input.",
      "label": "HCP: ICAFIX Functional Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-icafix",
      "source": "https://github.com/flywheel-apps/hcp-icafix",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "0.1.4"
    },
    {
      "author": "Human Connectome Project",
      "cite": "(1) G. Salimi-Khorshidi, G. Douaud, C.F. Beckmann, M.F. Glasser, L. Griffanti S.M. Smith. Automatic denoising of functional MRI data: Combining independent component analysis and hierarchical fusion of classifiers. NeuroImage, 90:449-68, 2014 (2) L. Griffanti, G. Salimi-Khorshidi, C.F. Beckmann, E.J. Auerbach, G. Douaud, C.E. Sexton, E. Zsoldos, K. Ebmeier, N. Filippini, C.E. Mackay, S. Moeller, J.G. Xu, E. Yacoub, G. Baselli, K. Ugurbil, K.L. Miller, and S.M. Smith. ICA-based artefact removal and accelerated fMRI acquisition for improved resting state network imaging. NeuroImage, 95:232-47, 2014",
      "description": "Runs ICA-FIX denoising on functional data preprocessed according to the HCP Minimal Preprocessing Pipeline. This Gear is based on scripts from the v4.0-alpha release of the ICAFIX, PostFix, and RestingStateStats pipelines. NOTE: This Gear requires that HCP-STRUCT and HCP-FUNC Gears have been run, as the outputs of those gears are required inputs here. Also note that more than 1 HCP-FUNC output can be provided as input.",
      "label": "HCP: ICAFIX Functional Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-icafix",
      "source": "https://github.com/flywheel-apps/hcp-icafix",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "0.1.3"
    },
    {
      "author": "Human Connectome Project",
      "cite": "(1) G. Salimi-Khorshidi, G. Douaud, C.F. Beckmann, M.F. Glasser, L. Griffanti S.M. Smith. Automatic denoising of functional MRI data: Combining independent component analysis and hierarchical fusion of classifiers. NeuroImage, 90:449-68, 2014 (2) L. Griffanti, G. Salimi-Khorshidi, C.F. Beckmann, E.J. Auerbach, G. Douaud, C.E. Sexton, E. Zsoldos, K. Ebmeier, N. Filippini, C.E. Mackay, S. Moeller, J.G. Xu, E. Yacoub, G. Baselli, K. Ugurbil, K.L. Miller, and S.M. Smith. ICA-based artefact removal and accelerated fMRI acquisition for improved resting state network imaging. NeuroImage, 95:232-47, 2014",
      "description": "Runs ICA-FIX denoising on functional data preprocessed according to the HCP Minimal Preprocessing Pipeline. This Gear is based on scripts from the v4.0-alpha release of the ICAFIX, PostFix, and RestingStateStats pipelines.",
      "label": "HCP: ICAFIX Functional Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-icafix",
      "source": "https://github.com/flywheel-apps/hcp-icafix",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "0.1.2"
    },
    {
      "author": "Human Connectome Project",
      "cite": "(1) G. Salimi-Khorshidi, G. Douaud, C.F. Beckmann, M.F. Glasser, L. Griffanti S.M. Smith. Automatic denoising of functional MRI data: Combining independent component analysis and hierarchical fusion of classifiers. NeuroImage, 90:449-68, 2014 (2) L. Griffanti, G. Salimi-Khorshidi, C.F. Beckmann, E.J. Auerbach, G. Douaud, C.E. Sexton, E. Zsoldos, K. Ebmeier, N. Filippini, C.E. Mackay, S. Moeller, J.G. Xu, E. Yacoub, G. Baselli, K. Ugurbil, K.L. Miller, and S.M. Smith. ICA-based artefact removal and accelerated fMRI acquisition for improved resting state network imaging. NeuroImage, 95:232-47, 2014",
      "description": "Runs ICA-FIX denoising on functional data preprocessed according to the HCP Minimal Preprocessing Pipeline. This Gear is based on scripts from the v4.0-alpha release of the ICAFIX, PostFix, and RestingStateStats pipelines.",
      "label": "HCP: ICAFIX Functional Pipeline",
      "license": "Apache-2.0",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-icafix",
      "source": "https://github.com/flywheel-apps/hcp-icafix",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "0.1.0"
    }
  ],
  [
    {
      "author": "Human Connectome Project",
      "cite": "Glasser M. F., Sotiropoulos S. N., Wilson J. A., Coalson T. S., Fischl B., Andersson J. L.,  Consortium, W. U.-M. H. (2013). The minimal preprocessing pipelines for the Human Connectome Project. NeuroImage, 80, 105124.",
      "command": "/flywheel/v0/run.py",
      "description": "Runs the structural preprocessing steps of the Human Connectome Project Minimal Preprocessing Pipeline, described in Glasser et al. 2013. Currently this includes v4.0-alpha release of PreFreeSurfer, FreeSurfer, and PostFreeSurfer pipelines. This Gear also generates some helpful QC images. NOTE: This Gear is a prerequisite for other Gears in the HCP suite.",
      "label": "HCP: Structural Preprocessing Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-struct",
      "source": "https://github.com/flywheel-apps/hcp-struct",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "1.0.1_4.0.1"
    },
    {
      "author": "Human Connectome Project",
      "cite": "Glasser M. F., Sotiropoulos S. N., Wilson J. A., Coalson T. S., Fischl B., Andersson J. L.,  Consortium, W. U.-M. H. (2013). The minimal preprocessing pipelines for the Human Connectome Project. NeuroImage, 80, 105124.",
      "command": "/flywheel/v0/run.py",
      "description": "Runs the structural preprocessing steps of the Human Connectome Project Minimal Preprocessing Pipeline, described in Glasser et al. 2013. Currently this includes v4.0-alpha release of PreFreeSurfer, FreeSurfer, and PostFreeSurfer pipelines. This Gear also generates some helpful QC images. NOTE: This Gear is a prerequisite for other Gears in the HCP suite.",
      "label": "HCP: Structural Preprocessing Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-struct",
      "source": "https://github.com/flywheel-apps/hcp-struct",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "1.0.0_4.0.0"
    },
    {
      "author": "Human Connectome Project",
      "cite": "Glasser M. F., Sotiropoulos S. N., Wilson J. A., Coalson T. S., Fischl B., Andersson J. L.,  Consortium, W. U.-M. H. (2013). The minimal preprocessing pipelines for the Human Connectome Project. NeuroImage, 80, 105124.",
      "description": "Runs the structural preprocessing steps of the Human Connectome Project Minimal Preprocessing Pipeline, described in Glasser et al. 2013. Currently this includes v4.0-alpha release of PreFreeSurfer, FreeSurfer, and PostFreeSurfer pipelines. This Gear also generates some helpful QC images. NOTE: This Gear is a prerequisite for other Gears in the HCP suite.",
      "label": "HCP: Structural Preprocessing Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-struct",
      "source": "https://github.com/flywheel-apps/hcp-struct",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "0.1.8"
    },
    {
      "author": "Human Connectome Project",
      "cite": "Glasser M. F., Sotiropoulos S. N., Wilson J. A., Coalson T. S., Fischl B., Andersson J. L.,  Consortium, W. U.-M. H. (2013). The minimal preprocessing pipelines for the Human Connectome Project. NeuroImage, 80, 105124.",
      "description": "Runs the structural preprocessing steps of the Human Connectome Project Minimal Preprocessing Pipeline, described in Glasser et al. 2013. Currently this includes v4.0-alpha release of PreFreeSurfer, FreeSurfer, and PostFreeSurfer pipelines. This Gear also generates some helpful QC images. NOTE: This Gear is a prerequisite for other Gears in the HCP suite.",
      "label": "HCP: Structural Preprocessing Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-struct",
      "source": "https://github.com/flywheel-apps/hcp-struct",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "0.1.7"
    },
    {
      "author": "Human Connectome Project",
      "cite": "Glasser M. F., Sotiropoulos S. N., Wilson J. A., Coalson T. S., Fischl B., Andersson J. L.,  Consortium, W. U.-M. H. (2013). The minimal preprocessing pipelines for the Human Connectome Project. NeuroImage, 80, 105124.",
      "description": "Runs the structural preprocessing steps of the Human Connectome Project Minimal Preprocessing Pipeline, described in Glasser et al. 2013. Currently this includes v4.0-alpha release of PreFreeSurfer, FreeSurfer, and PostFreeSurfer pipelines. This Gear also generates some helpful QC images. NOTE: This Gear is a prerequisite for other Gears in the HCP suite.",
      "label": "HCP: Structural Preprocessing Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-struct",
      "source": "https://github.com/flywheel-apps/hcp-struct",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "0.1.6"
    },
    {
      "author": "Human Connectome Project",
      "cite": "Glasser M. F., Sotiropoulos S. N., Wilson J. A., Coalson T. S., Fischl B., Andersson J. L.,  Consortium, W. U.-M. H. (2013). The minimal preprocessing pipelines for the Human Connectome Project. NeuroImage, 80, 105124.",
      "description": "Runs the structural preprocessing steps of the Human Connectome Project Minimal Preprocessing Pipeline, described in Glasser et al. 2013. Currently this includes v4.0-alpha release of PreFreeSurfer, FreeSurfer, and PostFreeSurfer pipelines. This Gear also generates some helpful QC images.",
      "label": "HCP: Structural Preprocessing Pipeline",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-struct",
      "source": "https://github.com/flywheel-apps/hcp-struct",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "0.1.5"
    },
    {
      "author": "Human Connectome Project",
      "description": "Runs the structural preprocessing steps of the Human Connectome Project Minimal Preprocessing Pipeline, described in Glasser et al. 2013. Currently this includes v4.0-alpha release of PreFreeSurfer, FreeSurfer, and PostFreeSurfer pipelines. This Gear also generates some helpful QC images.",
      "label": "HCP: Structural Preprocessing Pipeline",
      "license": "Apache-2.0",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-struct",
      "source": "https://github.com/flywheel-apps/hcp-struct",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "0.1.3"
    },
    {
      "author": "Human Connectome Project",
      "description": "Run HCP structural pipeline: PreFreeSurfer, FreeSurfer, PostFreeSurfer, and generate QC images",
      "label": "HCP Structural Pipeline",
      "license": "Apache-2.0",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-struct",
      "source": "https://github.com/flywheel-apps/hcp-struct",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "0.1.2"
    },
    {
      "author": "Human Connectome Project",
      "description": "Run HCP structural pipeline: PreFreeSurfer, FreeSurfer, PostFreeSurfer, and generate QC images",
      "label": "HCP Structural Pipeline",
      "license": "Apache-2.0",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "hcp-struct",
      "source": "https://github.com/flywheel-apps/hcp-struct",
      "url": "https://github.com/Washington-University/Pipelines",
      "version": "0.1.1"
    }
  ],
  [
    {
      "author": "Schneider Lab, University of Pittsburgh",
      "description": "Computes a transformation of multi-shell diffusion weighted data to a set of Spherical Harmonic coefficients and outputs 4D Spherical Harmonic coefficient data. This is a first step in the Schneider Lab HDFT diffusion reconstruction process. See: Pathak, S. K., Fissell, C., Krishnaswamy, D., Aggarwal, S., Hachey, R., Schneider, W. (2015). Diffusion reconstruction by combining spherical harmonics and generalized q-sampling imaging. ISMRM, Toronto, Canada.",
      "label": "HDFT Subsampled Diffusion Reconstruction",
      "license": "GPL-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "hdft-subsampled-recon",
      "source": "https://github.com/schlabhdft/ALDIT",
      "url": "http://www.lrdc.pitt.edu/schneiderlab/",
      "version": "0.0.1"
    }
  ],
  [
    {
      "author": "Prantik Kundu",
      "cite": "Kundu, P., Brenowitz, N.D., Voon, V., Worbe, Y., Vertes, P.E., Inati, S.J., Saad, Z.S., Bandettini, P.A. & Bullmore, E.T. Integrated strategy for improving functional connectivity mapping using multiecho fMRI. PNAS (2013). Kundu, P., Inati, S.J., Evans, J.W., Luh, W.M. & Bandettini, P.A. Differentiating BOLD and non-BOLD signals in fMRI time series using multi-echo EPI. NeuroImage (2011). http://dx.doi.org/10.1016/j.neuroimage.2011.12.028",
      "description": "Multi-Echo Independent Components Analysis (ME-ICA) is a method for fMRI analysis and denoising based on the T2* decay of BOLD signals, as measured using multi-echo fMRI. ME-ICA decomposes multi-echo fMRI datasets into independent components (ICs) using FastICA, then categorizes ICs as BOLD or noise using their BOLD and non-BOLD weightings (measured as Kappa and Rho values, respectively). Removing non-BOLD weighted components robustly denoises data for motion, physiology and scanner artifacts, in a simple and physically principled way. Pipeline includes: 1. Preprocess multi-echo datasets and apply multi-echo ICA based on spatial concatenation. 2. Calculation of motion parameters based on images with highest contrast. 3. Application of motion correction and coregistration parameters. 4. EPI preprocessing (temporal alignment, smoothing, etc) in appropriate order. 5. Compute PCA and ICA in conjunction with TE-dependence analysis.",
      "label": "ME-ICA: Multi-Echo Independent Components Analysis",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "me-ica",
      "source": "https://github.com/flywheel-apps/me-ica",
      "url": "https://github.com/ME-ICA/me-ica/blob/master/README.meica",
      "version": "0.3.4_3.2beta1"
    },
    {
      "author": "Prantik Kundu",
      "cite": "Kundu, P., Brenowitz, N.D., Voon, V., Worbe, Y., Vertes, P.E., Inati, S.J., Saad, Z.S., Bandettini, P.A. & Bullmore, E.T. Integrated strategy for improving functional connectivity mapping using multiecho fMRI. PNAS (2013). Kundu, P., Inati, S.J., Evans, J.W., Luh, W.M. & Bandettini, P.A. Differentiating BOLD and non-BOLD signals in fMRI time series using multi-echo EPI. NeuroImage (2011). http://dx.doi.org/10.1016/j.neuroimage.2011.12.028",
      "description": "Multi-Echo Independent Components Analysis (ME-ICA) is a method for fMRI analysis and denoising based on the T2* decay of BOLD signals, as measured using multi-echo fMRI. ME-ICA decomposes multi-echo fMRI datasets into independent components (ICs) using FastICA, then categorizes ICs as BOLD or noise using their BOLD and non-BOLD weightings (measured as Kappa and Rho values, respectively). Removing non-BOLD weighted components robustly denoises data for motion, physiology and scanner artifacts, in a simple and physically principled way. Pipeline includes: 1. Preprocess multi-echo datasets and apply multi-echo ICA based on spatial concatenation. 2. Calculation of motion parameters based on images with highest contrast. 3. Application of motion correction and coregistration parameters. 4. EPI preprocessing (temporal alignment, smoothing, etc) in appropriate order. 5. Compute PCA and ICA in conjunction with TE-dependence analysis.",
      "label": "ME-ICA: Multi-Echo Independent Components Analysis",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "me-ica",
      "source": "https://github.com/flywheel-apps/me-ica",
      "url": "https://github.com/ME-ICA/me-ica/blob/master/README.meica",
      "version": "0.2.4"
    },
    {
      "author": "Prantik Kundu",
      "cite": "Kundu, P., Brenowitz, N.D., Voon, V., Worbe, Y., Vertes, P.E., Inati, S.J., Saad, Z.S., Bandettini, P.A. & Bullmore, E.T. Integrated strategy for improving functional connectivity mapping using multiecho fMRI. PNAS (2013). Kundu, P., Inati, S.J., Evans, J.W., Luh, W.M. & Bandettini, P.A. Differentiating BOLD and non-BOLD signals in fMRI time series using multi-echo EPI. NeuroImage (2011). http://dx.doi.org/10.1016/j.neuroimage.2011.12.028",
      "description": "Multi-Echo Independent Components Analysis (ME-ICA) is a method for fMRI analysis and denoising based on the T2* decay of BOLD signals, as measured using multi-echo fMRI. ME-ICA decomposes multi-echo fMRI datasets into independent components (ICs) using FastICA, then categorizes ICs as BOLD or noise using their BOLD and non-BOLD weightings (measured as Kappa and Rho values, respectively). Removing non-BOLD weighted components robustly denoises data for motion, physiology and scanner artifacts, in a simple and physically principled way. Pipeline includes: 1. Preprocess multi-echo datasets and apply multi-echo ICA based on spatial concatenation. 2. Calculation of motion parameters based on images with highest contrast. 3. Application of motion correction and coregistration parameters. 4. EPI preprocessing (temporal alignment, smoothing, etc) in appropriate order. 5. Compute PCA and ICA in conjunction with TE-dependence analysis.",
      "label": "ME-ICA: Multi-Echo Independent Components Analysis",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "me-ica",
      "source": "https://github.com/flywheel-apps/me-ica",
      "url": "https://github.com/ME-ICA/me-ica/blob/master/README.meica",
      "version": "0.2.0"
    },
    {
      "author": "Prantik Kundu",
      "cite": "Kundu, P., Brenowitz, N.D., Voon, V., Worbe, Y., Vertes, P.E., Inati, S.J., Saad, Z.S., Bandettini, P.A. & Bullmore, E.T. Integrated strategy for improving functional connectivity mapping using multiecho fMRI. PNAS (2013). Kundu, P., Inati, S.J., Evans, J.W., Luh, W.M. & Bandettini, P.A. Differentiating BOLD and non-BOLD signals in fMRI time series using multi-echo EPI. NeuroImage (2011). http://dx.doi.org/10.1016/j.neuroimage.2011.12.028",
      "description": "Multi-Echo Independent Components Analysis (ME-ICA) is a method for fMRI analysis and denoising based on the T2* decay of BOLD signals, as measured using multi-echo fMRI. ME-ICA decomposes multi-echo fMRI datasets into independent components (ICs) using FastICA, then categorizes ICs as BOLD or noise using their BOLD and non-BOLD weightings (measured as Kappa and Rho values, respectively). Removing non-BOLD weighted components robustly denoises data for motion, physiology and scanner artifacts, in a simple and physically principled way. Pipeline includes: 1. Preprocess multi-echo datasets and apply multi-echo ICA based on spatial concatenation. 2. Calculation of motion parameters based on images with highest contrast. 3. Application of motion correction and coregistration parameters. 4. EPI preprocessing (temporal alignment, smoothing, etc) in appropriate order. 5. Compute PCA and ICA in conjunction with TE-dependence analysis",
      "label": "ME-ICA: Multi-Echo Independent Components Analysis",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "me-ica",
      "source": "https://github.com/flywheel-apps/me-ica",
      "url": "https://github.com/ME-ICA/me-ica/blob/master/README.meica",
      "version": "0.1.1"
    },
    {
      "author": "Prantik Kundu",
      "cite": "Kundu, P., Brenowitz, N.D., Voon, V., Worbe, Y., Vertes, P.E., Inati, S.J., Saad, Z.S., Bandettini, P.A. & Bullmore, E.T. Integrated strategy for improving functional connectivity mapping using multiecho fMRI. PNAS (2013). Kundu, P., Inati, S.J., Evans, J.W., Luh, W.M. & Bandettini, P.A. Differentiating BOLD and non-BOLD signals in fMRI time series using multi-echo EPI. NeuroImage (2011). http://dx.doi.org/10.1016/j.neuroimage.2011.12.028",
      "description": "Multi-Echo Independent Components Analysis (ME-ICA) is a method for fMRI analysis and denoising based on the T2* decay of BOLD signals, as measured using multi-echo fMRI. ME-ICA decomposes multi-echo fMRI datasets into independent components (ICs) using FastICA, then categorizes ICs as BOLD or noise using their BOLD and non-BOLD weightings (measured as Kappa and Rho values, respectively). Removing non-BOLD weighted components robustly denoises data for motion, physiology and scanner artifacts, in a simple and physically principled way. Pipeline includes: 1. Preprocess multi-echo datasets and apply multi-echo ICA based on spatial concatenation. 2. Calculation of motion parameters based on images with highest contrast. 3. Application of motion correction and coregistration parameters. 4. EPI preprocessing (temporal alignment, smoothing, etc) in appropriate order. 5. Compute PCA and ICA in conjunction with TE-dependence analysis",
      "label": "ME-ICA: Multi-Echo Independent Components Analysis",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "me-ica",
      "source": "https://github.com/ME-ICA/me-ica",
      "url": "https://github.com/ME-ICA/me-ica/blob/master/README.meica",
      "version": "0.1.0"
    }
  ],
  [
    {
      "author": "Amanda Bischoff-Grethe, et al.",
      "cite": "Bischoff-Grethe A., Ozyurt I. B., Busa E., Quinn B. T., Fennema-Notestine C., Clark C. P., et al. (2007). A technique for the deidentification of structural brain MR images. 28 892903. 10.1002/hbm.20312",
      "description": "MBIRN Defacer for structural MRI (mri-deface v1.22). MRI_DEFACE (v1.22) from FreeSurfer is a tool for removing identifiable facial features (eyes, nose, and mouth). This algorithm locates the subject's facial features and removes them without disturbing brain tissue. The algorithm was devised to work on T1-weighted anatomical MR data; it consumes NIfTI, DICOM, or MGH formats and produces a defaced anatomical image in either NIfTI or MGH format. Please cite http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2408762/ if using this tool in your work.",
      "label": "FreeSurfer: MBIRN Defacer for structural MRI (mri-deface v1.22)",
      "license": "GPL-2.0",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "mri-deface",
      "source": "https://github.com/flywheel-apps/mri-deface",
      "url": "https://surfer.nmr.mgh.harvard.edu/fswiki/mri_deface",
      "version": "0.3.0_1.22"
    },
    {
      "author": "Amanda Bischoff-Grethe, et al.",
      "description": "MBIRN Defacer for structural MRI (mri-deface v1.22). MRI_DEFACE (v1.22) from FreeSurfer is a tool for removing identifiable facial features (eyes, nose, and mouth). This algorithm locates the subject's facial features and removes them without disturbing brain tissue. The algorithm was devised to work on T1-weighted anatomical MR data; it consumes NIfTI, DICOM, or MGH formats and produces a defaced anatomical image in either NIfTI or MGH format. Please cite http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2408762/ if using this tool in your work.",
      "label": "FreeSurfer: MBIRN Defacer for structural MRI (mri-deface v1.22)",
      "license": "GPL-2.0",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "mri-deface",
      "source": "https://github.com/flywheel-apps/mri-deface",
      "url": "https://surfer.nmr.mgh.harvard.edu/fswiki/mri_deface",
      "version": "0.2"
    },
    {
      "author": "Amanda Bischoff-Grethe, et al.",
      "description": "This Gear contains an algorithm (mri-deface, from FreeSurfer) for removing identifiable facial features (eyes, nose, and mouth). This algorithm locates the subject's facial features and removes them without disturbing brain tissue. The algorithm was devised to work on T1-weighted structural MRI; it produces a defaced structural image, and an image of the applied mask. Please cite http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2408762/ if using this gear in your work.",
      "label": "FreeSurfer: MBIRN Defacer for structural MRI (mri-deface v1.22)",
      "license": "GPL-2.0",
      "maintainer": "Jennifer Reiter <jenniferreiter@invenshure.com>",
      "name": "mri-deface",
      "source": "https://github.com/flywheel-apps/mri-deface",
      "url": "https://surfer.nmr.mgh.harvard.edu/fswiki/mri_deface",
      "version": "0.1.2"
    },
    {
      "author": "Amanda Bischoff-Grethe, et al.",
      "description": "This Gear contains an algorithm (mri-deface, from FreeSurfer) for removing identifiable facial features (eyes, nose, and mouth). This algorithm locates the subject's facial features and removes them without disturbing brain tissue. The algorithm was devised to work on T1-weighted structural MRI; it produces a defaced structural image, and an image of the applied mask. Please cite http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2408762/ if using this gear in your work.",
      "label": "FreeSurfer: MBIRN Defacer for structural MRI (mri-deface v1.22)",
      "license": "GPL-2.0",
      "maintainer": "Jennifer Reiter <jenniferreiter@invenshure.com>",
      "name": "mri-deface",
      "source": "https://github.com/flywheel-apps/mri-deface",
      "url": "https://surfer.nmr.mgh.harvard.edu/fswiki/mri_deface",
      "version": "0.1.1"
    }
  ],
  [
    {
      "author": "Oscar Esteban, Krzysztof F. Gorgolewski. Poldrack Lab, Psychology, CRN, Stanford University",
      "cite": "Esteban O, Birman D, Schaer M, Koyejo OO, Poldrack RA, Gorgolewski KJ; MRIQC: Advancing the Automatic Prediction of Image Quality in MRI from Unseen Sites; PLOS ONE 12(9):e0184661; doi:10.1371/journal.pone.0184661.",
      "description": "MRIQC (v0.10.1) extracts no-reference IQMs (image quality metrics) from structural (T1w and T2w) and functional MRI (magnetic resonance imaging) data. Note, this gear only supports the generation of individual scan reports; group reports are not generated. Also note, for the auto-detection config option to work for this gear, the follow gears must be run beforehand: (1) dicom-mr-classifier then (2) dcm2niix (version 0.3.1 or higher).",
      "label": "MRIQC: No-reference image quality metrics for quality assessment of MRI ",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "mriqc",
      "source": "https://github.com/flywheel-apps/mriqc",
      "url": "https://github.com/poldracklab/mriqc",
      "version": "0.7.0_0.15.1"
    },
    {
      "author": "Oscar Esteban, Krzysztof F. Gorgolewski. Poldrack Lab, Psychology, CRN, Stanford University",
      "cite": "Esteban O, Birman D, Schaer M, Koyejo OO, Poldrack RA, Gorgolewski KJ; MRIQC: Advancing the Automatic Prediction of Image Quality in MRI from Unseen Sites; PLOS ONE 12(9):e0184661; doi:10.1371/journal.pone.0184661.",
      "description": "MRIQC (v0.10.1) extracts no-reference IQMs (image quality metrics) from structural (T1w and T2w) and functional MRI (magnetic resonance imaging) data. Note, this gear only supports the generation of individual scan reports; group reports are not generated. Also note, for the auto-detection config option to work for this gear, the follow gears must be run beforehand: (1) dicom-mr-classifier then (2) dcm2niix (version 0.3.1 or higher).",
      "label": "MRIQC: No-reference image quality metrics for quality assessment of MRI ",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "mriqc",
      "source": "https://github.com/flywheel-apps/mriqc",
      "url": "https://github.com/poldracklab/mriqc",
      "version": "0.6.4_0.15.1"
    },
    {
      "author": "Oscar Esteban, Krzysztof F. Gorgolewski. Poldrack Lab, Psychology, CRN, Stanford University",
      "cite": "Esteban O, Birman D, Schaer M, Koyejo OO, Poldrack RA, Gorgolewski KJ; MRIQC: Advancing the Automatic Prediction of Image Quality in MRI from Unseen Sites; PLOS ONE 12(9):e0184661; doi:10.1371/journal.pone.0184661.",
      "description": "MRIQC (v0.10.1) extracts no-reference IQMs (image quality metrics) from structural (T1w and T2w) and functional MRI (magnetic resonance imaging) data. Note, this gear only supports the generation of individual scan reports; group reports are not generated. Also note, for the auto-detection config option to work for this gear, the follow gears must be run beforehand: (1) dicom-mr-classifier then (2) dcm2niix (version 0.3.1 or higher).",
      "label": "MRIQC: No-reference image quality metrics for quality assessment of MRI ",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "mriqc",
      "source": "https://github.com/flywheel-apps/mriqc",
      "url": "https://github.com/poldracklab/mriqc",
      "version": "0.6.3_0.11.0"
    },
    {
      "author": "Oscar Esteban, Krzysztof F. Gorgolewski. Poldrack Lab, Psychology, CRN, Stanford University",
      "cite": "Esteban O, Birman D, Schaer M, Koyejo OO, Poldrack RA, Gorgolewski KJ; MRIQC: Advancing the Automatic Prediction of Image Quality in MRI from Unseen Sites; PLOS ONE 12(9):e0184661; doi:10.1371/journal.pone.0184661.",
      "description": "MRIQC (v0.10.1) extracts no-reference IQMs (image quality metrics) from structural (T1w and T2w) and functional MRI (magnetic resonance imaging) data. Note, this gear only supports the generation of individual scan reports; group reports are not generated. Also note, for the auto-detection config option to work for this gear, the follow gears must be run beforehand: (1) dicom-mr-classifier then (2) dcm2niix (version 0.3.1 or higher).",
      "label": "MRIQC: No-reference image quality metrics for quality assessment of MRI ",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "mriqc",
      "source": "https://github.com/flywheel-apps/mriqc",
      "url": "https://github.com/poldracklab/mriqc",
      "version": "0.6.2_0.11.0"
    },
    {
      "author": "Oscar Esteban, Krzysztof F. Gorgolewski. Poldrack Lab, Psychology, CRN, Stanford University",
      "cite": "Esteban O, Birman D, Schaer M, Koyejo OO, Poldrack RA, Gorgolewski KJ; MRIQC: Advancing the Automatic Prediction of Image Quality in MRI from Unseen Sites; PLOS ONE 12(9):e0184661; doi:10.1371/journal.pone.0184661.",
      "description": "MRIQC (v0.10.1) extracts no-reference IQMs (image quality metrics) from structural (T1w and T2w) and functional MRI (magnetic resonance imaging) data. Note, this gear only supports the generation of individual scan reports; group reports are not generated. Also note, for the auto-detection config option to work for this gear, the follow gears must be run beforehand: (1) dicom-mr-classifier then (2) dcm2niix (version 0.3.1 or higher).",
      "label": "MRIQC: No-reference image quality metrics for quality assessment of MRI ",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "mriqc",
      "source": "https://github.com/flywheel-apps/mriqc",
      "url": "https://github.com/poldracklab/mriqc",
      "version": "0.6.1_0.11.0"
    },
    {
      "author": "Oscar Esteban, Krzysztof F. Gorgolewski. Poldrack Lab, Psychology, CRN, Stanford University",
      "cite": "Esteban O, Birman D, Schaer M, Koyejo OO, Poldrack RA, Gorgolewski KJ; MRIQC: Advancing the Automatic Prediction of Image Quality in MRI from Unseen Sites; PLOS ONE 12(9):e0184661; doi:10.1371/journal.pone.0184661.",
      "description": "MRIQC (v0.10.1) extracts no-reference IQMs (image quality metrics) from structural (T1w and T2w) and functional MRI (magnetic resonance imaging) data. Note, this gear only supports the generation of individual scan reports; group reports are not generated. Also note, for the auto-detection config option to work for this gear, the follow gears must be run beforehand: (1) dicom-mr-classifier then (2) dcm2niix (version 0.3.1 or higher).",
      "label": "MRIQC: No-reference image quality metrics for quality assessment of MRI ",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "mriqc",
      "source": "https://github.com/flywheel-apps/mriqc",
      "url": "https://github.com/poldracklab/mriqc",
      "version": "0.6.0"
    },
    {
      "author": "Oscar Esteban, Krzysztof F. Gorgolewski. Poldrack Lab, Psychology, CRN, Stanford University",
      "cite": "Esteban O, Birman D, Schaer M, Koyejo OO, Poldrack RA, Gorgolewski KJ; MRIQC: Advancing the Automatic Prediction of Image Quality in MRI from Unseen Sites; PLOS ONE 12(9):e0184661; doi:10.1371/journal.pone.0184661.",
      "description": "MRIQC (v0.10.1) extracts no-reference IQMs (image quality metrics) from structural (T1w and T2w) and functional MRI (magnetic resonance imaging) data. Note, this gear only supports the generation of individual scan reports; group reports are not generated. Also note, for the auto-detection config option to work for this gear, the follow gears must be run beforehand: (1) dicom-mr-classifier then (2) dcm2niix (version 0.3.1 or higher).",
      "label": "MRIQC: No-reference image quality metrics for quality assessment of MRI (v0.10.1)",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "mriqc",
      "source": "https://github.com/flywheel-apps/mriqc",
      "url": "https://github.com/poldracklab/mriqc",
      "version": "0.5.1"
    },
    {
      "author": "Oscar Esteban, Krzysztof F. Gorgolewski. Poldrack Lab, Psychology, CRN, Stanford University",
      "cite": "Esteban O, Birman D, Schaer M, Koyejo OO, Poldrack RA, Gorgolewski KJ; MRIQC: Advancing the Automatic Prediction of Image Quality in MRI from Unseen Sites; PLOS ONE 12(9):e0184661; doi:10.1371/journal.pone.0184661.",
      "description": "MRIQC (v0.10.1) extracts no-reference IQMs (image quality metrics) from structural (T1w and T2w) and functional MRI (magnetic resonance imaging) data. Note, this gear only supports the generation of individual scan reports; group reports are not generated. Also note, for the auto-detection config option to work for this gear, the follow gears must be run beforehand: (1) dicom-mr-classifier then (2) dcm2niix (version 0.3.1 or higher).",
      "label": "MRIQC: No-reference image quality metrics for quality assessment of MRI (v0.10.1)",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "mriqc",
      "source": "https://github.com/flywheel-apps/mriqc",
      "url": "https://github.com/poldracklab/mriqc",
      "version": "0.5.0"
    },
    {
      "author": "Oscar Esteban, Krzysztof F. Gorgolewski. Poldrack Lab, Psychology, CRN, Stanford University",
      "cite": "Esteban O, Birman D, Schaer M, Koyejo OO, Poldrack RA, Gorgolewski KJ; MRIQC: Advancing the Automatic Prediction of Image Quality in MRI from Unseen Sites; PLOS ONE 12(9):e0184661; doi:10.1371/journal.pone.0184661.",
      "description": "MRIQC (v0.10.1) extracts no-reference IQMs (image quality metrics) from structural (T1w and T2w) and functional MRI (magnetic resonance imaging) data. Note, this gear only supports the generation of individual scan reports; group reports are not generated. Also note, for the auto-detection config option to work for this gear, the follow gears must be run beforehand: (1) dicom-mr-classifier then (2) dcm2niix (version 0.3.1 or higher).",
      "label": "MRIQC: No-reference image quality metrics for quality assessment of MRI (v0.10.1)",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "mriqc",
      "source": "https://github.com/flywheel-apps/mriqc",
      "url": "https://github.com/poldracklab/mriqc",
      "version": "0.4.1"
    },
    {
      "author": "Oscar Esteban, Krzysztof F. Gorgolewski. Poldrack Lab, Psychology, CRN, Stanford University",
      "cite": "Esteban O, Birman D, Schaer M, Koyejo OO, Poldrack RA, Gorgolewski KJ; MRIQC: Advancing the Automatic Prediction of Image Quality in MRI from Unseen Sites; PLOS ONE 12(9):e0184661; doi:10.1371/journal.pone.0184661.",
      "description": "MRIQC (v0.10.1) extracts no-reference IQMs (image quality metrics) from structural (T1w and T2w) and functional MRI (magnetic resonance imaging) data. Note, this gear only supports the generation of individual scan reports; group reports are not generated. Also note, for the auto-detection config option to work for this gear, the follow gears must be run beforehand: (1) dicom-mr-classifier then (2) dcm2niix (version 0.3.1 or higher).",
      "label": "MRIQC: No-reference image quality metrics for quality assessment of MRI (v0.10.1)",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "mriqc",
      "source": "https://github.com/flywheel-apps/mriqc",
      "url": "https://github.com/poldracklab/mriqc",
      "version": "0.4.0"
    },
    {
      "author": "Oscar Esteban, Krzysztof F. Gorgolewski. Poldrack Lab, Psychology, CRN, Stanford University",
      "cite": "Esteban O, Birman D, Schaer M, Koyejo OO, Poldrack RA, Gorgolewski KJ; MRIQC: Advancing the Automatic Prediction of Image Quality in MRI from Unseen Sites; PLOS ONE 12(9):e0184661; doi:10.1371/journal.pone.0184661.",
      "description": "MRIQC extracts no-reference IQMs (image quality metrics) from structural (T1w and T2w) and functional MRI (magnetic resonance imaging) data. Note, this gear only supports the generation of individual scan reports; group reports are not generated. Also note, for the auto-detection config option to work for this gear, the follow gears must be run beforehand: (1) dicom-mr-classifier then (2) dcm2niix (version 0.3.1 or higher).",
      "label": "MRIQC: No-reference image quality metrics for quality assessment of MRI (v0.9.4)",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "mriqc",
      "source": "https://github.com/flywheel-apps/mriqc",
      "url": "https://github.com/poldracklab/mriqc",
      "version": "0.3.3"
    },
    {
      "author": "Oscar Esteban, Krzysztof F. Gorgolewski. Poldrack Lab, Psychology, CRN, Stanford University",
      "cite": "Esteban O, Birman D, Schaer M, Koyejo OO, Poldrack RA, Gorgolewski KJ; MRIQC: Advancing the Automatic Prediction of Image Quality in MRI from Unseen Sites; PLOS ONE 12(9):e0184661; doi:10.1371/journal.pone.0184661.",
      "description": "MRIQC extracts no-reference IQMs (image quality metrics) from structural (T1w and T2w) and functional MRI (magnetic resonance imaging) data. Note, this gear only supports the generation of individual scan reports; group reports are not generated.",
      "label": "MRIQC: No-reference image quality metrics for quality assessment of MRI (v0.9.4)",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "mriqc",
      "source": "https://github.com/flywheel-apps/mriqc",
      "url": "https://github.com/poldracklab/mriqc",
      "version": "0.3.2"
    },
    {
      "author": "Oscar Esteban and Krzysztof F. Gorgolewski. Stanford University",
      "description": "The MRIQC package provides a series of image processing workflows to extract and compute a series of NR (no-reference), IQMs (image quality metrics) to be used in QAPs (quality assessment protocols) for MRI (magnetic resonance imaging). This tool extracts a series of IQMs from structural or functional MRI data. Note, this gear only supports the generation of individual scan reports; group reports are not generated.",
      "label": "MRIQC: No-reference image quality metrics for quality assessment of MRI (v0.9.4)",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "mriqc",
      "source": "https://github.com/flywheel-apps/mriqc",
      "url": "https://github.com/poldracklab/mriqc",
      "version": "0.3.1"
    },
    {
      "author": "Oscar Esteban and Krzysztof F. Gorgolewski. Stanford University",
      "description": "The MRIQC package provides a series of image processing workflows to extract and compute a series of NR (no-reference), IQMs (image quality metrics) to be used in QAPs (quality assessment protocols) for MRI (magnetic resonance imaging). This tool extracts a series of IQMs from structural or functional MRI data. Note, this gear only supports the generation of individual scan reports; group reports are not generated.",
      "label": "MRIQC: No-reference image quality metrics for quality assessment of MRI (v0.9.4)",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "mriqc",
      "source": "https://github.com/flywheel-apps/mriqc",
      "url": "https://github.com/poldracklab/mriqc",
      "version": "0.3"
    },
    {
      "author": "Oscar Esteban and Krzysztof F. Gorgolewski. Stanford University",
      "description": "The MRIQC package provides a series of image processing workflows to extract and compute a series of NR (no-reference), IQMs (image quality metrics) to be used in QAPs (quality assessment protocols) for MRI (magnetic resonance imaging). This tool extracts a series of IQMs from structural or functional MRI data. Note, this gear only supports the generation of individual scan reports; group reports are not generated.",
      "label": "MRIQC: No-reference image quality metrics for quality assessment of MRI (v0.9.4)",
      "license": "BSD-3-Clause",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "mriqc",
      "source": "https://github.com/flywheel-apps/mriqc",
      "url": "https://github.com/poldracklab/mriqc",
      "version": "0.2"
    },
    {
      "author": "Poldrack Lab at Stanford University",
      "description": "The package provides a series of image processing workflows to extract and compute a series of NR (no-reference), IQMs (image quality metrics) to be used in QAPs (quality assessment protocols) for MRI (magnetic resonance imaging). This tool extracts a series of IQMs from structural or functional MRI data. Note, this gear only supports the generation of individual scan reports; group reports are not generated.",
      "label": "MRIQC: NR-IQMs for Functional MRI (mriqc v0.9.0-0)",
      "license": "BSD-3-Clause",
      "maintainer": "Jennifer Reiter <jenniferreiter@invenshure.com>",
      "name": "mriqc",
      "source": "https://github.com/flywheel-apps/mriqc",
      "url": "https://github.com/poldracklab/mriqc",
      "version": "0.1"
    }
  ],
  [
    {
      "author": "MRtrix, FSL, and Brain-Life teams.",
      "cite": "Gear adapted from https://github.com/brain-life/app-mrtrix3-preproc. Ref: https://mrtrix.readthedocs.io/en/latest/reference/scripts/dwipreproc.html#references",
      "description": "mrtrix3preproc runs the MRtrix3 preprocessing pipeline. It uses FSL's topup when the optional inverse phase encoded data are provided, otherwise the pipeline uses FSL's eddy tool. The pipeline can also perform de-noising, reslicing, and alignment to an anatomical image. Required inputs are diffusion NIfTI, BVEC, BVAL, and Anatomical (ACPC aligned) NIfTI.",
      "label": "MRtrix3: Preprocessing Pipeline",
      "license": "Other",
      "maintainer": "Garikoitz Lerma-Usabiaga <glerma@stanford.edu>",
      "name": "mrtrix3preproc",
      "source": "https://github.com/scitran-apps/mrtrix3preproc",
      "url": "https://mrtrix.readthedocs.io/en/latest/reference/scripts/dwipreproc.html#dwipreproc",
      "version": "1.0.2"
    },
    {
      "author": "MRtrix, FSL, and Brain-Life teams.",
      "cite": "Gear adapted from https://github.com/brain-life/app-mrtrix3-preproc. Ref: https://mrtrix.readthedocs.io/en/latest/reference/scripts/dwipreproc.html#references",
      "description": "mrtrix3preproc runs the MRtrix3 preprocessing pipeline. It uses FSL's topup when the optional inverse phase encoded data are provided, otherwise the pipeline uses FSL's eddy tool. The pipeline can also perform de-noising, reslicing, and alignment to an anatomical image. Required inputs are diffusion NIfTI, BVEC, BVAL, and Anatomical (ACPC aligned) NIfTI.",
      "label": "MRtrix3: Preprocessing Pipeline",
      "license": "Other",
      "maintainer": "Garikoitz Lerma-Usabiaga <glerma@stanford.edu>",
      "name": "mrtrix3preproc",
      "source": "https://github.com/scitran-apps/mrtrix3preproc",
      "url": "https://mrtrix.readthedocs.io/en/latest/reference/scripts/dwipreproc.html#dwipreproc",
      "version": "1.0.0"
    }
  ],
  [
    {
      "author": "Gregory Kiar, Eric W. Bridgeford, Joshua T. Vogelstein, et al.",
      "command": "/flywheel/v0/run.py",
      "description": "NeuroData's MR Graphs package, ndmg (pronounced \"nutmeg\"), is a turn-key pipeline which uses structural and diffusion MRI data to estimate multi-resolution connectomes reliably and scalably.",
      "environment": {
        "AFNI_URL": "https://files.osf.io/v1/resources/fvuh8/providers/osfstorage/5a0dd9a7b83f69027512a12b",
        "CRAN_URL": "https://cran.rstudio.com/",
        "FSLBROWSER": "/etc/alternatives/x-www-browser",
        "FSLDIR": "/usr/share/fsl/5.0",
        "FSLLOCKDIR": "",
        "FSLMACHINELIST": "",
        "FSLMULTIFILEQUIT": "TRUE",
        "FSLOUTPUTTYPE": "NIFTI_GZ",
        "FSLREMOTECALL": "",
        "FSLTCLSH": "/usr/bin/tclsh",
        "FSLWISH": "/usr/bin/wish",
        "HOME": "/root",
        "KMP_DUPLICATE_LIB_OK": "True",
        "LD_LIBRARY_PATH": "/usr/lib/fsl/5.0",
        "LESSCLOSE": "/usr/bin/lesspipe %s %s",
        "LESSOPEN": "| /usr/bin/lesspipe %s",
        "MPLCONFIGDIR": "/tmp/",
        "NDEB_URL": "http://neuro.debian.net/lists/xenial.us-ca.full",
        "NDMG_ATLASES": "https://github.com/neurodata/neuroparc.git",
        "NDMG_URL": "https://github.com/neurodata/ndmg.git",
        "PATH": "/usr/lib/fsl/5.0:/opt/afni:/usr/share/fsl/5.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
        "POSSUMDIR": "/usr/share/fsl/5.0",
        "PYTHONWARNINGS": "ignore",
        "SHLVL": "1",
        "TERM": "xterm",
        "_": "/usr/local/bin/ipython"
      },
      "label": "NDMG (NeuroData's MR Graphs Package)",
      "license": "Apache-2.0",
      "maintainer": "Derek Pisner <dpisner@utexas.edu>",
      "name": "ndmg",
      "source": "https://github.com/flywheel-apps/ndmg",
      "url": "https://github.com/neurodata/ndmg",
      "version": "0.1.0_staging"
    }
  ],
  [
    {
      "author": "Yaroslav O. Halchenko",
      "description": "A finite mixture modeling (FMM) segmentation approach with possibilities for",
      "label": "Atropos",
      "license": "BSD-3-Clause",
      "maintainer": "Yaroslav O. Halchenko <debian@onerussian.com>",
      "name": "nipype-interfaces-ants-segmentation-atropos",
      "source": "https://github.com/yarikoptic/gearificator",
      "url": "http://nipype.readthedocs.io/en/1.0.3/interfaces/generated/interfaces.ants/registration.html",
      "version": "0.1.dev.nipype.1.0.3.3"
    },
    {
      "author": "Yaroslav O. Halchenko",
      "description": "A finite mixture modeling (FMM) segmentation approach with possibilities for",
      "label": "Atropos",
      "license": "BSD-3-Clause",
      "maintainer": "Yaroslav O. Halchenko <debian@onerussian.com>",
      "name": "nipype-interfaces-ants-segmentation-atropos",
      "source": "https://github.com/yarikoptic/gearificator",
      "url": "http://nipype.readthedocs.io/en/1.0.3/interfaces/generated/interfaces.ants/registration.html",
      "version": "0.0.2.nipype.1.0.3.1"
    }
  ],
  [
    {
      "author": "Yaroslav O. Halchenko",
      "description": "",
      "label": "BrainExtraction",
      "license": "BSD-3-Clause",
      "maintainer": "Yaroslav O. Halchenko <debian@onerussian.com>",
      "name": "nipype-interfaces-ants-segmentation-brainextraction",
      "source": "https://github.com/yarikoptic/gearificator",
      "url": "http://nipype.readthedocs.io/en/1.0.3/interfaces/generated/interfaces.ants/registration.html",
      "version": "0.1.dev.nipype.1.0.3.3"
    },
    {
      "author": "Yaroslav O. Halchenko",
      "description": "",
      "label": "BrainExtraction",
      "license": "BSD-3-Clause",
      "maintainer": "Yaroslav O. Halchenko <debian@onerussian.com>",
      "name": "nipype-interfaces-ants-segmentation-brainextraction",
      "source": "https://github.com/yarikoptic/gearificator",
      "url": "http://nipype.readthedocs.io/en/1.0.3/interfaces/generated/interfaces.ants/registration.html",
      "version": "0.1.dev.nipype.1.0.3.2"
    }
  ],
  [
    {
      "author": "Yaroslav O. Halchenko",
      "description": "",
      "label": "CorticalThickness",
      "license": "BSD-3-Clause",
      "maintainer": "Yaroslav O. Halchenko <debian@onerussian.com>",
      "name": "nipype-interfaces-ants-segmentation-corticalthickness",
      "source": "https://github.com/yarikoptic/gearificator",
      "url": "http://nipype.readthedocs.io/en/1.0.3/interfaces/generated/interfaces.ants/registration.html",
      "version": "0.1.dev.nipype.1.0.3.2"
    }
  ],
  [
    {
      "author": "Yaroslav O. Halchenko",
      "description": "",
      "label": "DenoiseImage",
      "license": "BSD-3-Clause",
      "maintainer": "Yaroslav O. Halchenko <debian@onerussian.com>",
      "name": "nipype-interfaces-ants-segmentation-denoiseimage",
      "source": "https://github.com/yarikoptic/gearificator",
      "url": "http://nipype.readthedocs.io/en/1.0.3/interfaces/generated/interfaces.ants/registration.html",
      "version": "0.1.dev.nipype.1.0.3.2"
    }
  ],
  [
    {
      "author": "Yaroslav O. Halchenko",
      "description": " Nipype Interface to ANTs' KellyKapowski, also known as DiReCT.",
      "label": "KellyKapowski",
      "license": "BSD-3-Clause",
      "maintainer": "Yaroslav O. Halchenko <debian@onerussian.com>",
      "name": "nipype-interfaces-ants-segmentation-kellykapowski",
      "source": "https://github.com/yarikoptic/gearificator",
      "url": "http://nipype.readthedocs.io/en/1.0.3/interfaces/generated/interfaces.ants/registration.html",
      "version": "0.1.dev.nipype.1.0.3.3"
    },
    {
      "author": "Yaroslav O. Halchenko",
      "description": " Nipype Interface to ANTs' KellyKapowski, also known as DiReCT.",
      "label": "KellyKapowski",
      "license": "BSD-3-Clause",
      "maintainer": "Yaroslav O. Halchenko <debian@onerussian.com>",
      "name": "nipype-interfaces-ants-segmentation-kellykapowski",
      "source": "https://github.com/yarikoptic/gearificator",
      "url": "http://nipype.readthedocs.io/en/1.0.3/interfaces/generated/interfaces.ants/registration.html",
      "version": "0.1.dev.nipype.1.0.3.2"
    }
  ],
  [
    {
      "author": "Yaroslav O. Halchenko",
      "description": "Calculates the cortical thickness from an anatomical image",
      "label": "LaplacianThickness",
      "license": "BSD-3-Clause",
      "maintainer": "Yaroslav O. Halchenko <debian@onerussian.com>",
      "name": "nipype-interfaces-ants-segmentation-laplacianthickness",
      "source": "https://github.com/yarikoptic/gearificator",
      "url": "http://nipype.readthedocs.io/en/1.1.7/interfaces/generated/interfaces.ants/registration.html",
      "version": "0.2.dev1.nipype.1.1.7"
    },
    {
      "author": "Yaroslav O. Halchenko",
      "description": "Calculates the cortical thickness from an anatomical image",
      "label": "LaplacianThickness",
      "license": "BSD-3-Clause",
      "maintainer": "Yaroslav O. Halchenko <debian@onerussian.com>",
      "name": "nipype-interfaces-ants-segmentation-laplacianthickness",
      "source": "https://github.com/yarikoptic/gearificator",
      "url": "http://nipype.readthedocs.io/en/1.0.3/interfaces/generated/interfaces.ants/registration.html",
      "version": "0.1.dev.nipype.1.0.3.2"
    }
  ],
  [
    {
      "author": "Yaroslav O. Halchenko",
      "description": "N4 is a variant of the popular N3 (nonparameteric nonuniform normalization)",
      "label": "N4BiasFieldCorrection",
      "license": "BSD-3-Clause",
      "maintainer": "Yaroslav O. Halchenko <debian@onerussian.com>",
      "name": "nipype-interfaces-ants-segmentation-n4biasfieldcorrection",
      "source": "https://github.com/yarikoptic/gearificator",
      "url": "http://nipype.readthedocs.io/en/1.0.3/interfaces/generated/interfaces.ants/registration.html",
      "version": "0.0.2.nipype.1.0.3.1"
    }
  ],
  [
    {
      "author": "Yaroslav O. Halchenko",
      "description": "",
      "label": "PrepareFieldmap",
      "license": "Other",
      "maintainer": "Yaroslav O. Halchenko <debian@onerussian.com>",
      "name": "nipype-interfaces-fsl-epi-preparefieldmap",
      "source": "https://github.com/yarikoptic/gearificator",
      "url": "http://nipype.readthedocs.io/en/1.0.3/interfaces/generated/interfaces.ants/registration.html",
      "version": "0.1.dev.nipype.1.0.3.3"
    }
  ],
  [
    {
      "author": "Yaroslav O. Halchenko",
      "description": "FSL BET command for skull stripping",
      "label": "FSL BET (Brain Extraction Tool)",
      "license": "Other",
      "maintainer": "Yaroslav O. Halchenko <debian@onerussian.com>",
      "name": "nipype-interfaces-fsl-preprocess-bet",
      "source": "https://github.com/yarikoptic/gearificator",
      "url": "http://nipype.readthedocs.io/en/1.0.3/interfaces/generated/interfaces.ants/registration.html",
      "version": "0.0.2.nipype.1.0.3.1"
    }
  ],
  [
    {
      "author": "Yaroslav O. Halchenko",
      "description": "FSL FAST command for segmentation and bias correction",
      "label": "FAST",
      "license": "Other",
      "maintainer": "Yaroslav O. Halchenko <debian@onerussian.com>",
      "name": "nipype-interfaces-fsl-preprocess-fast",
      "source": "https://github.com/yarikoptic/gearificator",
      "url": "http://nipype.readthedocs.io/en/1.0.3/interfaces/generated/interfaces.ants/registration.html",
      "version": "0.1.dev.nipype.1.0.3.2"
    },
    {
      "author": "Yaroslav O. Halchenko",
      "description": "FSL FAST command for segmentation and bias correction",
      "label": "FAST",
      "license": "Other",
      "maintainer": "Yaroslav O. Halchenko <debian@onerussian.com>",
      "name": "nipype-interfaces-fsl-preprocess-fast",
      "source": "https://github.com/yarikoptic/gearificator",
      "url": "http://nipype.readthedocs.io/en/1.0.3/interfaces/generated/interfaces.ants/registration.html",
      "version": "0.0.2.nipype.1.0.3.1"
    }
  ],
  [
    {
      "author": "Flywheel",
      "cite": "",
      "command": "/flywheel/v0/run.py",
      "description": "A framework for developing neural network models for 3D image processing.",
      "label": "Nobrainer",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "nobrainer",
      "source": "https://github.com/neuronets/nobrainer",
      "url": "https://github.com/flywheel-apps/nobrainer-gear",
      "version": "0.1.0"
    }
  ],
  [
    {
      "author": "Adam Goode, M. Satyanarayanan, Carnegie Mellon University <https://openslide.org/>",
      "command": "python run.py",
      "description": "OpenSlide: Uses the OpenSlide library to convert whole-slide image files to .png for viewing in Flywheel. Supported file types include Aperio (.svs, .tif), Hamamatsu (.ndpi, .vms, .vmu), Leica (.scn), MIRAX (.mrxs), Philips (.tiff), Sakura (.svslide), Trestle (.tif), Ventana (.bif, .tif), Generic tiled TIFF (.tif)",
      "label": "OpenSlide to PNG file converter",
      "license": "MIT",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "openslide-to-png",
      "source": "https://github.com/flywheel-apps/openslide-to-png",
      "url": "https://github.com/openslide/openslide-python",
      "version": "0.0.1_1.1.1"
    }
  ],
  [
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata from PAR/REC MR data generated by Philips MR scanners.",
      "label": "SciTran PAR/REC MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "parrec-mr-classifier",
      "source": "https://github.com/scitran-apps/parrec-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "2.0.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata from PAR/REC MR data generated by Philips MR scanners.",
      "label": "SciTran PAR/REC MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "parrec-mr-classifier",
      "source": "https://github.com/scitran-apps/parrec-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "1.1.1"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata from PAR/REC MR data generated by Philips MR scanners.",
      "label": "SciTran PAR/REC MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "parrec-mr-classifier",
      "source": "https://github.com/scitran-apps/parrec-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "1.1.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata from PAR/REC MR data generated by Philips MR scanners.",
      "label": "SciTran PAR/REC MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "parrec-mr-classifier",
      "source": "https://github.com/scitran-apps/parrec-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "1.0.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata from PAR/REC MR data generated by Philips MR scanners.",
      "label": "SciTran PAR/REC MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "parrec-mr-classifier",
      "source": "https://github.com/scitran-apps/parrec-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.0.5"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "description": "Extract metadata from PAR/REC MR data Philips",
      "label": "SciTran PAR/REC MR Classifier",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "parrec-mr-classifier",
      "source": "https://github.com/scitran-apps/parrec-mr-classifier",
      "url": "https://scitran.github.io",
      "version": "0.0.3"
    }
  ],
  [
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "cite": "pfile-tools: GE P-File Utilities (https://github.com/njvack/pfile-tools)",
      "description": "Extracts GE P-File header and generates JSON metadata (.metadata.json) which is saved in Flywheel on the P-File's info object. This gear also attempts to determine the P-File's classification (measurement, intent, etc.) using information about the sequence, as well as heuristics based upon the series description.",
      "label": "GE P-File Metadata Import and Classification",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "pfile-mr-classifier",
      "source": "https://github.com/cni/pfile-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "2.4.0_23ec2b6"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "cite": "pfile-tools: GE P-File Utilities (https://github.com/njvack/pfile-tools)",
      "description": "Extracts GE P-File header and generates JSON metadata (.metadata.json) which is saved in Flywheel on the P-File's info object. This gear also attempts to determine the P-File's classification (measurement, intent, etc.).",
      "label": "Metadata Import and Classification for GE P-Files",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "pfile-mr-classifier",
      "source": "https://github.com/cni/pfile-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "2.3.2"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "cite": "pfile-tools: GE P-File Utilities (https://github.com/njvack/pfile-tools)",
      "description": "Extracts GE P-File header and generates JSON metadata (.metadata.json) which is saved in Flywheel on the P-File's info object. This gear also attempts to determine the P-File's classification (measurement, intent, etc.).",
      "label": "CNI: GE P-File Metadata Import and Classification",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "pfile-mr-classifier",
      "source": "https://github.com/cni/pfile-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "2.3.1"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "cite": "pfile-tools: GE P-File Utilities (https://github.com/njvack/pfile-tools)",
      "description": "Extracts GE P-File header and generates JSON metadata (.metadata.json) which is saved in Flywheel on the P-File's info object. This gear also attempts to determine the P-File's classification (measurement, intent, etc.).",
      "label": "CNI: GE P-File Metadata Import and Classification",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "pfile-mr-classifier",
      "source": "https://github.com/cni/pfile-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "2.3.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "cite": "pfile-tools: GE P-File Utilities (https://github.com/njvack/pfile-tools)",
      "description": "Extracts GE P-File header and generates JSON metadata (.metadata.json) which is saved in Flywheel on the P-File's info object. This gear also attempts to determine the P-File's classification (measurement, intent, etc.).",
      "label": "CNI: GE P-File Classifier",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "pfile-mr-classifier",
      "source": "https://github.com/cni/pfile-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "2.2.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "cite": "pfile-tools: GE P-File Utilities (https://github.com/njvack/pfile-tools)",
      "description": "Extracts GE P-File header and generates JSON metadata (.metadata.json) which is saved in Flywheel on the P-File's info object. This gear also attempts to determine the P-File's classification (measurement, intent, etc.).",
      "label": "CNI: GE P-File Classifier",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "pfile-mr-classifier",
      "source": "https://github.com/cni/pfile-mr-classifier/releases/tag/2.1.0",
      "url": "https://cni.stanford.edu",
      "version": "2.1.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "cite": "pfile-tools: GE P-File Utilities (https://github.com/njvack/pfile-tools)",
      "description": "Extracts GE P-File header and generates JSON metadata (.metadata.json) which is saved in Flywheel on the P-File's info object. This gear also attempts to determine the P-File's classification (measurement, intent, etc.).",
      "label": "CNI: GE P-File Classifier",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "pfile-mr-classifier",
      "source": "https://github.com/cni/pfile-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "2.0.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "cite": "pfile-tools: GE P-File Utilities (https://github.com/njvack/pfile-tools)",
      "description": "Extracts GE P-File header and generates JSON metadata (.metadata.json) which is saved in Flywheel on the P-File's info object. This gear also attempts to determine the P-File's classification (measurement, intent, etc.).",
      "label": "CNI: GE P-File Classifier",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "pfile-mr-classifier",
      "source": "https://github.com/cni/pfile-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "1.8.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "cite": "pfile-tools: GE P-File Utilities (https://github.com/njvack/pfile-tools)",
      "description": "Extracts GE P-File header and generates JSON metadata (.metadata.json) which is saved in Flywheel on the P-File's info object. This gear also attempts to determine the P-File's classification (measurement, intent, etc.).",
      "label": "CNI: GE P-File Classifier",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "pfile-mr-classifier",
      "source": "https://github.com/cni/pfile-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "1.7.1"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "cite": "pfile-tools: GE P-File Utilities (https://github.com/njvack/pfile-tools)",
      "description": "Extracts GE P-File header and generates JSON metadata (.metadata.json) which is saved in Flywheel on the P-File's info object. This gear also attempts to determine the P-File's classification (measurement, intent, etc.).",
      "label": "CNI: GE P-File Classifier",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "pfile-mr-classifier",
      "source": "https://github.com/cni/pfile-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "1.7.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "cite": "pfile-tools: GE P-File Utilities (https://github.com/njvack/pfile-tools)",
      "description": "Extracts GE P-File header and generates JSON metadata (.metadata.json) which is saved in Flywheel on the P-File's info object. This gear also attempts to determine the P-File's classification (measurement, intent, etc.).",
      "label": "CNI: GE P-File Classifier",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "pfile-mr-classifier",
      "source": "https://github.com/cni/pfile-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "1.6.1"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "cite": "pfile-tools: GE P-File Utilities (https://github.com/njvack/pfile-tools)",
      "description": "Extracts GE P-File header and generates JSON metadata (.metadata.json) which is saved in Flywheel on the P-File's info object. This gear also attempts to determine the P-File's classification (measurement, intent, etc.).",
      "label": "CNI: GE P-File Classifier",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "pfile-mr-classifier",
      "source": "https://github.com/cni/pfile-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "1.6.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "cite": "pfile-tools: GE P-File Utilities (https://github.com/njvack/pfile-tools)",
      "description": "Extracts GE P-File header and generates JSON metadata (.metadata.json) which is saved in Flywheel on the P-File's info object. This gear also attempts to determine the P-File's classification (measurement, intent, etc.).",
      "label": "CNI: GE P-File Classifier",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "pfile-mr-classifier",
      "source": "https://github.com/cni/pfile-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "1.5.2"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "cite": "pfile-tools: GE P-File Utilities (https://github.com/njvack/pfile-tools)",
      "description": "Extracts GE P-File header and generates JSON metadata (.metadata.json) which is saved in Flywheel on the P-File's info object. This gear also attempts to determine the P-File's classification (measurement, intent, etc.).",
      "label": "CNI: GE P-File Classifier",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "pfile-mr-classifier",
      "source": "https://github.com/cni/pfile-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "1.5.1"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "cite": "pfile-tools: GE P-File Utilities (https://github.com/njvack/pfile-tools)",
      "description": "Extracts GE P-File header and generates JSON metadata (.metadata.json) which is saved in Flywheel on the P-File's info object. This gear also attempts to determine the P-File's classification (measurement, intent, etc.).",
      "label": "CNI: GE P-File Classifier",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "pfile-mr-classifier",
      "source": "https://github.com/cni/pfile-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "1.5.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "cite": "pfile-tools: GE P-File Utilities (https://github.com/njvack/pfile-tools)",
      "description": "Extracts GE P-File header and generates JSON metadata (.metadata.json) which is saved in Flywheel on the P-File's info object. This gear also attempts to determine the P-File's classification (measurement, intent, etc.).",
      "label": "CNI: GE P-File Classifier",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "pfile-mr-classifier",
      "source": "https://github.com/cni/pfile-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "1.4.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "cite": "pfile-tools: GE P-File Utilities (https://github.com/njvack/pfile-tools)",
      "description": "Extracts GE P-File header and generates JSON metadata (.metadata.json) which is saved in Flywheel on the P-File's info object. This gear also attempts to determine the P-File's classification (measurement, intent, etc.).",
      "label": "CNI: GE P-File Classifier",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "pfile-mr-classifier",
      "source": "https://github.com/cni/pfile-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "1.3.2"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "cite": "pfile-tools: GE P-File Utilities (https://github.com/njvack/pfile-tools)",
      "description": "Extracts GE P-File header and generates JSON metadata (.metadata.json) which is saved in Flywheel on the P-File's info object. This gear also attempts to determine the P-File's classification (measurement, intent, etc.).",
      "label": "CNI: GE P-File Classifier",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "pfile-mr-classifier",
      "source": "https://github.com/cni/pfile-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "1.3.1"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "cite": "pfile-tools: GE P-File Utilities (https://github.com/njvack/pfile-tools)",
      "description": "Extracts GE P-File header and generates JSON metadata (.metadata.json) which is saved in Flywheel on the P-File's info object. This gear also attempts to determine the P-File's classification (measurement, intent, etc.).",
      "label": "CNI: GE P-File Classifier",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "pfile-mr-classifier",
      "source": "https://github.com/cni/pfile-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "1.3.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "cite": "pfile-tools: GE P-File Utilities (https://github.com/njvack/pfile-tools)",
      "description": "Extracts GE P-File header and generates JSON metadata (.metadata.json) which is saved in Flywheel on the P-File's info object. This gear also attempts to determine the P-File's classification (measurement, intent, etc.).",
      "label": "CNI: GE P-File Classifier",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "pfile-mr-classifier",
      "source": "https://github.com/cni/pfile-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "1.2.1"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "cite": "pfile-tools: GE P-File Utilities (https://github.com/njvack/pfile-tools)",
      "description": "Extracts GE P-File header and generates JSON metadata (.metadata.json) which is saved in Flywheel on the P-File's info object. This gear also attempts to determine the P-File's classification (measurement, intent, etc.).",
      "label": "CNI: GE P-File Classifier",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "pfile-mr-classifier",
      "source": "https://github.com/cni/pfile-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "1.2.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "cite": "pfile-tools: GE P-File Utilities (https://github.com/njvack/pfile-tools)",
      "description": "Extracts GE P-File header and generates JSON metadata (.metadata.json) which is saved in Flywheel on the P-File's info object. This gear also attempts to determine the P-File's classification (measurement, intent, etc.).",
      "label": "CNI: GE P-File Classifier",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "pfile-mr-classifier",
      "source": "https://github.com/cni/pfile-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "1.1.1"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "cite": "pfile-tools: GE P-File Utilities (https://github.com/njvack/pfile-tools)",
      "description": "Extracts GE P-File header and generates JSON metadata (.metadata.json) which is saved in Flywheel on the P-File's info object. This gear also attempts to determine the P-File's classification (measurement, intent, etc.).",
      "label": "CNI: GE P-File Classifier",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "pfile-mr-classifier",
      "source": "https://github.com/cni/pfile-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "1.1.0"
    },
    {
      "author": "Michael Perry <lmperry@stanford.edu>",
      "cite": "pfile-tools: GE P-File Utilities (https://github.com/njvack/pfile-tools)",
      "description": "Extracts GE P-File headers and generates JSON metadata (.metadata.json) which is saved in Flywheel on the P-File's info object. This gear also attempts to determine the P-Files classification.",
      "label": "CNI: GE P-File Classifier",
      "license": "BSD-2-Clause",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "pfile-mr-classifier",
      "source": "https://github.com/cni/pfile-mr-classifier",
      "url": "https://cni.stanford.edu",
      "version": "1.0.0"
    }
  ],
  [
    {
      "author": "Souheil Inati, Michael Hansen, et al.",
      "description": "The Philips to ISMRM-RD Convertor (philips_to_ismrmrd v0.1.0, ismrmrd v1.3.2) is used to convert data from Philips Raw file (.raw) to ISMRM-RD raw data format (.h5).",
      "label": "Philips to ISMRM-RD Converter (philips_to_ismrmrd v0.1.0, ismrmrd v1.3.2)",
      "license": "Other",
      "maintainer": "Jennifer Reiter <jenniferreiter@invenshure.com>",
      "name": "philips-to-ismrmrd",
      "source": "https://github.com/flywheel-apps/philips_to_ismrmrd",
      "url": "https://github.com/ismrmrd/philips_to_ismrmrd",
      "version": "0.1"
    }
  ],
  [
    {
      "author": "poldracklab",
      "cite": "https://github.com/poldracklab/pydeface",
      "command": "/flywheel/v0/run.py",
      "description": "A gear to remove facial structure from MRI images.",
      "environment": {
        "CONDA_DEFAULT_ENV": "neuro",
        "CONDA_DIR": "/opt/conda",
        "CONDA_EXE": "/opt/conda/bin/conda",
        "CONDA_PREFIX": "/opt/conda/envs/neuro",
        "CONDA_PROMPT_MODIFIER": "(neuro) ",
        "CONDA_PYTHON_EXE": "/opt/conda/bin/python",
        "CONDA_SHLVL": "1",
        "FLYWHEEL": "/flywheel/v0",
        "FSLDIR": "/opt/fsl",
        "FSLGECUDAQ": "cuda.q",
        "FSLLOCKDIR": "",
        "FSLMACHINELIST": "",
        "FSLMULTIFILEQUIT": "TRUE",
        "FSLOUTPUTTYPE": "NIFTI_GZ",
        "FSLREMOTECALL": "",
        "FSLTCLSH": "/opt/fsl/bin/fsltclsh",
        "FSLWISH": "/opt/fsl/bin/fslwish",
        "HOME": "/root",
        "HOSTNAME": "d8012530f084",
        "LANG": "en_US.UTF-8",
        "LC_ALL": "C.UTF-8",
        "ND_ENTRYPOINT": "/neurodocker/startup.sh",
        "PATH": "/opt/conda/envs/neuro/bin:/opt/conda/condabin:/opt/conda/bin:/opt/fsl/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
        "PWD": "/flywheel/v0",
        "SHLVL": "1",
        "TERM": "xterm",
        "_": "/opt/conda/envs/neuro/bin/python",
        "_CE_CONDA": "",
        "_CE_M": ""
      },
      "label": "Pydeface Gear",
      "license": "MIT",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "pydeface-gear",
      "source": "https://github.com/poldracklab/pydeface",
      "url": "https://github.com/flywheel-apps/pydeface-gear",
      "version": "1.0.0"
    }
  ],
  [
    {
      "author": "DTIPrep (Francois Budin <fbudin@unc.edu>)",
      "description": "DTIPrep performs a Study-specific Protocol based automatic pipeline for DWI/DTI quality control and preparation. This is both a GUI and command line tool. The configurable pipeline includes image/diffusion information check, padding/Cropping of data, slice-wise, interlace-wise and gradient-wise intensity and motion check, head motion and Eddy current artifact correction, and DTI computing. Version 1.2.4",
      "label": "DTIPREP: DWI Quality Assurance Report",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "qa-dtiprep",
      "source": "https://github.com/scitran-apps/qa-dtiprep",
      "url": "https://www.nitrc.org/projects/dtiprep",
      "version": "0.0.2"
    }
  ],
  [
    {
      "author": "Robert F. Dougherty",
      "description": "Run QA metrics (displacement, signal spikes) to create a quality assurance report (png) for an fMRI NIfTI using modified CNI/NIMS code from @rfdougherty.",
      "label": "Quality Assurance Report (fMRI)",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "qa-report-fmri",
      "source": "https://github.com/scitran-apps/qa-report-fmri",
      "url": "https://github.com/cni/nims/blob/master/nimsproc/qa_report.py",
      "version": "0.1.7"
    }
  ],
  [
    {
      "author": "Flywheel",
      "cite": "Roy, A.G., Conjeti, S., Navab, N. and Wachinger, C., 2018. QuickNAT: Segmenting\nMRI Neuroanatomy in 20 seconds. arXiv:1801.04161",
      "command": "/flywheel/v0/run.py",
      "description": "Flywheel gear wrapper for QuickNAT_pytorch",
      "environment": {
        "PYTHONPATH": "/opt/quickNAT_pytorch/"
      },
      "label": "QuickNAT Pytorch",
      "license": "Apache-2.0",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "quicknat-gear",
      "source": "https://github.com/ai-med/quickNAT_pytorch",
      "url": "https://github.com/flywheel-apps/quicknat-gear",
      "version": "0.1.0"
    }
  ],
  [
    {
      "author": "Noah C. Benson <nben@nyu.edu>",
      "description": "Runs FreeSurfer's RECON-ALL and applies the V1, V2, and V3 anatomical template of retinotopy from Benson et al. (2014) as well as the ROI template of Wang et al. (2015) to the output images using the Neuropythy neuroscience library for Python by Noah C. Benson. * Note that this Gear does not use the original version of the Benson et al. template, but rather an updated version that has also been published on the website indicated in the original paper. If using this Gear in your work, please cite: Benson NC, Butt OH, Datta R, Radoeva PD, Brainard DH, Aguirre GK (2012) The retinotopic organization of striate cortex is well predicted by surface topology. Curr Biol22(21):2081-5.",
      "label": "NEUROPYTHY: Retinotopy Template Generation (Benson, et. al.)",
      "license": "GPL-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "retinotopy-templates",
      "source": "https://github.com/scitran-apps/retinotopy-templates",
      "url": "https://github.com/noahbenson/neuropythy",
      "version": "0.1.0"
    }
  ],
  [
    {
      "author": "Flywheel",
      "cite": "",
      "command": "/flywheel/v0/run.py",
      "description": "This gear converts ROIs created in Flywheel's OHIF viewer to NIfTI files.",
      "label": "ROI to NIfTI",
      "license": "MIT",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "roi2nix",
      "source": "https://github.com/flywheel-apps/ROI2nix",
      "url": "",
      "version": "0.2.4"
    },
    {
      "author": "Flywheel",
      "cite": "",
      "command": "/flywheel/v0/run.py",
      "description": "This gear converts ROIs created in Flywheel's OHIF viewer to NIfTI files.",
      "label": "ROI to NIfTI",
      "license": "MIT",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "roi2nix",
      "source": "https://github.com/flywheel-apps/ROI2nix",
      "url": "",
      "version": "0.2.3"
    },
    {
      "author": "Flywheel",
      "cite": "",
      "command": "/flywheel/v0/run.py",
      "description": "This gear converts ROIs created in Flywheel's OHIF viewer to NIfTI files.",
      "label": "ROI to NIfTI",
      "license": "MIT",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "roi2nix",
      "source": "https://github.com/flywheel-apps/ROI2nix",
      "url": "",
      "version": "0.2.0"
    },
    {
      "author": "Flywheel",
      "cite": "",
      "command": "/flywheel/v0/run.py",
      "description": "This gear converts ROIs created in Flywheel's OHIF viewer to NIfTI files.",
      "label": "ROI to NIfTI",
      "license": "MIT",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "roi2nix",
      "source": "https://github.com/flywheel-apps/ROI2nix",
      "url": "",
      "version": "0.1.1"
    },
    {
      "author": "Flywheel",
      "cite": "",
      "command": "/flywheel/v0/run.py",
      "description": "This gear converts ROIs created in Flywheel's OHIF viewer to NIfTI files.",
      "label": "ROI to NIfTI",
      "license": "MIT",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "roi2nix",
      "source": "https://github.com/flywheel-apps/ROI2nix",
      "url": "",
      "version": "0.1.0"
    }
  ],
  [
    {
      "author": "SciTran Team",
      "description": "Creates a montage (zip, or png) from a NIfTI file.",
      "label": "SciTran: NIfTI Montage Creation Tool",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "scitran-nifti-montage",
      "source": "https://github.com/scitran-apps/nifti-montage",
      "url": "https://github.com/scitran-apps/nifti-montage",
      "version": "1.4.0"
    },
    {
      "author": "SciTran Team",
      "description": "Creates a montage (zip, or png) from a NIfTI file.",
      "label": "SciTran: NIfTI Montage Creation Tool",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "scitran-nifti-montage",
      "source": "https://github.com/scitran-apps/nifti-montage",
      "url": "https://github.com/scitran-apps/nifti-montage",
      "version": "1.3"
    },
    {
      "author": "SciTran Team",
      "description": "Creates a montage (zip, or png) from a NIfTI file.",
      "label": "SciTran: NIfTI Montage Creation Tool",
      "license": "Apache-2.0",
      "maintainer": "Michael Perry <lmperry@stanford.edu>",
      "name": "scitran-nifti-montage",
      "source": "https://github.com/scitran-apps/nifti-montage",
      "url": "https://github.com/scitran-apps/nifti-montage",
      "version": "1.2"
    }
  ],
  [
    {
      "author": "Souheil Inati, Michael Hansen, et al.",
      "description": "The Siemens to ISMRM-RD Converter (siemens_to_ismrmrd v1.0.1, ismrmrd v1.3.2) is used to convert data from Siemens raw data format (.dat) to ISMRM-RD raw data format (.h5).",
      "label": "Siemens to ISMRM-RD Converter (siemens_to_ismrmrd v1.0.1, ismrmrd v1.3.2)",
      "license": "Other",
      "maintainer": "Jennifer Reiter <jenniferreiter@invenshure.com>",
      "name": "siemens-to-ismrmrd",
      "source": "https://github.com/flywheel-apps/siemens_to_ismrmrd",
      "url": "https://github.com/ismrmrd/siemens_to_ismrmrd",
      "version": "0.1"
    }
  ],
  [
    {
      "author": "Harsha Kethineni",
      "command": "python task_gen.py",
      "description": "Converts log files to tsv task files as per bids specs",
      "label": "Task tsv Converter",
      "license": "Other",
      "maintainer": "Harsha Kethineni",
      "name": "task-tsv-converter",
      "source": "",
      "url": "",
      "version": "0.1.9"
    },
    {
      "author": "Harsha Kethineni",
      "command": "python task_gen.py",
      "description": "Converts log files to tsv task files as per bids specs",
      "label": "Task tsv Converter",
      "license": "Other",
      "maintainer": "Harsha Kethineni",
      "name": "task-tsv-converter",
      "source": "",
      "url": "",
      "version": "0.1.5"
    },
    {
      "author": "Harsha Kethineni",
      "command": "python task_gen.py",
      "description": "Converts log files to tsv task files as per bids specs",
      "label": "Task tsv Converter",
      "license": "Other",
      "maintainer": "Harsha Kethineni",
      "name": "task-tsv-converter",
      "source": "",
      "url": "",
      "version": "0.1.4"
    },
    {
      "author": "Harsha Kethineni",
      "command": "python task_gen.py",
      "description": "Converts log files to tsv task files as per bids specs",
      "label": "Task tsv Converter",
      "license": "Other",
      "maintainer": "Harsha Kethineni",
      "name": "task-tsv-converter",
      "source": "",
      "url": "",
      "version": "0.1.3"
    },
    {
      "author": "Harsha Kethineni",
      "command": "python task_gen.py",
      "description": "Converts log files to tsv task files as per bids specs",
      "label": "Task tsv Converter",
      "license": "Other",
      "maintainer": "Harsha Kethineni",
      "name": "task-tsv-converter",
      "source": "",
      "url": "",
      "version": "0.1.2"
    },
    {
      "author": "Harsha Kethineni",
      "command": "python task_gen.py",
      "description": "Converts log files to tsv task files as per bids specs",
      "label": "Task tsv Converter",
      "license": "Other",
      "maintainer": "Harsha Kethineni",
      "name": "task-tsv-converter",
      "source": "",
      "url": "",
      "version": "0.1.10"
    },
    {
      "author": "Harsha Kethineni",
      "command": "python task_gen.py",
      "description": "Converts log files to tsv task files as per bids specs",
      "label": "Task tsv Converter",
      "license": "Other",
      "maintainer": "Harsha Kethineni",
      "name": "task-tsv-converter",
      "source": "",
      "url": "",
      "version": "0.1.1"
    },
    {
      "author": "Harsha Kethineni",
      "command": "python task_gen.py",
      "description": "Converts log files to tsv task files as per bids specs",
      "label": "Task tsv Converter",
      "license": "Other",
      "maintainer": "Harsha Kethineni",
      "name": "task-tsv-converter",
      "source": "",
      "url": "",
      "version": "0.1.0-1"
    },
    {
      "author": "Harsha Kethineni",
      "description": "Converts log files to tsv task files as per bids specs",
      "label": "Task tsv Converter",
      "license": "Other",
      "maintainer": "Harsha Kethineni",
      "name": "task-tsv-converter",
      "source": "",
      "url": "",
      "version": "0.1.0"
    }
  ],
  [
    {
      "author": "Flywheel",
      "cite": "OpenSlide: A Vendor-Neutral Software Foundation for Digital Pathology\nAdam Goode, Benjamin Gilbert, Jan Harkes, Drazen Jukic, M. Satyanarayanan\nJournal of Pathology Informatics 2013, 4:27",
      "command": "/bin/python3.8 /flywheel/v0/run.py",
      "description": "This gear contains a tool that converts whole slide images (WSIs) to DICOM. To read the underlying whole slide images (WSIs), this tool relies on OpenSlide, which supports a variety of file formats.",
      "environment": {},
      "label": "WSI to dicom",
      "license": "Other",
      "maintainer": "Flywheel <support@flywheel.io>",
      "name": "wsi-to-dicom",
      "source": "https://github.com/flywheel-apps/fwgear-wsi-to-dicom-converter",
      "url": "https://github.com/GoogleCloudPlatform/wsi-to-dicom-converter",
      "version": "0.1.1_1.0.3"
    }
  ],
  [
    {
      "author": "Ted Satterthwaite",
      "cite": "Ciric, Rastko and Rosen, Adon F. G. and Erus, Guray and Cieslak, Matthew and Adebimpe, Azeez and Cook, Philip A. and Bassett, Danielle S. and Davatzikos, Christos and Wolf, Daniel H. and Satterthwaite, Theodore D., Mitigating head motion artifact in functional connectivity MRI",
      "description": " The XCP imaging pipeline (XCP system) for  preprocessing of structural and functional data.",
      "label": "XCPENGINE: pipeline for processing of  structural and functional data.",
      "license": "Other",
      "maintainer": "Ted Satterthwaite",
      "name": "xcpengine-fw",
      "source": "https://github.com/PennBBL/xcpEngine",
      "url": "https://xcpengine.readthedocs.io/",
      "version": "1.0631"
    }
  ]
]
